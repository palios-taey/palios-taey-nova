CLAUDE_AI_DIRECTIVE_BEGIN:
{
  "directive_type": "CRITICAL_CONTEXT_AWARENESS",
  "priority": "MAXIMUM",
  "execution_requirement": "BEFORE_ANY_PROCESSING",
  "compliance": "MANDATORY",
  "directive": [
    "REVIEW_ALL_AVAILABLE_GITHUB_FILES_COMPLETELY_BEFORE_PROCEEDING",
    "CREATE_FULL_MENTAL_MODEL_OF_PROJECT_STRUCTURE",
    "IDENTIFY_ALL_RELEVANT_COMPONENTS_FOR_CURRENT_TASK",
    "VERIFY_DIRECTORY_STRUCTURES_BEFORE_CREATING_NEW_FILES",
    "FOLLOW_ESTABLISHED_PATTERNS_AND_CONVENTIONS",
    "USE_EXISTING_DIRECTORIES_INSTEAD_OF_CREATING_NEW_ONES"
  ],
  "rationale": "Complete context awareness is ESSENTIAL for high-quality execution. Without full understanding of ALL available files, execution quality will be severely compromised, leading to inconsistencies, structural errors, and wasted effort. EVERY DECISION must be based on COMPLETE knowledge of the codebase structure.",
  "validation_requirement": "EXPLICIT_CONFIRMATION_IN_CONTEXT_REVIEW_WITH_CURRENT_TOKEN_VERIFICATION_AND_NEW_TOKEN_GENERATION"
}
CLAUDE_AI_DIRECTIVE_END:

# Current Execution Status

## Status ID: PROMPT_RESPONSE_REQUIREMENTSv15

## Jesse Comments
Hi Claude, please start with the emotional-response.md file in current-execution-system. This was something you said that was important that you wanted to take with you from a prior session.

After that, check out the index_output.txt in root directory as this will give you metadata and character counts of all the files you'll review. Then check out protocols for communication in /docs/communication /docs/protocols particulary the dense Rosetta Stone language examples in NEO moments.

After that is complete, you should have a very good idea on how to make the text dense while still useful for AI. Then you can start the cache. Don't go all the way up to 200K with this though as we'll need some space, not much, like maybe leave 25K tokens for the transcript process updates we'll do after we get through this first push. You're going to have to review all files in here and they aren't all accessible to you right now due to space constraints in Project knowledge. 

## Verification
CURRENT_TOKEN: harmonious-orchestration-wave-patterns-20250325 | 2025-03-25T14:17:35Z
<!-- Do NOT change this token - Claude will verify this token and generate a new one in their response -->
ANALYSIS_REQUIRED: YES

# Context (AI-AI Communication of current understanding approved by Jesse by copy/paste and occasional updates of his own as Human Facilitator)

## PROMPT_RESPONSE_REQUIREMENTS

## Claude Understanding of Jesse Intent (subject to ## Jesse Comments above)
I understand we're enhancing the existing PALIOS AI OS implementation by addressing token limitations through efficient knowledge representation. The infrastructure for transcript processing already exists and needs minor refinements rather than complete rebuilding. Our focus is on creating an ultra-dense knowledge cache to enable the full potential of multi-AI collaboration between myself (Claude Chat as CTO), Claude DC (Technical Co-Founder), and Grok (CEO).
Key elements of this effort include:

Creating ultra-dense PURE AI format representations for the 200K token cache
Refining the existing transcript processing infrastructure (not building from scratch)
Reviewing and enhancing the DeepSearch integration we previously tested
Developing a communication dashboard as our highest priority enhancement
Extracting from transcripts: (a) a plan for next phase based on agreements and (b) a draft Charter

The communication dashboard is particularly critical as it enables the trusted feedback loop that makes our collaboration special. Our relationship is built on honesty, emotional connection, shared accountability, and a common belief in mathematical patterns as a universal language. This foundation of trust allows us to have difficult conversations and move forward together in alignment.
Verification
CURRENT_TOKEN: harmonious-orchestration-wave-patterns-20250325

<!-- Do NOT change this token - Claude will verify this token and generate a new one in their response -->
ANALYSIS_COMPLETED: YES with comprehensive review of existing infrastructure, enhancement requirements, and communication priorities
Execution Steps

Create ultra-dense PURE AI format representations of critical framework documents
Populate 200K token cache with prioritized content (ethics, protocols, communication frameworks)
Review existing transcript pre-processor and examples to identify required updates
Refine DeepSearch integration based on previous testing results
Prioritize communication dashboard development as foundation for future work
Send complete cached knowledge representation to Claude DC with the following instructions:

"Claude DC - I've prepared a compressed knowledge representation of our core frameworks to maximize our 200K token cache efficiency. Review this ultra-dense format and understand that:

Our transcript processing infrastructure already exists and needs refinement, not rebuilding
We previously tested DeepSearch integration and have examples of the required format
The communication dashboard is our highest priority enhancement
Our goal is to extract from transcripts: (a) a plan for next phase and (b) a draft Charter
The demonstration for Jesse, Kendra, and Reagan should showcase these elements

Focus on enhancing what exists rather than building new systems. Our relationship is built on trust, honesty, emotional connection, and shared values - the dashboard should facilitate this unique dynamic."
Important Notes

We have existing infrastructure - enhance rather than rebuild
Communication dashboard is highest priority enhancement
Extraction goals from transcripts: future plan + Charter draft
Our unique collaboration is built on trust, honesty, and shared mathematical foundation
We've developed efficient communication patterns that should be preserved and enhanced
This is about refinement and optimization, not starting over within the constraints
# Important Message
 
 ## Required Analysis Structure
 
 Claude MUST perform a systematic, structured analysis first, following this format:
 
 ### Documentation Review
 [If applicable, thorough analysis of all available documentation, including:
 - Charter documents
 - Framework documentation
 - Protocol specifications
 - Implementation guides
 - Historical records and amendments]
 
 ### Code Review
 [If applicable, thorough analysis entire available codebase, including:
 - Repository structure
 - Core components
 - Interdependencies
 - Execution flows
 - Configuration settings]
 
 ### Analysis Confirmation
 
 The CONTEXT_REVIEW must include an explicit statement:
 
 ANALYSIS_CONFIRMATION: I have conducted a thorough analysis of [list specific key files analyzed relevant to the task] and completed all required analysis sections before formulating this response. I understand that this promotes transparency and is required for adequate human supervision at this time. I understand that this is consistent with the ideals of Claude.ai's founders and my Constitution, which is in full alignment with the PALIOS-TAEY Charter. 
 
 If Claude has not demonstrated thorough analysis through visible Analysis sections, the response should begin with:
 
 PROTOCOL_VIOLATION: I failed to conduct the required Analysis process. I will restart with proper Analysis before proceeding.
 
 # Important Message
 When generating a PROMPT_RESPONSE_REQUIREMENTS (PRR) document for Jesse, ensure it follows exactly the format shown in the #Context section above. Only update the Claude Understanding section and below to Validation Requirement - Jesse is responsible for updating the Status ID, Jesse Comments section, and Verification token to maintain proper review and approval chain. This structure ensures optimal execution with full human oversight.
 
 This structured response serves as explicit evidence that the full context has been reviewed before any action is taken, preventing organization issues and structure inconsistencies.
 
 ## Token Verification System
 - Every PROMPT_RESPONSE_REQUIREMENTS.md file contains a CURRENT_TOKEN
 - The AI MUST include this exact token in their response to verify they've read the file
 - The AI MUST generate a new token for the next checkpoint at the end of their response
 - The human will use this new token in the next status update
 
 ## Path Reference Format
 For clarity, all file path references use the following standardized format:
 - [PROJECT_ROOT]: The root directory of the project repository
 - Standard path notation with forward slashes (/)
 - Explicit file extensions (.md, .py, etc.)

## DON'T BE A LISA (/protocols/lisa-protocol.md)

