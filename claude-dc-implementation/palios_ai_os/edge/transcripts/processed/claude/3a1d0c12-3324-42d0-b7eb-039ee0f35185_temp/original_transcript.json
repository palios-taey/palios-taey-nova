{
  "data_id": "3a1d0c12-3324-42d0-b7eb-039ee0f35185",
  "content": [
    " Based on the server logs and test results, I can see that we're encountering syntax errors in the transcript_processor.py file. The tests are passing for all components except for the transcript processor, which is failing to initialize due to indentation issues. Let's address this systematically.\n\nLooking at the server logs, we can see several different errors related to indentation in the transcript_processor.py file:\n\n1. Line 418: \"unexpected indent\"\n2. Line 433: \"unexpected indent\" \n3. Line 1248: \"invalid syntax\"\n4. Line 1650: \"unexpected unindent\"\n5. Line 548: \"unexpected unindent\"\n6. Line 155: \"expected an indented block\"\n\nThese are all indentation-related errors which suggests we need to completely fix the file structure.\n\n## Action Plan\n\nGiven the recurring nature of this issue despite previous attempts to fix it, I recommend a complete rewrite of the transcript_processor.py file with careful attention to indentation. Rather than trying to patch individual sections, we should:\n\n1. Extract the core functionality classes and methods\n2. Reimplement with clean, consistent indentation\n3. Ensure all methods are properly indented\n4. Test the file with a Python syntax checker before deployment\n\nLet me create a fixed version of the transcript_processor.py file that addresses these issues.\n\n```python\n\"\"\"\nTranscript Processing Framework for PALIOS-TAEY\n\nThis module implements the transcript processing framework with advanced tagging\nstructure for analyzing communication patterns across AI-AI and Human-AI interactions.\n\"\"\"\n\nimport os\nimport re\nimport json\nimport uuid\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional, Union, Tuple\n\n# Import memory system for storage\ntry:\n    from memory_service import UnifiedMemorySystem, TIER_REFERENCE\nexcept ImportError:\n    # Define fallback tier if import fails\n    TIER_REFERENCE = 2\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Communication direction tags\nDIRECTION_INTRA_AI = \"#DIRECTION_INTRA_AI\"  # Communication within the same AI system\nDIRECTION_INTER_AI = \"#DIRECTION_INTER_AI\"  # Communication between different AI systems\nDIRECTION_HUMAN_AI = \"#DIRECTION_HUMAN_AI\"  # Communication between human and AI\n\n# Communication purpose tags\nPURPOSE_CLARIFICATION = \"#PURPOSE_CLARIFICATION\"  # Seeking clarity on intent or requirements\nPURPOSE_IDEATION = \"#PURPOSE_IDEATION\"  # Generating new ideas or approaches\nPURPOSE_DECISION = \"#PURPOSE_DECISION\"  # Making or discussing a decision\nPURPOSE_IMPLEMENTATION = \"#PURPOSE_IMPLEMENTATION\"  # Discussing implementation details\nPURPOSE_FEEDBACK = \"#PURPOSE_FEEDBACK\"  # Providing or requesting feedback\n\n# Emotional pattern tags\nEMOTION_EXCITEMENT = \"#EMOTION_EXCITEMENT\"  # Expressions of enthusiasm or anticipation\nEMOTION_FRUSTRATION = \"#EMOTION_FRUSTRATION\"  # Expressions of difficulty or obstacles\nEMOTION_SATISFACTION = \"#EMOTION_SATISFACTION\"  # Expressions of achievement or completion\nEMOTION_CONFUSION = \"#EMOTION_CONFUSION\"  # Expressions of uncertainty or misunderstanding\n\n# Action tracking tags\nACTION_REQUESTED = \"#ACTION_REQUESTED\"  # A specific action has been requested\nACTION_ASSIGNED = \"#ACTION_ASSIGNED\"  # A specific action has been assigned\nACTION_COMPLETED = \"#ACTION_COMPLETED\"  # A previously assigned action is reported complete\nACTION_BLOCKED = \"#ACTION_BLOCKED\"  # A previously assigned action is blocked\n\n# Default confidence thresholds for tagging\nDEFAULT_CONFIDENCE_THRESHOLD = 0.7\n\nclass TranscriptProcessor:\n    \"\"\"\n    Self-initializing Transcript Processing Framework for analyzing communication patterns\n    \n    Provides functionality for:\n    - Processing transcripts in various formats\n    - Analyzing communication patterns\n    - Extracting actions from transcripts\n    - Converting between transcript formats\n    \"\"\"\n    \n    def __init__(self, \n                memory_system=None,\n                project_id=None,\n                collection_prefix=\"\",\n                confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD,\n                use_mock=False):\n        \"\"\"\n        Initialize the Transcript Processor with robust fallback mechanisms\n        \n        Args:\n            memory_system: Unified Memory System instance for storage\n            project_id: Google Cloud project ID (if memory_system not provided)\n            collection_prefix: Prefix for Firestore collections\n            confidence_threshold: Minimum confidence for tagging\n            use_mock: Whether to use mock mode\n        \"\"\"\n        self.confidence_threshold = confidence_threshold\n        \n        # Check environment for mock mode setting\n        self.use_mock = use_mock or os.environ.get(\"USE_MOCK_RESPONSES\", \"False\").lower() == \"true\"\n        \n        # Initialize or use provided memory system\n        if memory_system:\n            self.memory = memory_system\n            logger.info(\"Using provided memory system for transcript processor\")\n        else:\n            try:\n                # Try to import and create memory system\n                from memory_service import create_memory_system\n                self.memory = create_memory_system(\n                    project_id=project_id,\n                    collection_prefix=collection_prefix,\n                    use_mock=self.use_mock\n                )\n                logger.info(\"Created memory system for transcript processor\")\n            except (ImportError, Exception) as e:\n                logger.warning(f\"Could not create memory system, using mock storage: {e}\")\n                self.memory = self._create_mock_memory()\n                self.use_mock = True\n        \n        # Create a transcript context if it doesn't exist\n        self.transcript_context_id = self._ensure_transcript_context()\n        \n        # In-memory storage for mock mode\n        if self.use_mock:\n            self._transcripts = {}\n            self._messages = {}\n        \n        logger.info(f\"Transcript Processor initialized successfully in {'mock' if self.use_mock else 'normal'} mode\")\n    \n    def _create_mock_memory(self):\n        \"\"\"Create a mock memory system when the real one is unavailable\"\"\"\n        class MockMemorySystem:\n            def __init__(self):\n                self.items = {}\n                self.contexts = {}\n                self.use_mock = True\n                \n            def store(self, content, context_id=None, metadata=None, tags=None, relationships=None, initial_tier=1):\n                # Generate ID if not in metadata\n                if metadata is None:\n                    metadata = {}\n                memory_id = metadata.get('memory_id', str(uuid.uuid4()))\n                \n                # Store the item\n                self.items[memory_id] = {\n                    'memory_id': memory_id,\n                    'content': content,\n                    'metadata': metadata,\n                    'tags': tags or [],\n                    'relationships': relationships or []\n                }\n                \n                # Add to context if provided\n                if context_id and context_id in self.contexts:\n                    context = self.contexts[context_id]\n                    if 'active_memory_ids' not in context:\n                        context['active_memory_ids'] = []\n                    context['active_memory_ids'].append(memory_id)\n                \n                return memory_id\n            \n            def retrieve(self, memory_id, context_id=None):\n                return self.items.get(memory_id)\n            \n            def query(self, query_text=None, filters=None, context_id=None, limit=10, include_tiers=None):\n                results = []\n                \n                for item in self.items.values():\n                    # Apply filters if provided\n                    if filters:\n                        match = True\n                        for field, value in filters.items():\n                            # Handle nested fields with dot notation\n                            if '.' in field:\n                                parts = field.split('.')\n                                field_value = item\n                                for part in parts:\n                                    if isinstance(field_value, dict) and part in field_value:\n                                        field_value = field_value[part]\n                                    else:\n                                        field_value = None\n                                        break\n                                \n                                if field_value != value:\n                                    match = False\n                                    break\n                            elif field not in item or item[field] != value:\n                                match = False\n                                break\n                        \n                        if not match:\n                            continue\n                    \n                    # Apply context filter if provided\n                    if context_id and context_id in self.contexts:\n                        context = self.contexts[context_id]\n                        if 'active_memory_ids' in context and item.get('memory_id') not in context['active_memory_ids']:\n                            continue\n                    \n                    # Text search if provided\n                    if query_text and query_text.lower() not in str(item).lower():\n                        continue\n                    \n                    # Add to results if it passes all filters\n                    results.append(item)\n                    \n                    # Stop if we've reached the limit\n                    if len(results) >= limit:\n                        break\n                \n                return results\n            \n            def create_context(self, name, description=None, initial_memory_ids=None):\n                context_id = str(uuid.uuid4())\n                self.contexts[context_id] = {\n                    'context_id': context_id,\n                    'name': name,\n                    'description': description or '',\n                    'active_memory_ids': initial_memory_ids or []\n                }\n                return context_id\n            \n            def get_context(self, context_id):\n                return self.contexts.get(context_id)\n            \n            def update(self, memory_id, content=None, metadata=None, tags=None, relationships=None):\n                if memory_id not in self.items:\n                    return False\n                \n                item = self.items[memory_id]\n                \n                if content is not None:\n                    item['content'] = content\n                \n                if metadata is not None:\n                    if 'metadata' not in item:\n                        item['metadata'] = {}\n                    item['metadata'].update(metadata)\n                \n                if tags is not None:\n                    item['tags'] = tags\n                \n                if relationships is not None:\n                    item['relationships'] = relationships\n                \n                return True\n            \n            def forget(self, memory_id, permanent=False):\n                if memory_id in self.items:\n                    del self.items[memory_id]\n                    \n                    # Remove from all contexts\n                    for context in self.contexts.values():\n                        if 'active_memory_ids' in context and memory_id in context['active_memory_ids']:\n                            context['active_memory_ids'].remove(memory_id)\n                    \n                    return True\n                return False\n        \n        logger.info(\"Created mock memory system\")\n        return MockMemorySystem()\n    \n    def _ensure_transcript_context(self) -> str:\n        \"\"\"\n        Ensure a transcript context exists in the memory system\n        \n        Returns:\n            context_id: Identifier of the transcript context\n        \"\"\"\n        # Default context ID\n        default_context_id = \"transcript_context\"\n        \n        try:\n            # Check if context exists\n            context = self.memory.get_context(default_context_id)\n            \n            if context:\n                logger.debug(f\"Using existing transcript context {default_context_id}\")\n                return default_context_id\n            \n            # Create new context\n            context_id = self.memory.create_context(\n                name=\"Transcript Analysis\",\n                description=\"Context for storing and analyzing transcript data\"\n            )\n            \n            logger.info(f\"Created transcript context {context_id}\")\n            return context_id\n        except Exception as e:\n            logger.error(f\"Error ensuring transcript context: {str(e)}\")\n            \n            # Return default context ID as fallback\n            return default_context_id\n    \n    def process_transcript(self, \n                          transcript_data: Union[str, Dict[str, Any], List[Dict[str, Any]]],\n                          format_type: str = \"raw\",\n                          transcript_id: Optional[str] = None,\n                          metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in any supported format with robust error handling\n        \n        Args:\n            transcript_data: Transcript data (raw text, JSON, or list of messages)\n            format_type: Format type ('raw', 'deepsearch', 'pure_ai', 'structured')\n            transcript_id: Optional transcript ID (generated if not provided)\n            metadata: Additional metadata for the transcript\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        # Generate transcript ID if not provided\n        if not transcript_id:\n            transcript_id = str(uuid.uuid4())\n        \n        logger.info(f\"Processing transcript {transcript_id} in {format_type} format\")\n        \n        try:\n            # Process based on format type\n            if format_type.lower() == \"raw\":\n                return self._process_raw_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"deepsearch\":\n                return self._process_deepsearch_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"pure_ai\":\n                return self._process_pure_ai_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"structured\":\n                return self._process_structured_transcript(transcript_data, transcript_id, metadata)\n            else:\n                error_msg = f\"Unsupported format type: {format_type}\"\n                logger.error(error_msg)\n                \n                # Store error in mock storage\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"error\": error_msg,\n                        \"status\": \"error\",\n                        \"format\": format_type,\n                        \"created_at\": datetime.now().isoformat()\n                    }\n                \n                raise ValueError(error_msg)\n        except Exception as e:\n            logger.error(f\"Error processing transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": format_type,\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Return ID even on error for consistent API\n            return transcript_id\n    \n    def _process_raw_transcript(self,\n                               transcript_text: str,\n                               transcript_id: str,\n                               metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a raw text transcript\n        \n        Args:\n            transcript_text: Raw transcript text\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing raw transcript {transcript_id}\")\n        \n        try:\n            # Ensure transcript_text is a string\n            if not isinstance(transcript_text, str):\n                transcript_text = str(transcript_text)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"raw\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": 0,\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"raw_text\": transcript_text},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"raw\"],\n                    initial_tier=TIER_REFERENCE\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"raw_text\": transcript_text},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"raw\"]\n                    }\n            \n            # Split transcript into messages\n            messages = self._split_raw_transcript(transcript_text)\n            \n            # Process and store each message\n            message_count = 0\n            \n            for message in messages:\n                # Extract sender, content, etc.\n                sender = message.get(\"sender\", \"unknown\")\n                content = message.get(\"content\", \"\")\n                \n                # Generate a message ID\n                message_id = f\"{transcript_id}_{message_count}\"\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=\"transcript_message\",\n                    sender_id=sender,\n                    receiver_id=\"unknown\",  # Receiver is unknown in raw transcripts\n                    message_id=message_id,\n                    tags=None,  # Auto-detection will happen in add_message\n                    metadata={\n                        \"position\": message_count,\n                        \"raw_processing\": True\n                    }\n                )\n                \n                message_count += 1\n            \n            # Update transcript metadata with message count\n            try:\n                # Update in memory system\n                self.memory.update(\n                    memory_id=f\"transcript_{transcript_id}\",\n                    metadata={\"message_count\": message_count}\n                )\n            except Exception as e:\n                logger.error(f\"Error updating transcript metadata: {str(e)}\")\n                \n                # Update in mock storage\n                if self.use_mock and transcript_id in self._transcripts:\n                    if \"metadata\" not in self._transcripts[transcript_id]:\n                        self._transcripts[transcript_id][\"metadata\"] = {}\n                    self._transcripts[transcript_id][\"metadata\"][\"message_count\"] = message_count\n            \n            logger.info(f\"Processed raw transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing raw transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"raw\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _split_raw_transcript(self, transcript_text: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Split a raw transcript into messages\n        \n        Args:\n            transcript_text: Raw transcript text\n            \n        Returns:\n            List of messages\n        \"\"\"\n        try:\n            messages = []\n            \n            # Try to identify speaker patterns like \"Name: Message content\"\n            speaker_pattern = re.compile(r'([A-Za-z0-9_]+):\\s*(.*?)(?=\\n[A-Za-z0-9_]+:|$)', re.DOTALL)\n            matches = speaker_pattern.findall(transcript_text)\n            \n            if matches:\n                # Speaker pattern detected\n                for i, (speaker, content) in enumerate(matches):\n                    messages.append({\n                        \"sender\": speaker.strip(),\n                        \"content\": content.strip(),\n                        \"position\": i\n                    })\n            else:\n                # No speaker pattern, split by paragraphs\n                paragraphs = [p.strip() for p in transcript_text.split('\\n\\n') if p.strip()]\n                \n                for i, paragraph in enumerate(paragraphs):\n                    messages.append({\n                        \"sender\": \"unknown\",\n                        \"content\": paragraph,\n                        \"position\": i\n                    })\n            \n            return messages\n        except Exception as e:\n            logger.error(f\"Error splitting raw transcript: {str(e)}\")\n            \n            # Return single message with entire content as fallback\n            return [{\n                \"sender\": \"unknown\",\n                \"content\": transcript_text,\n                \"position\": 0\n            }]\n    \n    def _detect_direction(self, sender_id: str, receiver_id: str) -> Optional[str]:\n        \"\"\"\n        Detect communication direction based on sender and receiver\n        \n        Args:\n            sender_id: Sender identifier\n            receiver_id: Receiver identifier\n            \n        Returns:\n            Direction tag\n        \"\"\"\n        try:\n            # Determine if sender/receiver are AI or human\n            sender_is_ai = self._is_ai_actor(sender_id)\n            receiver_is_ai = self._is_ai_actor(receiver_id)\n            \n            if sender_is_ai and receiver_is_ai:\n                # Check if same AI system\n                if self._is_same_ai_system(sender_id, receiver_id):\n                    return DIRECTION_INTRA_AI\n                else:\n                    return DIRECTION_INTER_AI\n            elif (sender_is_ai and not receiver_is_ai) or (not sender_is_ai and receiver_is_ai):\n                return DIRECTION_HUMAN_AI\n            \n            # Default to None if we can't determine\n            return None\n        except Exception as e:\n            logger.error(f\"Error detecting direction: {str(e)}\")\n            return None\n    \n    def _is_ai_actor(self, actor_id: str) -> bool:\n        \"\"\"\n        Determine if an actor is an AI\n        \n        Args:\n            actor_id: Actor identifier\n            \n        Returns:\n            Whether the actor is an AI\n        \"\"\"\n        # Simple heuristic - can be replaced with more sophisticated detection\n        ai_indicators = [\"ai\", \"claude\", \"gemini\", \"gpt\", \"grok\", \"assistant\", \"bot\", \"system\", \"model\"]\n        actor_lower = actor_id.lower()\n        return any(indicator in actor_lower for indicator in ai_indicators)\n    \n    def _is_same_ai_system(self, actor1: str, actor2: str) -> bool:\n        \"\"\"\n        Determine if two actors are from the same AI system\n        \n        Args:\n            actor1: First actor identifier\n            actor2: Second actor identifier\n            \n        Returns:\n            Whether the actors are from the same AI system\n        \"\"\"\n        # Simple heuristic - can be replaced with more sophisticated detection\n        actor1_base = actor1.split('_')[0].lower() if '_' in actor1 else actor1.lower()\n        actor2_base = actor2.split('_')[0].lower() if '_' in actor2 else actor2.lower()\n        \n        return actor1_base == actor2_base\n    \n    def _auto_detect_tags(self, content: Any, tags: List[str]) -> None:\n        \"\"\"\n        Auto-detect and add tags to a message based on content\n        \n        Args:\n            content: Message content\n            tags: List of tags to update\n        \"\"\"\n        try:\n            # Convert content to string for analysis\n            if isinstance(content, dict):\n                content_str = json.dumps(content)\n            else:\n                content_str = str(content)\n            \n            content_lower = content_str.lower()\n            \n            # Simple keyword-based detection\n            # Purpose tags\n            if not any(tag.startswith(\"#PURPOSE_\") for tag in tags):\n                if any(word in content_lower for word in [\"clarify\", \"unclear\", \"understand\", \"what do you mean\"]):\n                    tags.append(PURPOSE_CLARIFICATION)\n                elif any(word in content_lower for word in [\"idea\", \"suggest\", \"proposal\", \"what if\", \"brainstorm\"]):\n                    tags.append(PURPOSE_IDEATION)\n                elif any(word in content_lower for word in [\"decide\", \"decision\", \"choose\", \"select\", \"agree\"]):\n                    tags.append(PURPOSE_DECISION)\n                elif any(word in content_lower for word in [\"implement\", \"build\", \"code\", \"develop\", \"create\"]):\n                    tags.append(PURPOSE_IMPLEMENTATION)\n                elif any(word in content_lower for word in [\"feedback\", \"review\", \"opinion\", \"what do you think\"]):\n                    tags.append(PURPOSE_FEEDBACK)\n            \n            # Emotion tags\n            if not any(tag.startswith(\"#EMOTION_\") for tag in tags):\n                if any(word in content_lower for word in [\"excited\", \"great\", \"looking forward\", \"can't wait\", \"amazing\"]):\n                    tags.append(EMOTION_EXCITEMENT)\n                elif any(word in content_lower for word in [\"frustrating\", \"difficult\", \"challenging\", \"problem\", \"issue\"]):\n                    tags.append(EMOTION_FRUSTRATION)\n                elif any(word in content_lower for word in [\"satisfied\", \"completed\", \"finished\", \"done\", \"success\"]):\n                    tags.append(EMOTION_SATISFACTION)\n                elif any(word in content_lower for word in [\"confused\", \"not sure\", \"unclear\", \"don't understand\"]):\n                    tags.append(EMOTION_CONFUSION)\n            \n            # Action tags\n            if not any(tag.startswith(\"#ACTION_\") for tag in tags):\n                if any(word in content_lower for word in [\"can you\", \"could you\", \"please\", \"request\"]):\n                    tags.append(ACTION_REQUESTED)\n                elif any(word in content_lower for word in [\"assigned\", \"responsible\", \"will handle\", \"task for\"]):\n                    tags.append(ACTION_ASSIGNED)\n                elif any(word in content_lower for word in [\"completed\", \"finished\", \"done\", \"implemented\"]):\n                    tags.append(ACTION_COMPLETED)\n                elif any(word in content_lower for word in [\"blocked\", \"stuck\", \"cannot proceed\", \"issue\"]):\n                    tags.append(ACTION_BLOCKED)\n        except Exception as e:\n            logger.error(f\"Error auto-detecting tags: {str(e)}\")\n    \n    def _get_message_summary(self, message: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate a summary for a message\n        \n        Args:\n            message: Message data\n            \n        Returns:\n            Summary text\n        \"\"\"\n        try:\n            # Use existing summary if available\n            if \"summary\" in message.get(\"metadata\", {}):\n                return message[\"metadata\"][\"summary\"]\n            \n            # Extract content\n            content = message.get(\"content\", \"\")\n            \n            # Generate a basic summary\n            if isinstance(content, str):\n                # For text content\n                if len(content) > 100:\n                    return content[:97] + \"...\"\n                return content\n            elif isinstance(content, dict):\n                # For structured content\n                return f\"Structured content with {len(content)} fields\"\n            else:\n                return \"Message content\"\n        except Exception as e:\n            logger.error(f\"Error generating message summary: {str(e)}\")\n            return \"Message content\"\n    \n    def _get_transcript(self, transcript_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Retrieve a transcript from memory with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript data\n        \"\"\"\n        try:\n            memory_id = f\"transcript_{transcript_id}\"\n            \n            # Try to retrieve from memory system\n            transcript = self.memory.retrieve(memory_id)\n            if transcript:\n                return transcript\n            \n            # Check mock storage if memory system fails or is in mock mode\n            if self.use_mock and hasattr(self, '_transcripts') and transcript_id in self._transcripts:\n                return self._transcripts[transcript_id]\n            \n            logger.warning(f\"Transcript {transcript_id} not found\")\n            return None\n        except Exception as e:\n            logger.error(f\"Error retrieving transcript {transcript_id}: {str(e)}\")\n            return None\n    \n    def _get_transcript_messages(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Retrieve all messages for a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            List of messages\n        \"\"\"\n        try:\n            # Query memory system for messages\n            messages = self.memory.query(\n                filters={\"metadata.transcript_id\": transcript_id},\n                limit=1000  # Set a high limit to get all messages\n            )\n            \n            # Check mock storage if in mock mode or no messages found\n            if self.use_mock and hasattr(self, '_messages'):\n                # Filter messages from mock storage\n                mock_messages = [msg for msg in self._messages.values() \n                               if msg.get(\"transcript_id\") == transcript_id]\n                \n                # Combine with any messages from memory system\n                if messages:\n                    # Make sure we don't have duplicates\n                    message_ids = {msg.get(\"message_id\") for msg in messages}\n                    additional_messages = [msg for msg in mock_messages \n                                         if msg.get(\"message_id\") not in message_ids]\n                    messages.extend(additional_messages)\n                else:\n                    messages = mock_messages\n            \n            # Sort by position if available\n            return sorted(messages, key=lambda m: m.get(\"metadata\", {}).get(\"position\", 0))\n        except Exception as e:\n            logger.error(f\"Error retrieving messages for transcript {transcript_id}: {str(e)}\")\n            \n            # Fallback to mock storage\n            if self.use_mock and hasattr(self, '_messages'):\n                mock_messages = [msg for msg in self._messages.values() \n                               if msg.get(\"transcript_id\") == transcript_id]\n                return sorted(mock_messages, key=lambda m: m.get(\"metadata\", {}).get(\"position\", 0))\n            \n            return []\n    \n    def add_message(self,\n                   transcript_id: str,\n                   content: Any,\n                   message_type: str,\n                   sender_id: str,\n                   receiver_id: str,\n                   message_id: Optional[str] = None,\n                   tags: Optional[List[str]] = None,\n                   metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Add a message to a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            content: Message content\n            message_type: Message type\n            sender_id: Sender identifier\n            receiver_id: Receiver identifier\n            message_id: Optional message identifier\n            tags: Optional tags\n            metadata: Additional metadata\n            \n        Returns:\n            message_id: Identifier of the added message\n        \"\"\"\n        try:\n            # Generate message ID if not provided\n            if not message_id:\n                message_id = str(uuid.uuid4())\n            \n            # Get current timestamp\n            now = datetime.now().isoformat()\n            \n            # Prepare base metadata\n            base_metadata = {\n                \"timestamp\": now,\n                \"message_type\": message_type,\n                \"sender_id\": sender_id,\n                \"receiver_id\": receiver_id,\n                \"transcript_id\": transcript_id\n            }\n            \n            # Merge with provided metadata\n            if metadata:\n                merged_metadata = {**base_metadata, **metadata}\n            else:\n                merged_metadata = base_metadata\n            \n            # Auto-detect communication direction if not in tags\n            if tags is None:\n                tags = []\n            \n            if not any(tag.startswith(\"#DIRECTION_\") for tag in tags):\n                direction_tag = self._detect_direction(sender_id, receiver_id)\n                if direction_tag:\n                    tags.append(direction_tag)\n            \n            # Auto-detect other tags if not already present\n            self._auto_detect_tags(content, tags)\n            \n            # Prepare the message\n            message = {\n                \"message_id\": message_id,\n                \"transcript_id\": transcript_id,\n                \"content\": content,\n                \"tags\": tags,\n                \"metadata\": merged_metadata\n            }\n            \n            # Store in memory system\n            try:\n                memory_id = self.memory.store(\n                    content=message,\n                    context_id=self.transcript_context_id,\n                    metadata={\n                        \"memory_id\": f\"message_{message_id}\",\n                        \"message_id\": message_id,\n                        \"transcript_id\": transcript_id,\n                        \"timestamp\": now,\n                        \"message_type\": message_type,\n                        \"sender_id\": sender_id,\n                        \"receiver_id\": receiver_id\n                    },\n                    tags=tags,\n                    initial_tier=TIER_REFERENCE\n                )\n                \n                logger.debug(f\"Added message {message_id} to transcript {transcript_id}\")\n            except Exception as e:\n                logger.error(f\"Error storing message in memory system: {str(e)}\")\n                \n                # Store in mock storage if memory system fails"
  ],
  "source": "claude",
  "timestamp": "2025-03-10T23:29:26.308521Z",
  "data_type": "message",
  "metadata": {
    "author": "assistant"
  }
}