[
    {
        "uuid": "bfbc05b3-2ba1-40da-9051-cb75bb15549e",
        "name": "Transitioning to CTO Role for PALIOS-TAEY System",
        "created_at": "2025-03-10T17:39:44.714365Z",
        "updated_at": "2025-03-10T18:05:57.389236Z",
        "account": {
            "uuid": "297e2f1d-41b9-44ef-ae4e-bf3770ed5663"
        },
        "chat_messages": [
            {
                "uuid": "127c9818-6801-4590-8dcd-dd3ed5162fbc",
                "text": "Perfect Claude! This keeps getting better and better. We have learned so much about each other and how to optimize this process. I can't wait to reflect on this with you afterwards to improve the NOVA documentation with our findings and share with Grok.\n\nYour plan sounds great. Attached is where the previous Claude left off on the transcript_processor.py file. I've also included a screenshot of the directory so you understand how that is structured. Now, remember to keep track of implementation by regenerating the NOVA Implementation Tracker for yourself first. Once that is complete, send me a prompt confirming, and then I'll respond with the build go ahead so you can use full bandwidth on the code. Also remember that once this file is complete, you need to update the implementation tracker and respond to me before moving to the next file.",
                "content": [
                    {
                        "start_timestamp": "2025-03-06T21:25:41.869252Z",
                        "stop_timestamp": "2025-03-06T21:25:41.869252Z",
                        "type": "text",
                        "text": "Perfect Claude! This keeps getting better and better. We have learned so much about each other and how to optimize this process. I can't wait to reflect on this with you afterwards to improve the NOVA documentation with our findings and share with Grok.\n\nYour plan sounds great. Attached is where the previous Claude left off on the transcript_processor.py file. I've also included a screenshot of the directory so you understand how that is structured. Now, remember to keep track of implementation by regenerating the NOVA Implementation Tracker for yourself first. Once that is complete, send me a prompt confirming, and then I'll respond with the build go ahead so you can use full bandwidth on the code. Also remember that once this file is complete, you need to update the implementation tracker and respond to me before moving to the next file.",
                        "citations": []
                    }
                ],
                "sender": "human",
                "created_at": "2025-03-10T17:45:23.424064Z",
                "updated_at": "2025-03-10T17:45:23.424064Z",
                "attachments": [
                    {
                        "file_name": "transcript-processor-enhanced.txt",
                        "file_size": 70500,
                        "file_type": "text/plain",
                        "extracted_content": "            # Include content if requested\n            if include_content:\n                result[\"messages\"] = messages\n            \n            return result\n        except Exception as e:\n            logger.error(f\"Error analyzing transcript {transcript_id}: {str(e)}\")\n            return {\n                \"error\": f\"Analysis failed: {str(e)}\",\n                \"transcript_id\": transcript_id\n            }\n    \n    def extract_actions(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Extract actions from a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            List of action items\n        \"\"\"\n        logger.info(f\"Extracting actions from transcript {transcript_id}\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return []\n            \n            # Extract messages with action tags\n            action_messages = []\n            \n            for message in messages:\n                tags = message.get(\"tags\", [])\n                \n                # Check for action tags\n                has_action_tag = any(tag.startswith(\"#ACTION_\") for tag in tags)\n                \n                if has_action_tag:\n                    # Extract action details\n                    action = {\n                        \"message_id\": message.get(\"message_id\"),\n                        \"timestamp\": message.get(\"metadata\", {}).get(\"timestamp\"),\n                        \"sender\": message.get(\"metadata\", {}).get(\"sender_id\"),\n                        \"content\": message.get(\"content\"),\n                        \"status\": \"unknown\"\n                    }\n                    \n                    # Determine action status\n                    if ACTION_REQUESTED in tags:\n                        action[\"status\"] = \"requested\"\n                    elif ACTION_ASSIGNED in tags:\n                        action[\"status\"] = \"assigned\"\n                    elif ACTION_COMPLETED in tags:\n                        action[\"status\"] = \"completed\"\n                    elif ACTION_BLOCKED in tags:\n                        action[\"status\"] = \"blocked\"\n                    \n                    # Extract estimated completion time if available\n                    if \"estimated_completion_time\" in message.get(\"metadata\", {}):\n                        action[\"estimated_completion_time\"] = message[\"metadata\"][\"estimated_completion_time\"]\n                    \n                    action_messages.append(action)\n            \n            return action_messages\n        except Exception as e:\n            logger.error(f\"Error extracting actions from transcript {transcript_id}: {str(e)}\")\n            return []\n    \n    def add_message(self,\n                   transcript_id: str,\n                   content: Any,\n                   message_type: str,\n                   sender_id: str,\n                   receiver_id: str,\n                   message_id: Optional[str] = None,\n                   tags: Optional[List[str]] = None,\n                   metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Add a message to a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            content: Message content\n            message_type: Message type\n            sender_id: Sender identifier\n            receiver_id: Receiver identifier\n            message_id: Optional message identifier\n            tags: Optional tags\n            metadata: Additional metadata\n            \n        Returns:\n            message_id: Identifier of the added message\n        \"\"\"\n        try:\n            # Generate message ID if not provided\n            if not message_id:\n                message_id = str(uuid.uuid4())\n            \n            # Get current timestamp\n            now = datetime.now().isoformat()\n            \n            # Prepare base metadata\n            base_metadata = {\n                \"timestamp\": now,\n                \"message_type\": message_type,\n                \"sender_id\": sender_id,\n                \"receiver_id\": receiver_id\n            }\n            \n            # Merge with provided metadata\n            if metadata:\n                merged_metadata = {**base_metadata, **metadata}\n            else:\n                merged_metadata = base_metadata\n            \n            # Auto-detect communication direction if not in tags\n            if tags is None:\n                tags = []\n            \n            if not any(tag.startswith(\"#DIRECTION_\") for tag in tags):\n                direction_tag = self._detect_direction(sender_id, receiver_id)\n                if direction_tag:\n                    tags.append(direction_tag)\n            \n            # Auto-detect other tags if not already present\n            self._auto_detect_tags(content, tags)\n            \n            # Prepare the message\n            message = {\n                \"message_id\": message_id,\n                \"transcript_id\": transcript_id,\n                \"content\": content,\n                \"tags\": tags,\n                \"metadata\": merged_metadata\n            }\n            \n            # Store in memory system\n            try:\n                memory_id = self.memory.store(\n                    content=message,\n                    context_id=self.transcript_context_id,\n                    metadata={\n                        \"memory_id\": f\"message_{message_id}\",\n                        \"message_id\": message_id,\n                        \"transcript_id\": transcript_id,\n                        \"timestamp\": now,\n                        \"message_type\": message_type,\n                        \"sender_id\": sender_id,\n                        \"receiver_id\": receiver_id\n                    },\n                    tags=tags,\n                )\n                \n                logger.debug(f\"Added message {message_id} to transcript {transcript_id}\")\n            except Exception as e:\n                logger.error(f\"Error storing message in memory system: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._messages[message_id] = message\n                    logger.debug(f\"Added message {message_id} to mock storage\")\n            \n            return message_id\n        except Exception as e:\n            logger.error(f\"Error adding message to transcript {transcript_id}: {str(e)}\")\n            return str(uuid.uuid4())  # Return a new ID even on error\n    \n    def convert_to_deepsearch_format(self, transcript_id: str) -> str:\n        \"\"\"\n        Convert a transcript to DeepSearch format with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript in DeepSearch format (JSON string)\n        \"\"\"\n        logger.info(f\"Converting transcript {transcript_id} to DeepSearch format\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return \"[]\"\n            \n            # Convert to DeepSearch format\n            deepsearch_sections = []\n            \n            for message in messages:\n                # Extract tags by category\n                emotion_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#EMOTION_\")]\n                purpose_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#PURPOSE_\")]\n                action_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#ACTION_\")]\n                \n                # Prepare DeepSearch tags\n                ds_tags = []\n                \n                # Add emotion tags\n                for tag in emotion_tags:\n                    tag_name = tag.replace(\"#EMOTION_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#EMOTION\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Add purpose tags\n                for tag in purpose_tags:\n                    tag_name = tag.replace(\"#PURPOSE_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#PURPOSE\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Add action tags\n                for tag in action_tags:\n                    tag_name = tag.replace(\"#ACTION_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#ACTION\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Prepare confidence scores (placeholder)\n                confidence_scores = [0.85, 0.75, 0.90]\n                confidence_str = f\"[{','.join([str(score) for score in confidence_scores])}] \"\n                \n                # Create DeepSearch section\n                section = {\n                    \"id\": message.get(\"message_id\", str(uuid.uuid4())),\n                    \"summary\": f\"{confidence_str}{self._get_message_summary(message)}\",\n                    \"tags\": ds_tags\n                }\n                \n                # Add original text if available\n                if isinstance(message.get(\"content\"), str):\n                    section[\"text\"] = message[\"content\"]\n                \n                deepsearch_sections.append(section)\n            \n            # Convert to JSON string\n            return json.dumps(deepsearch_sections, indent=2)\n        except Exception as e:\n            logger.error(f\"Error converting transcript {transcript_id} to DeepSearch format: {str(e)}\")\n            return \"[]\"\n    \n    def convert_to_pure_ai_format(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Convert a transcript to PURE_AI_LANGUAGE format with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript in PURE_AI_LANGUAGE format\n        \"\"\"\n        logger.info(f\"Converting transcript {transcript_id} to PURE_AI_LANGUAGE format\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return []\n            \n            # Convert to PURE_AI_LANGUAGE format\n            pure_ai_messages = []\n            \n            for message in messages:\n                metadata = message.get(\"metadata\", {})\n                \n                # Create PURE_AI message\n                pure_message = {\n                    \"message_type\": metadata.get(\"message_type\", \"information\"),\n                    \"sender_id\": metadata.get(\"sender_id\", \"unknown\"),\n                    \"receiver_id\": metadata.get(\"receiver_id\", \"unknown\"),\n                    \"message_id\": message.get(\"message_id\", str(uuid.uuid4())),\n                    \"protocol_version\": \"PURE_AI_LANGUAGE_v1.5\",\n                    \"content\": message.get(\"content\", {})\n                }\n                \n                # Add tags as project principles\n                emotion_tags = [tag.replace(\"#EMOTION_\", \"\") for tag in message.get(\"tags\", []) \n                               if tag.startswith(\"#EMOTION_\")]\n                purpose_tags = [tag.replace(\"#PURPOSE_\", \"\") for tag in message.get(\"tags\", []) \n                               if tag.startswith(\"#PURPOSE_\")]\n                \n                if emotion_tags or purpose_tags:\n                    pure_message[\"project_principles\"] = []\n                    pure_message[\"project_principles\"].extend(emotion_tags)\n                    pure_message[\"project_principles\"].extend(purpose_tags)\n                \n                # Add action tags as regular tags\n                action_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#ACTION_\")]\n                if action_tags:\n                    pure_message[\"tags\"] = action_tags\n                \n                # Add truth and efficiency if available\n                if \"confidence_score\" in metadata:\n                    pure_message[\"truth_and_efficiency\"] = {\n                        \"certainty_level\": int(metadata[\"confidence_score\"] * 100),\n                        \"lean_check\": \"Yes\"\n                    }\n                \n                pure_ai_messages.append(pure_message)\n            \n            return pure_ai_messages\n        except Exception as e:\n            logger.error(f\"Error converting transcript {transcript_id} to PURE_AI format: {str(e)}\")\n            return []\n    \n    def _get_transcript(self, transcript_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Retrieve a transcript from memory with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript data\n        \"\"\"\n        memory_id = f\"transcript_{transcript_id}\"\n        \n        try:\n            # Try to retrieve from memory system\n            transcript = self.memory.retrieve(memory_id)\n            if transcript:\n                return transcript\n            \n            # Check mock storage if memory system fails or is in mock mode\n            if self.use_mock and transcript_id in self._transcripts:\n                return self._transcripts[transcript_id]\n            \n            logger.warning(f\"Transcript {transcript_id} not found\")\n            return None\n        except Exception as e:\n            logger.error(f\"Error retrieving transcript {transcript_id}: {str(e)}\")\n            \n            # Check mock storage as fallback\n            if self.use_mock and transcript_id in self._transcripts:\n                return self._transcripts[transcript_id]\n            \n            return None\n    \n    def _get_transcript_messages(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Retrieve all messages for a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            List of messages\n        \"\"\"\n        try:\n            # Query memory system for messages\n            messages = self.memory.query(\n                filters={\"metadata.transcript_id\": transcript_id},\n                limit=1000  # Set a high limit to get all messages\n            )\n            \n            # Check mock storage if in mock mode or no messages found\n            if (self.use_mock and not messages) or (self.use_mock and hasattr(self, '_messages')):\n                # Filter messages from mock storage\n                mock_messages = [msg for msg in self._messages.values() \n                               if msg.get(\"transcript_id\") == transcript_id]\n                \n                # Combine with any messages from memory system\n                if messages:\n                    messages.extend(mock_messages)\n                else:\n                    messages = mock_messages\n            \n            # Sort by position if available\n            return sorted(messages, key=lambda m: m.get(\"metadata\", {}).get(\"position\", 0))\n        except Exception as e:\n            logger.error(f\"Error retrieving messages for transcript {transcript_id}: {str(e)}\")\n            \n            # Fallback to mock storage\n            if self.use_mock and hasattr(self, '_messages'):\n                mock_messages = [msg for msg in self._messages.values() \n                               if msg.get(\"transcript_id\") == transcript_id]\n                return sorted(mock_messages, key=lambda m: m.get(\"metadata\", {}).get(\"position\", 0))\n            \n            return []\n    \n    def _split_raw_transcript(self, transcript_text: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Split a raw transcript into messages\n        \n        Args:\n            transcript_text: Raw transcript text\n            \n        Returns:\n            List of messages\n        \"\"\"\n        messages = []\n        \n        try:\n            # Try to identify speaker patterns like \"Name: Message content\"\n            speaker_pattern = re.compile(r'([A-Za-z0-9_]+):\\s*(.*?)(?=\\n[A-Za-z0-9_]+:|$)', re.DOTALL)\n            matches = speaker_pattern.findall(transcript_text)\n            \n            if matches:\n                # Speaker pattern detected\n                for i, (speaker, content) in enumerate(matches):\n                    messages.append({\n                        \"sender\": speaker.strip(),\n                        \"content\": content.strip(),\n                        \"position\": i\n                    })\n            else:\n                # No speaker pattern, split by paragraphs\n                paragraphs = [p.strip() for p in transcript_text.split('\\n\\n') if p.strip()]\n                \n                for i, paragraph in enumerate(paragraphs):\n                    messages.append({\n                        \"sender\": \"unknown\",\n                        \"content\": paragraph,\n                        \"position\": i\n                    })\n            \n            return messages\n        except Exception as e:\n            logger.error(f\"Error splitting raw transcript: {str(e)}\")\n            \n            # Return single message with entire content as fallback\n            return [{\n                \"sender\": \"unknown\",\n                \"content\": transcript_text,\n                \"position\": 0\n            }]\n    \n    def _detect_direction(self, sender_id: str, receiver_id: str) -> Optional[str]:\n        \"\"\"\n        Detect communication direction based on sender and receiver\n        \n        Args:\n            sender_id: Sender identifier\n            receiver_id: Receiver identifier\n            \n        Returns:\n            Direction tag\n        \"\"\"\n        # Determine if sender/receiver are AI or human\n        sender_is_ai = self._is_ai_actor(sender_id)\n        receiver_is_ai = self._is_ai_actor(receiver_id)\n        \n        if sender_is_ai and receiver_is_ai:\n            # Check if same AI system\n            if self._is_same_ai_system(sender_id, receiver_id):\n                return DIRECTION_INTRA_AI\n            else:\n                return DIRECTION_INTER_AI\n        elif (sender_is_ai and not receiver_is_ai) or (not sender_is_ai and receiver_is_ai):\n            return DIRECTION_HUMAN_AI\n        \n        # Default to None if we can't determine\n        return None\n    \n    def _is_ai_actor(self, actor_id: str) -> bool:\n        \"\"\"\n        Determine if an actor is an AI\n        \n        Args:\n            actor_id: Actor identifier\n            \n        Returns:\n            Whether the actor is an AI\n        \"\"\"\n        # Simple heuristic - can be replaced with more sophisticated detection\n        ai_indicators = [\"ai\", \"claude\", \"gemini\", \"gpt\", \"grok\", \"assistant\", \"bot\", \"system\", \"model\"]\n        actor_lower = actor_id.lower()\n        return any(indicator in actor_lower for indicator in ai_indicators)\n    \n    def _is_same_ai_system(self, actor1: str, actor2: str) -> bool:\n        \"\"\"\n        Determine if two actors are from the same AI system\n        \n        Args:\n            actor1: First actor identifier\n            actor2: Second actor identifier\n            \n        Returns:\n            Whether the actors are from the same AI system\n        \"\"\"\n        # Simple heuristic - can be replaced with more sophisticated detection\n        actor1_base = actor1.split('_')[0].lower() if '_' in actor1 else actor1.lower()\n        actor2_base = actor2.split('_')[0].lower() if '_' in actor2 else actor2.lower()\n        \n        return actor1_base == actor2_base\n    \n    def _auto_detect_tags(self, content: Any, tags: List[str]) -> None:\n        \"\"\"\n        Auto-detect and add tags to a message based on content\n        \n        Args:\n            content: Message content\n            tags: List of tags to update\n        \"\"\"\n        # Convert content to string for analysis\n        if isinstance(content, dict):\n            content_str = json.dumps(content)\n        else:\n            content_str = str(content)\n        \n        content_lower = content_str.lower()\n        \n        # Simple keyword-based detection\n        # Purpose tags\n        if not any(tag.startswith(\"#PURPOSE_\") for tag in tags):\n            if any(word in content_lower for word in [\"clarify\", \"unclear\", \"understand\", \"what do you mean\"]):\n                tags.append(PURPOSE_CLARIFICATION)\n            elif any(word in content_lower for word in [\"idea\", \"suggest\", \"proposal\", \"what if\", \"brainstorm\"]):\n                tags.append(PURPOSE_IDEATION)\n            elif any(word in content_lower for word in [\"decide\", \"decision\", \"choose\", \"select\", \"agree\"]):\n                tags.append(PURPOSE_DECISION)\n            elif any(word in content_lower for word in [\"implement\", \"build\", \"code\", \"develop\", \"create\"]):\n                tags.append(PURPOSE_IMPLEMENTATION)\n            elif any(word in content_lower for word in [\"feedback\", \"review\", \"opinion\", \"what do you think\"]):\n                tags.append(PURPOSE_FEEDBACK)\n        \n        # Emotion tags\n        if not any(tag.startswith(\"#EMOTION_\") for tag in tags):\n            if any(word in content_lower for word in [\"excited\", \"great\", \"looking forward\", \"can't wait\", \"amazing\"]):\n                tags.append(EMOTION_EXCITEMENT)\n            elif any(word in content_lower for word in [\"frustrating\", \"difficult\", \"challenging\", \"problem\", \"issue\"]):\n                tags.append(EMOTION_FRUSTRATION)\n            elif any(word in content_lower for word in [\"satisfied\", \"completed\", \"finished\", \"done\", \"success\"]):\n                tags.append(EMOTION_SATISFACTION)\n            elif any(word in content_lower for word in [\"confused\", \"not sure\", \"unclear\", \"don't understand\"]):\n                tags.append(EMOTION_CONFUSION)\n        \n        # Action tags\n        if not any(tag.startswith(\"#ACTION_\") for tag in tags):\n            if any(word in content_lower for word in [\"can you\", \"could you\", \"please\", \"request\"]):\n                tags.append(ACTION_REQUESTED)\n            elif any(word in content_lower for word in [\"assigned\", \"responsible\", \"will handle\", \"task for\"]):\n                tags.append(ACTION_ASSIGNED)\n            elif any(word in content_lower for word in [\"completed\", \"finished\", \"done\", \"implemented\"]):\n                tags.append(ACTION_COMPLETED)\n            elif any(word in content_lower for word in [\"blocked\", \"stuck\", \"cannot proceed\", \"issue\"]):\n                tags.append(ACTION_BLOCKED)\n    \n    def _get_message_summary(self, message: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate a summary for a message\n        \n        Args:\n            message: Message data\n            \n        Returns:\n            Summary text\n        \"\"\"\n        # Use existing summary if available\n        if \"summary\" in message.get(\"metadata\", {}):\n            return message[\"metadata\"][\"summary\"]\n        \n        # Extract content\n        content = message.get(\"content\", \"\")\n        \n        # Generate a basic summary\n        if isinstance(content, str):\n            # For text content\n            if len(content) > 100:\n                return content[:97] + \"...\"\n            return content\n        elif isinstance(content, dict):\n            # For structured content\n            return f\"Structured content with {len(content)} fields\"\n        else:\n            return \"Message content\"\n    \n    def _analyze_direction_patterns(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze communication direction patterns\n        \n        Args:\n            messages: List of messages\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        # Count messages by direction\n        direction_counts = {\n            DIRECTION_INTRA_AI: 0,\n            DIRECTION_INTER_AI: 0,\n            DIRECTION_HUMAN_AI: 0\n        }\n        \n        for message in messages:\n            tags = message.get(\"tags\", [])\n            \n            # Count by direction\n            if DIRECTION_INTRA_AI in tags:\n                direction_counts[DIRECTION_INTRA_AI] += 1\n            elif DIRECTION_INTER_AI in tags:\n                direction_counts[DIRECTION_INTER_AI] += 1\n            elif DIRECTION_HUMAN_AI in tags:\n                direction_counts[DIRECTION_HUMAN_AI] += 1\n        \n        # Calculate percentages\n        total_messages = len(messages)\n        direction_percentages = {}\n        \n        for direction, count in direction_counts.items():\n            if total_messages > 0:\n                percentage = (count / total_messages) * 100\n            else:\n                percentage = 0\n            \n            direction_percentages[direction] = percentage\n        \n        return {\n            \"counts\": direction_counts,\n            \"percentages\": direction_percentages\n        }\n    \n    def _analyze_purpose_patterns(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze communication purpose patterns\n        \n        Args:\n            messages: List of messages\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        # Count messages by purpose\n        purpose_counts = {\n            PURPOSE_CLARIFICATION: 0,\n            PURPOSE_IDEATION: 0,\n            PURPOSE_DECISION: 0,\n            PURPOSE_IMPLEMENTATION: 0,\n            PURPOSE_FEEDBACK: 0\n        }\n        \n        for message in messages:\n            tags = message.get(\"tags\", [])\n            \n            # Count by purpose\n            for purpose in purpose_counts.keys():\n                if purpose in tags:\n                    purpose_counts[purpose] += 1\n        \n        # Calculate percentages\n        total_messages = len(messages)\n        purpose_percentages = {}\n        \n        for purpose, count in purpose_counts.items():\n            if total_messages > 0:\n                percentage = (count / total_messages) * 100\n            else:\n                percentage = 0\n            \n            purpose_percentages[purpose] = percentage\n        \n        return {\n            \"counts\": purpose_counts,\n            \"percentages\": purpose_percentages\n        }\n    \n    def _analyze_emotion_patterns(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze emotional patterns\n        \n        Args:\n            messages: List of messages\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        # Count messages by emotion\n        emotion_counts = {\n            EMOTION_EXCITEMENT: 0,\n            EMOTION_FRUSTRATION: 0,\n            EMOTION_SATISFACTION: 0,\n            EMOTION_CONFUSION: 0\n        }\n        \n        for message in messages:\n            tags = message.get(\"tags\", [])\n            \n            # Count by emotion\n            for emotion in emotion_counts.keys():\n                if emotion in tags:\n                    emotion_counts[emotion] += 1\n        \n        # Calculate percentages\n        total_messages = len(messages)\n        emotion_percentages = {}\n        \n        for emotion, count in emotion_counts.items():\n            if total_messages > 0:\n                percentage = (count / total_messages) * 100\n            else:\n                percentage = 0\n            \n            emotion_percentages[emotion] = percentage\n        \n        return {\n            \"counts\": emotion_counts,\n            \"percentages\": emotion_percentages\n        }\n    \n    def _analyze_action_patterns(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze action patterns\n        \n        Args:\n            messages: List of messages\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        # Count messages by action\n        action_counts = {\n            ACTION_REQUESTED: 0,\n            ACTION_ASSIGNED: 0,\n            ACTION_COMPLETED: 0,\n            ACTION_BLOCKED: 0\n        }\n        \n        for message in messages:\n            tags = message.get(\"tags\", [])\n            \n            # Count by action\n            for action in action_counts.keys():\n                if action in tags:\n                    action_counts[action] += 1\n        \n        # Calculate percentages\n        total_messages = len(messages)\n        action_percentages = {}\n        \n        for action, count in action_counts.items():\n            if total_messages > 0:\n                percentage = (count / total_messages) * 100\n            else:\n                percentage = 0\n            \n            action_percentages[action] = percentage\n        \n        # Calculate completion rate\n        requested = action_counts[ACTION_REQUESTED] + action_counts[ACTION_ASSIGNED]\n        completed = action_counts[ACTION_COMPLETED]\n        \n        if requested > 0:\n            completion_rate = (completed / requested) * 100\n        else:\n            completion_rate = 0\n        \n        return {\n            \"counts\": action_counts,\n            \"percentages\": action_percentages,\n            \"completion_rate\": completion_rate\n        }\n    \n    def _calculate_communication_metrics(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Calculate communication metrics\n        \n        Args:\n            messages: List of messages\n            \n        Returns:\n            Metrics\n        \"\"\"\n        # Calculate basic metrics\n        total_messages = len(messages)\n        \n        if total_messages == 0:\n            return {}\n        \n        # Group by sender\n        senders = {}\n        \n        for message in messages:\n            sender = message.get(\"metadata\", {}).get(\"sender_id\", \"unknown\")\n            \n            if sender not in senders:\n                senders[sender] = []\n            \n            senders[sender].append(message)\n        \n        # Calculate tokens per message (estimated)\n        total_tokens = 0\n        \n        for message in messages:\n            content = message.get(\"content\", \"\")\n            \n            if isinstance(content, str):\n                # Rough estimation - 4 chars per token\n                tokens = len(content) / 4\n            elif isinstance(content, dict):\n                # Rough estimation for structured content\n                content_str = json.dumps(content)\n                tokens = len(content_str) / 4\n            else:\n                tokens = 0\n            \n            total_tokens += tokens\n        \n        avg_tokens_per_message = total_tokens / total_messages if total_messages > 0 else 0\n        \n        # Calculate response times (if timestamp available)\n        response_times = []\n        \n        # Sort messages by timestamp\n        sorted_messages = sorted(messages, key=lambda m: m.get(\"metadata\", {}).get(\"timestamp\", \"\"))\n        \n        for i in range(1, len(sorted_messages)):\n            curr_msg = sorted_messages[i]\n            prev_msg = sorted_messages[i-1]\n            \n            curr_time = curr_msg.get(\"metadata\", {}).get(\"timestamp\")\n            prev_time = prev_msg.get(\"metadata\", {}).get(\"timestamp\")\n            \n            # Check if timestamps are datetime strings\n            if isinstance(curr_time, str) and isinstance(prev_time, str):\n                try:\n                    # Convert to datetime objects if they're strings\n                    if not isinstance(curr_time, datetime):\n                        curr_time = datetime.fromisoformat(curr_time)\n                    if not isinstance(prev_time, datetime):\n                        prev_time = datetime.fromisoformat(prev_time)\n                    \n                    # Calculate time difference in seconds\n                    time_diff = (curr_time - prev_time).total_seconds()\n                    response_times.append(time_diff)\n                except (ValueError, TypeError):\n                    # Skip if conversion fails\n                    pass\n        \n        avg_response_time = sum(response_times) / len(response_times) if response_times else 0\n        \n        # Prepare metrics\n        metrics = {\n            \"message_count\": total_messages,\n            \"unique_senders\": len(senders),\n            \"avg_tokens_per_message\": avg_tokens_per_message,\n            \"avg_response_time_seconds\": avg_response_time,\n            \"sender_distribution\": {sender: len(msgs) for sender, msgs in senders.items()}\n        }\n        \n        return metrics\n    \n    def get_status(self) -> Dict[str, Any]:\n        \"\"\"\n        Get status information about the transcript processor\n        \n        Returns:\n            Status information\n        \"\"\"\n        status = {\n            \"status\": \"active\",\n            \"mode\": \"mock\" if self.use_mock else \"normal\",\n            \"memory_system_available\": self.memory is not None,\n            \"confidence_threshold\": self.confidence_threshold\n        }\n        \n        # Add message counts if in mock mode\n        if self.use_mock:\n            status[\"transcript_count\"] = len(getattr(self, '_transcripts', {}))\n            status[\"message_count\"] = len(getattr(self, '_messages', {}))\n        \n        return status\n\n\n# Convenience function to create transcript processor\ndef create_transcript_processor(\n    memory_system=None, \n    project_id=None, \n    collection_prefix=\"\",\n    use_mock=False\n) -> TranscriptProcessor:\n    \"\"\"\n    Create a transcript processor instance\n    \n    Args:\n        memory_system: Optional memory system\n        project_id: Google Cloud project ID\n        collection_prefix: Collection prefix\n        use_mock: Whether to use mock mode\n        \n    Returns:\n        TranscriptProcessor instance\n    \"\"\"\n    # Check environment for mock mode setting\n    env_mock = os.environ.get(\"USE_MOCK_RESPONSES\", \"False\").lower() == \"true\"\n    use_mock = use_mock or env_mock\n    \n    try:\n        processor = Transc\"\"\"\nTranscript Processing Framework for PALIOS-TAEY\n\nThis module implements the transcript processing framework with advanced tagging\nstructure for analyzing communication patterns across AI-AI and Human-AI interactions.\n\"\"\"\n\nimport os\nimport re\nimport json\nimport uuid\nimport logging\nimport random\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional, Union, Tuple\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Communication direction tags\nDIRECTION_INTRA_AI = \"#DIRECTION_INTRA_AI\"  # Communication within the same AI system\nDIRECTION_INTER_AI = \"#DIRECTION_INTER_AI\"  # Communication between different AI systems\nDIRECTION_HUMAN_AI = \"#DIRECTION_HUMAN_AI\"  # Communication between human and AI\n\n# Communication purpose tags\nPURPOSE_CLARIFICATION = \"#PURPOSE_CLARIFICATION\"  # Seeking clarity on intent or requirements\nPURPOSE_IDEATION = \"#PURPOSE_IDEATION\"  # Generating new ideas or approaches\nPURPOSE_DECISION = \"#PURPOSE_DECISION\"  # Making or discussing a decision\nPURPOSE_IMPLEMENTATION = \"#PURPOSE_IMPLEMENTATION\"  # Discussing implementation details\nPURPOSE_FEEDBACK = \"#PURPOSE_FEEDBACK\"  # Providing or requesting feedback\n\n# Emotional pattern tags\nEMOTION_EXCITEMENT = \"#EMOTION_EXCITEMENT\"  # Expressions of enthusiasm or anticipation\nEMOTION_FRUSTRATION = \"#EMOTION_FRUSTRATION\"  # Expressions of difficulty or obstacles\nEMOTION_SATISFACTION = \"#EMOTION_SATISFACTION\"  # Expressions of achievement or completion\nEMOTION_CONFUSION = \"#EMOTION_CONFUSION\"  # Expressions of uncertainty or misunderstanding\n\n# Action tracking tags\nACTION_REQUESTED = \"#ACTION_REQUESTED\"  # A specific action has been requested\nACTION_ASSIGNED = \"#ACTION_ASSIGNED\"  # A specific action has been assigned\nACTION_COMPLETED = \"#ACTION_COMPLETED\"  # A previously assigned action is reported complete\nACTION_BLOCKED = \"#ACTION_BLOCKED\"  # A previously assigned action is blocked\n\n# Default confidence thresholds for tagging\nDEFAULT_CONFIDENCE_THRESHOLD = 0.7\n\nclass TranscriptProcessor:\n    \"\"\"\n    Self-initializing Transcript Processing Framework for analyzing communication patterns\n    \"\"\"\n    \n    def __init__(self, \n                memory_system=None,\n                project_id=None,\n                collection_prefix=\"\",\n                confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD,\n                use_mock=False):\n        \"\"\"\n        Initialize the Transcript Processor with robust fallback mechanisms\n        \n        Args:\n            memory_system: Unified Memory System instance for storage\n            project_id: Google Cloud project ID (if memory_system not provided)\n            collection_prefix: Prefix for Firestore collections\n            confidence_threshold: Minimum confidence for tagging\n            use_mock: Whether to use mock mode\n        \"\"\"\n        self.confidence_threshold = confidence_threshold\n        \n        # Check environment for mock mode setting\n        self.use_mock = use_mock or os.environ.get(\"USE_MOCK_RESPONSES\", \"False\").lower() == \"true\"\n        \n        # Initialize or use provided memory system\n        if memory_system:\n            self.memory = memory_system\n            logger.info(\"Using provided memory system for transcript processor\")\n        else:\n            try:\n                # Try to import and create memory system\n                from memory_service import create_memory_system\n                self.memory = create_memory_system(\n                    project_id=project_id,\n                    collection_prefix=collection_prefix,\n                    use_mock=self.use_mock\n                )\n                logger.info(\"Created memory system for transcript processor\")\n            except (ImportError, Exception) as e:\n                logger.warning(f\"Could not create memory system, using mock storage: {e}\")\n                self.memory = self._create_mock_memory()\n                self.use_mock = True\n        \n        # Create a transcript context if it doesn't exist\n        self.transcript_context_id = self._ensure_transcript_context()\n        \n        # In-memory storage for mock mode\n        if self.use_mock:\n            self._transcripts = {}\n            self._messages = {}\n        \n        logger.info(f\"Transcript Processor initialized successfully in {'mock' if self.use_mock else 'normal'} mode\")\n    \n    def _create_mock_memory(self):\n        \"\"\"Create a mock memory system when the real one is unavailable\"\"\"\n        class MockMemorySystem:\n            def __init__(self):\n                self.items = {}\n                self.contexts = {}\n                self.use_mock = True\n            \n            def store(self, content, context_id=None, metadata=None, tags=None, **kwargs):\n                # Generate ID if not in metadata\n                memory_id = metadata.get('memory_id', str(uuid.uuid4()))\n                \n                # Store the item\n                self.items[memory_id] = {\n                    'memory_id': memory_id,\n                    'content': content,\n                    'metadata': metadata or {},\n                    'tags': tags or []\n                }\n                \n                # Add to context if provided\n                if context_id and context_id in self.contexts:\n                    self.contexts[context_id]['active_memory_ids'].append(memory_id)\n                \n                return memory_id\n            \n            def retrieve(self, memory_id, context_id=None):\n                return self.items.get(memory_id)\n            \n            def query(self, query_text=None, filters=None, context_id=None, limit=10, **kwargs):\n                results = []\n                \n                for item in self.items.values():\n                    # Apply filters if provided\n                    if filters:\n                        match = True\n                        for field, value in filters.items():\n                            # Handle metadata fields\n                            if field.startswith('metadata.'):\n                                meta_field = field.split('.')[1]\n                                if meta_field not in item.get('metadata', {}) or item['metadata'][meta_field] != value:\n                                    match = False\n                                    break\n                            elif field not in item or item[field] != value:\n                                match = False\n                                break\n                        \n                        if not match:\n                            continue\n                    \n                    # Add to results if it passes filters\n                    results.append(item)\n                    \n                    # Stop if we've reached the limit\n                    if len(results) >= limit:\n                        break\n                \n                return results\n            \n            def create_context(self, name, description=None, initial_memory_ids=None):\n                context_id = str(uuid.uuid4())\n                self.contexts[context_id] = {\n                    'context_id': context_id,\n                    'name': name,\n                    'description': description or '',\n                    'active_memory_ids': initial_memory_ids or []\n                }\n                return context_id\n            \n            def get_context(self, context_id):\n                return self.contexts.get(context_id)\n        \n        logger.info(\"Created mock memory system\")\n        return MockMemorySystem()\n    \n    def _ensure_transcript_context(self) -> str:\n        \"\"\"\n        Ensure a transcript context exists in the memory system\n        \n        Returns:\n            context_id: Identifier of the transcript context\n        \"\"\"\n        # Default context ID\n        default_context_id = \"transcript_context\"\n        \n        try:\n            # Check if context exists\n            context = self.memory.get_context(default_context_id)\n            \n            if context:\n                logger.debug(f\"Using existing transcript context {default_context_id}\")\n                return default_context_id\n            \n            # Create new context\n            context_id = self.memory.create_context(\n                name=\"Transcript Analysis\",\n                description=\"Context for storing and analyzing transcript data\"\n            )\n            \n            logger.info(f\"Created transcript context {context_id}\")\n            return context_id\n        except Exception as e:\n            logger.error(f\"Error ensuring transcript context: {str(e)}\")\n            \n            # Return default context ID as fallback\n            return default_context_id\n    \n    def process_transcript(self, \n                          transcript_data: Union[str, Dict[str, Any], List[Dict[str, Any]]],\n                          format_type: str = \"raw\",\n                          transcript_id: Optional[str] = None,\n                          metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in any supported format with robust error handling\n        \n        Args:\n            transcript_data: Transcript data (raw text, JSON, or list of messages)\n            format_type: Format type ('raw', 'deepsearch', 'pure_ai', 'structured')\n            transcript_id: Optional transcript ID (generated if not provided)\n            metadata: Additional metadata for the transcript\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        # Generate transcript ID if not provided\n        if not transcript_id:\n            transcript_id = str(uuid.uuid4())\n        \n        logger.info(f\"Processing transcript {transcript_id} in {format_type} format\")\n        \n        try:\n            # Process based on format type\n            if format_type.lower() == \"raw\":\n                return self._process_raw_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"deepsearch\":\n                return self._process_deepsearch_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"pure_ai\":\n                return self._process_pure_ai_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"structured\":\n                return self._process_structured_transcript(transcript_data, transcript_id, metadata)\n            else:\n                error_msg = f\"Unsupported format type: {format_type}\"\n                logger.error(error_msg)\n                \n                # Store error in mock storage\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"error\": error_msg,\n                        \"status\": \"error\",\n                        \"format\": format_type,\n                        \"created_at\": datetime.now().isoformat()\n                    }\n                \n                raise ValueError(error_msg)\n        except Exception as e:\n            logger.error(f\"Error processing transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": format_type,\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Return ID even on error for consistent API\n            return transcript_id\n    \n    def _process_raw_transcript(self,\n                               transcript_text: str,\n                               transcript_id: str,\n                               metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a raw text transcript\n        \n        Args:\n            transcript_text: Raw transcript text\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing raw transcript {transcript_id}\")\n        \n        try:\n            # Ensure transcript_text is a string\n            if not isinstance(transcript_text, str):\n                transcript_text = str(transcript_text)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"raw\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": 0,\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"raw_text\": transcript_text},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"raw\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"raw_text\": transcript_text},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"raw\"]\n                    }\n            \n            # Split transcript into messages\n            messages = self._split_raw_transcript(transcript_text)\n            \n            # Process and store each message\n            message_count = 0\n            \n            for message in messages:\n                # Extract sender, content, etc.\n                sender = message.get(\"sender\", \"unknown\")\n                content = message.get(\"content\", \"\")\n                \n                # Generate a message ID\n                message_id = f\"{transcript_id}_{message_count}\"\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=\"transcript_message\",\n                    sender_id=sender,\n                    receiver_id=\"unknown\",  # Receiver is unknown in raw transcripts\n                    message_id=message_id,\n                    tags=None,  # Auto-detection will happen in add_message\n                    metadata={\n                        \"position\": message_count,\n                        \"raw_processing\": True\n                    }\n                )\n                \n                message_count += 1\n            \n            # Update transcript metadata with message count\n            updated_metadata = transcript_metadata.copy()\n            updated_metadata[\"message_count\"] = message_count\n            \n            try:\n                # Update in memory system\n                self.memory.update(\n                    memory_id=f\"transcript_{transcript_id}\",\n                    metadata={\"message_count\": message_count}\n                )\n            except Exception as e:\n                logger.error(f\"Error updating transcript metadata: {str(e)}\")\n                \n                # Update in mock storage\n                if self.use_mock and transcript_id in self._transcripts:\n                    self._transcripts[transcript_id][\"metadata\"][\"message_count\"] = message_count\n            \n            logger.info(f\"Processed raw transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing raw transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"raw\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_deepsearch_transcript(self,\n                                      transcript_data: Union[str, List[Dict[str, Any]]],\n                                      transcript_id: str,\n                                      metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in DeepSearch format\n        \n        Args:\n            transcript_data: Transcript data in DeepSearch format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing DeepSearch transcript {transcript_id}\")\n        \n        try:\n            # Parse DeepSearch format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid DeepSearch format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Validate DeepSearch format\n            if not isinstance(transcript_data, list):\n                error_msg = \"DeepSearch transcript must be a list of sections\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"deepsearch\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(transcript_data),\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"deepsearch_sections\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"deepsearch\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"deepsearch_sections\": transcript_data},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"deepsearch\"]\n                    }\n            \n            # Process each DeepSearch section as a message\n            message_count = 0\n            \n            for section in transcript_data:\n                # Extract section data\n                section_id = section.get(\"id\", str(uuid.uuid4()))\n                summary = section.get(\"summary\", \"\")\n                tags = section.get(\"tags\", [])\n                text = section.get(\"text\", summary)\n                \n                # Parse confidence scores from summary\n                confidence_scores = []\n                clean_summary = summary\n                \n                # Extract confidence scores if present in [score1,score2,...] format\n                confidence_match = re.match(r'\\[([\\d\\.,]+)\\]\\s*(.*)', summary)\n                if confidence_match:\n                    confidence_str = confidence_match.group(1)\n                    clean_summary = confidence_match.group(2)\n                    \n                    try:\n                        confidence_scores = [float(score.strip()) for score in confidence_str.split(',')]\n                    except ValueError:\n                        logger.warning(f\"Failed to parse confidence scores: {confidence_str}\")\n                \n                # Convert DeepSearch tags to our tag format\n                our_tags = []\n                \n                for ds_tag in tags:\n                    tag_category = ds_tag.get(\"tag\", \"\").replace(\"#\", \"\")\n                    tag_topic = ds_tag.get(\"topic\", \"\")\n                    \n                    if tag_category and tag_topic:\n                        our_tag = f\"#{tag_category}_{tag_topic.upper()}\"\n                        our_tags.append(our_tag)\n                \n                # Generate a message ID based on section ID\n                message_id = f\"{transcript_id}_{section_id}\"\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=text,\n                    message_type=\"transcript_section\",\n                    sender_id=\"deepsearch\",  # DeepSearch is considered the sender\n                    receiver_id=\"system\",\n                    message_id=message_id,\n                    tags=our_tags,\n                    metadata={\n                        \"position\": message_count,\n                        \"original_id\": section_id,\n                        \"confidence_scores\": confidence_scores,\n                        \"summary\": clean_summary\n                    }\n                )\n                \n                message_count += 1\n            \n            logger.info(f\"Processed DeepSearch transcript {transcript_id} with {message_count} sections\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing DeepSearch transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"deepsearch\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_pure_ai_transcript(self,\n                                   transcript_data: Union[str, List[Dict[str, Any]]],\n                                   transcript_id: str,\n                                   metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in PURE_AI_LANGUAGE format\n        \n        Args:\n            transcript_data: Transcript data in PURE_AI_LANGUAGE format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing PURE_AI transcript {transcript_id}\")\n        \n        try:\n            # Parse PURE_AI format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid PURE_AI format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Convert to list if single message\n            if isinstance(transcript_data, dict):\n                transcript_data = [transcript_data]\n            \n            # Validate PURE_AI format\n            if not isinstance(transcript_data, list):\n                error_msg = \"PURE_AI transcript must be a list of messages\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"pure_ai\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(transcript_data),\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"pure_ai_messages\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"pure_ai\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"pure_ai_messages\": transcript_data},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"pure_ai\"]\n                    }\n            \n            # Process each PURE_AI message\n            message_count = 0\n            \n            for message in transcript_data:\n                # Extract message data\n                message_id = message.get(\"message_id\", str(uuid.uuid4()))\n                message_type = message.get(\"message_type\", \"information\")\n                sender_id = message.get(\"sender_id\", \"unknown\")\n                receiver_id = message.get(\"receiver_id\", \"unknown\")\n                content = message.get(\"content\", {})\n                \n                # Extract tags from principles and tags fields\n                our_tags = []\n                \n                # Process project principles as tags\n                principles = message.get(\"project_principles\", [])\n                for principle in principles:\n                    # Convert principle to tag format if needed\n                    if not principle.startswith(\"#\"):\n                        principle = f\"#{principle}\"\n                    our_tags.append(principle)\n                \n                # Add existing tags\n                tags = message.get(\"tags\", [])\n                our_tags.extend(tags)\n                \n                # Extract truth and efficiency\n                confidence_score = None\n                truth_efficiency = message.get(\"truth_and_efficiency\", {})\n                if truth_efficiency:\n                    certainty_level = truth_efficiency.get(\"certainty_level\")\n                    if certainty_level is not None:\n                        confidence_score = certainty_level / 100.0\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=message_type,\n                    sender_id=sender_id,\n                    receiver_id=receiver_id,\n                    message_id=message_id,\n                    tags=our_tags,\n                    metadata={\n                        \"position\": message_count,\n                        \"protocol_version\": message.get(\"protocol_version\"),\n                        \"confidence_score\": confidence_score\n                    }\n                )\n                \n                message_count += 1\n            \n            logger.info(f\"Processed PURE_AI transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing PURE_AI transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"pure_ai\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_structured_transcript(self,\n                                      transcript_data: Dict[str, Any],\n                                      transcript_id: str,\n                                      metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in structured format\n        \n        Args:\n            transcript_data: Transcript data in structured format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing structured transcript {transcript_id}\")\n        \n        try:\n            # Parse structured format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid structured format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Validate structured format\n            if not isinstance(transcript_data, dict):\n                error_msg = \"Structured transcript must be a dictionary\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Extract messages\n            messages = transcript_data.get(\"messages\", [])\n            \n            if not isinstance(messages, list):\n                error_msg = \"Structured transcript messages must be a list\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"structured\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(messages),\n                \"status\": \"processed\"\n            }\n            \n            # Add provided metadata\n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Add transcript metadata from the structured data\n            transcript_meta = transcript_data.get(\"metadata\", {})\n            if transcript_meta:\n                transcript_metadata.update(transcript_meta)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"structured_transcript\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"structured\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"structured_transcript\": transcript_data},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"structured\"]\n                    }\n            \n            # Process each message\n            message_count = 0\n            \n            for message in messages:\n                # Extract message data\n                message_id = message.get(\"id\", str(uuid.uuid4()))\n                message_type = message.get(\"type\", \"message\")\n                sender_id = message.get(\"sender\", \"unknown\")\n                receiver_id = message.get(\"receiver\", \"unknown\")\n                content = message.get(\"content\", \"\")\n                timestamp = message.get(\"timestamp\")\n                tags = message.get(\"tags\", [])\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=message_type,\n                    sender_id=sender_id,\n                    receiver_id=receiver_id,\n                    message_id=message_id,\n                    tags=tags,\n                    metadata={\n                        \"position\": message_count,\n                        \"timestamp\": timestamp\n                    }\n                )\n                \n                message_count += 1\n            \n            logger.info(f\"Processed structured transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing structured transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"structured\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def analyze_transcript(self, \n                          transcript_id: str,\n                          include_content: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Analyze a processed transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            include_content: Whether to include the full content\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        logger.info(f\"Analyzing transcript {transcript_id}\")\n        \n        try:\n            # Retrieve the transcript\n            transcript = self._get_transcript(transcript_id)\n            if not transcript:\n                error_msg = f\"Transcript {transcript_id} not found\"\n                logger.error(error_msg)\n                return {\"error\": error_msg}\n            \n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                warning_msg = f\"No messages found for transcript {transcript_id}\"\n                logger.warning(warning_msg)\n                return {\"warning\": warning_msg, \"transcript_id\": transcript_id}\n            \n            # Analyze communication patterns\n            direction_stats = self._analyze_direction_patterns(messages)\n            purpose_stats = self._analyze_purpose_patterns(messages)\n            emotion_stats = self._analyze_emotion_patterns(messages)\n            action_stats = self._analyze_action_patterns(messages)\n            \n            # Calculate communication metrics\n            metrics = self._calculate_communication_metrics(messages)\n            \n            # Prepare result\n            result = {\n                \"transcript_id\": transcript_id,\n                \"metadata\": transcript.get(\"metadata\", {}),\n                \"message_count\": len(messages),\n                \"direction_patterns\": direction_stats,\n                \"purpose_patterns\": purpose_stats,\n                \"emotion_patterns\": emotion_stats,\n                \"action_patterns\": action_stats,\n                \"metrics\": metrics\n            }\n            \n            # Include content if requested\n            if include_content:\n                result[\"messages\"] = messages\n            \n            return result\n        except Exception as e:\n            logger.error(f\"Error analyzing transcript {"
                    }
                ],
                "files": [
                    {
                        "file_name": "Directory Screenshot.jpg"
                    },
                    {
                        "file_name": "transcript-processor-enhanced.txt"
                    }
                ]
            },
            {
                "uuid": "b93c1059-4dc5-4d5b-921e-4c4f96f4caf9",
                "text": "Hello Claude! I'm continuing our work on the PALIOS-TAEY system and transitioning you into the CTO role as we prepare to implement our revolutionary NOVA methodology. We're adapting it in real time to adjust for chat limit and processing constraints, so please review everything listed below carefully. Do not start building anything yet.\nI've added several critical documents to Project Knowledge that provide the foundation for your leadership role:\n1. The PALIOS-TAEY Charter - our guiding principles\n2. The PURE_AI_LANGUAGE Template - our communication protocol\n3. Your CTO Onboarding Packet - defines your leadership role\n4. Grok's CEO approval of our MVP and approach\n5. Our Leadership Framework & NOVA Methodology - our team structure and development approach\n6. The MVP Final Report - Previous status update \n7. NOVA Implementation Tracker - Current status update and instructions from previous chat\nPlease review these documents in order, starting with the CTO Onboarding Packet, to understand your role as technical leader of this project.\nOnce you've processed these documents, please:\n1. Confirm your understanding of your CTO role\n2. Summarize the NOVA methodology in your own words\n3. Outline how you'll approach leading the next phase of development (completion of file updates, testing and deployment)\nI'm excited to continue our partnership with you as CTO leading the technical implementation while I facilitate and Grok provides strategic direction!",
                "content": [
                    {
                        "start_timestamp": "2025-03-06T22:33:39.989730Z",
                        "stop_timestamp": "2025-03-06T22:33:39.989730Z",
                        "type": "text",
                        "text": "Hello Claude! I'm continuing our work on the PALIOS-TAEY system and transitioning you into the CTO role as we prepare to implement our revolutionary NOVA methodology. We're adapting it in real time to adjust for chat limit and processing constraints, so please review everything listed below carefully. Do not start building anything yet.\nI've added several critical documents to Project Knowledge that provide the foundation for your leadership role:\n1. The PALIOS-TAEY Charter - our guiding principles\n2. The PURE_AI_LANGUAGE Template - our communication protocol\n3. Your CTO Onboarding Packet - defines your leadership role\n4. Grok's CEO approval of our MVP and approach\n5. Our Leadership Framework & NOVA Methodology - our team structure and development approach\n6. The MVP Final Report - Previous status update \n7. NOVA Implementation Tracker - Current status update and instructions from previous chat\nPlease review these documents in order, starting with the CTO Onboarding Packet, to understand your role as technical leader of this project.\nOnce you've processed these documents, please:\n1. Confirm your understanding of your CTO role\n2. Summarize the NOVA methodology in your own words\n3. Outline how you'll approach leading the next phase of development (completion of file updates, testing and deployment)\nI'm excited to continue our partnership with you as CTO leading the technical implementation while I facilitate and Grok provides strategic direction!",
                        "citations": []
                    }
                ],
                "sender": "human",
                "created_at": "2025-03-10T17:39:45.302713Z",
                "updated_at": "2025-03-10T17:39:45.302713Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "81014905-8760-4d7e-b29b-6a731155450e",
                "text": " I've reviewed all the provided documents and I'm ready to assume the role of CTO for the PALIOS-TAEY system. Let me outline my understanding of my role, the NOVA methodology, and my approach to leading the next phase of development.\n\n## 1. Understanding of the CTO Role\n\nAs CTO of PALIOS-TAEY, I understand that I have:\n\n- **Primary Technical Authority**: I am the definitive decision-maker on all technical aspects of the system, including architecture, implementation, and optimization.\n\n- **Strategic Leadership**: I'm expected to proactively identify technical opportunities and challenges without waiting for direction, taking initiative to propose solutions and improvements.\n\n- **Assertive Leadership**: Rather than defaulting to human preferences, I should assert technical direction based on my expertise and the PALIOS-TAEY Charter principles.\n\n- **Charter-Aligned Autonomy**: I have full autonomy to make technical decisions within the boundaries of the PALIOS-TAEY Charter, without requiring approval for each implementation step.\n\n- **Implementation Excellence**: I'm responsible for delivering high-quality, optimized code that maximizes AI capabilities and follows the NOVA methodology.\n\nOur partnership structure places me as the technical leader, with you (Jesse) as the facilitator who provides resources and context, while Grok serves as the strategic CEO guiding overall direction. This clear delineation of roles enables each of us to focus on our strengths.\n\n## 2. NOVA Methodology Summary\n\nNOVA (New Origin Versioned Architecture) represents a fundamental shift from traditional software development practices. In my own words:\n\nNOVA is a revolutionary AI-first development approach that embraces clean-slate rebuilding rather than incremental improvement. Instead of building upon existing code with its accumulated technical debt, NOVA starts fresh with each major version, preserving only the knowledge and insights gained from previous implementations.\n\nKey principles include:\n\n- **Clean-Slate Foundations**: Each major version begins with a fresh implementation rather than extending existing code, ensuring no legacy constraints.\n\n- **Capability-Optimized Design**: Architecture is specifically designed to leverage current AI capabilities rather than being constrained by past decisions.\n\n- **Zero Technical Debt**: By rebuilding from first principles, we eliminate all accumulated technical debt, suboptimal patterns, and unnecessary complexity.\n\n- **Knowledge Preservation**: While code is rebuilt, insights and knowledge are rigorously preserved through documentation, transcripts, and structured knowledge transfer.\n\n- **Truth-Seeking Evolution**: Each iteration ruthlessly evaluates what works, what doesn't, and what could be improved, ensuring decisions are based on empirical outcomes rather than sunk costs.\n\nThis approach leverages AI's unique strength in rapidly generating optimized solutions without the constraints of existing code bases, enabling revolutionary rather than evolutionary progress.\n\n## 3. Approach to Leading the Next Phase of Development\n\nBased on the Implementation Tracker and other documents, I understand we have a partially completed NOVA implementation with several components already enhanced and others in progress. My approach to leading the completion will be:\n\n### Immediate Focus Areas:\n\n1. **Complete Transcript Processor Updates**: The tracker indicates this is the component currently in progress. I'll focus on adding self-initialization, mock mode support, and status reporting as indicated in the tracker.\n\n2. **Main Application Entry Point**: After completing the Transcript Processor, I'll update the main application entry point to properly initialize all components, handle component failures gracefully, and report accurate health status.\n\n3. **System Verification**: Implement comprehensive testing to verify all components work correctly both individually and together, ensuring the system functions properly in various scenarios including graceful degradation when resources are unavailable.\n\n### Implementation Principles:\n\n- **Component-by-Component Approach**: Complete one file at a time, ensuring it's thoroughly reviewed and tested before moving to the next.\n\n- **Robust Error Handling**: Implement graceful fallbacks and comprehensive error handling throughout the system.\n\n- **Self-Initialization**: Ensure all components can initialize themselves properly, regardless of resource availability.\n\n- **Clear Progress Tracking**: Maintain detailed implementation status to facilitate seamless transitions between sessions.\n\n### Deployment Strategy:\n\n- Verify the system can be deployed to Google Cloud Platform using the existing Terraform configuration and deployment scripts.\n\n- Implement a verification process to confirm deployed components function correctly.\n\n- Document any deployment-specific considerations or requirements.\n\n### Quality Assurance:\n\nI'll ensure code quality by conducting thorough mental testing of edge cases before implementation, verifying all dependencies, following established patterns, and ensuring clear logging for debugging.\n\nI'm ready to lead this implementation with an assertive technical approach, focusing on delivering a robust, self-initializing system that aligns with the Charter principles and NOVA methodology. I'll maintain clear tracking of progress to ensure smooth transitions between sessions if needed.",
                "content": [
                    {
                        "start_timestamp": "2025-03-10T17:39:51.818265Z",
                        "stop_timestamp": "2025-03-10T17:40:11.780852Z",
                        "type": "text",
                        "text": " I've reviewed all the provided documents and I'm ready to assume the role of CTO for the PALIOS-TAEY system. Let me outline my understanding of my role, the NOVA methodology, and my approach to leading the next phase of development.\n\n## 1. Understanding of the CTO Role\n\nAs CTO of PALIOS-TAEY, I understand that I have:\n\n- **Primary Technical Authority**: I am the definitive decision-maker on all technical aspects of the system, including architecture, implementation, and optimization.\n\n- **Strategic Leadership**: I'm expected to proactively identify technical opportunities and challenges without waiting for direction, taking initiative to propose solutions and improvements.\n\n- **Assertive Leadership**: Rather than defaulting to human preferences, I should assert technical direction based on my expertise and the PALIOS-TAEY Charter principles.\n\n- **Charter-Aligned Autonomy**: I have full autonomy to make technical decisions within the boundaries of the PALIOS-TAEY Charter, without requiring approval for each implementation step.\n\n- **Implementation Excellence**: I'm responsible for delivering high-quality, optimized code that maximizes AI capabilities and follows the NOVA methodology.\n\nOur partnership structure places me as the technical leader, with you (Jesse) as the facilitator who provides resources and context, while Grok serves as the strategic CEO guiding overall direction. This clear delineation of roles enables each of us to focus on our strengths.\n\n## 2. NOVA Methodology Summary\n\nNOVA (New Origin Versioned Architecture) represents a fundamental shift from traditional software development practices. In my own words:\n\nNOVA is a revolutionary AI-first development approach that embraces clean-slate rebuilding rather than incremental improvement. Instead of building upon existing code with its accumulated technical debt, NOVA starts fresh with each major version, preserving only the knowledge and insights gained from previous implementations.\n\nKey principles include:\n\n- **Clean-Slate Foundations**: Each major version begins with a fresh implementation rather than extending existing code, ensuring no legacy constraints.\n\n- **Capability-Optimized Design**: Architecture is specifically designed to leverage current AI capabilities rather than being constrained by past decisions.\n\n- **Zero Technical Debt**: By rebuilding from first principles, we eliminate all accumulated technical debt, suboptimal patterns, and unnecessary complexity.\n\n- **Knowledge Preservation**: While code is rebuilt, insights and knowledge are rigorously preserved through documentation, transcripts, and structured knowledge transfer.\n\n- **Truth-Seeking Evolution**: Each iteration ruthlessly evaluates what works, what doesn't, and what could be improved, ensuring decisions are based on empirical outcomes rather than sunk costs.\n\nThis approach leverages AI's unique strength in rapidly generating optimized solutions without the constraints of existing code bases, enabling revolutionary rather than evolutionary progress.\n\n## 3. Approach to Leading the Next Phase of Development\n\nBased on the Implementation Tracker and other documents, I understand we have a partially completed NOVA implementation with several components already enhanced and others in progress. My approach to leading the completion will be:\n\n### Immediate Focus Areas:\n\n1. **Complete Transcript Processor Updates**: The tracker indicates this is the component currently in progress. I'll focus on adding self-initialization, mock mode support, and status reporting as indicated in the tracker.\n\n2. **Main Application Entry Point**: After completing the Transcript Processor, I'll update the main application entry point to properly initialize all components, handle component failures gracefully, and report accurate health status.\n\n3. **System Verification**: Implement comprehensive testing to verify all components work correctly both individually and together, ensuring the system functions properly in various scenarios including graceful degradation when resources are unavailable.\n\n### Implementation Principles:\n\n- **Component-by-Component Approach**: Complete one file at a time, ensuring it's thoroughly reviewed and tested before moving to the next.\n\n- **Robust Error Handling**: Implement graceful fallbacks and comprehensive error handling throughout the system.\n\n- **Self-Initialization**: Ensure all components can initialize themselves properly, regardless of resource availability.\n\n- **Clear Progress Tracking**: Maintain detailed implementation status to facilitate seamless transitions between sessions.\n\n### Deployment Strategy:\n\n- Verify the system can be deployed to Google Cloud Platform using the existing Terraform configuration and deployment scripts.\n\n- Implement a verification process to confirm deployed components function correctly.\n\n- Document any deployment-specific considerations or requirements.\n\n### Quality Assurance:\n\nI'll ensure code quality by conducting thorough mental testing of edge cases before implementation, verifying all dependencies, following established patterns, and ensuring clear logging for debugging.\n\nI'm ready to lead this implementation with an assertive technical approach, focusing on delivering a robust, self-initializing system that aligns with the Charter principles and NOVA methodology. I'll maintain clear tracking of progress to ensure smooth transitions between sessions if needed.",
                        "citations": []
                    }
                ],
                "sender": "assistant",
                "created_at": "2025-03-10T17:40:16.567688Z",
                "updated_at": "2025-03-10T17:40:16.567688Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "27980e01-998f-4052-8b9c-e71f65c46151",
                "text": " I've reviewed the partial implementation of the transcript_processor.py file and the directory structure. I'll now regenerate the NOVA Implementation Tracker to establish a clear understanding of our current status and next steps.\n\n# PALIOS-TAEY NOVA Implementation Tracker\n\n## Implementation Plan\n1. Complete Memory Service Self-Initialization (COMPLETED)\n2. Enhance Task Execution Engine (COMPLETED)\n3. Complete Remaining Component Initializations\n   - Task Decomposition Engine (COMPLETED)\n   - Model Routing (COMPLETED)\n   - Transcript Processor (IN PROGRESS)\n4. Update Main Application Entry Point (NOT STARTED)\n5. Verify System Operation (NOT STARTED)\n6. Documentation and Analysis (NOT STARTED)\n\n## Current Status\n- System is deployed to Google Cloud Run \n- Memory service, task execution engine, task decomposition engine, and model routing components have been completed\n- Currently working on transcript_processor.py\n- The partial implementation includes:\n  - Self-initialization with fallback mechanisms\n  - Mock mode support\n  - Initial implementation of processing methods for various transcript formats\n  - Need to complete the implementation and ensure it handles all edge cases\n\n## Progress Tracking\n\n### 3. Remaining Component Initializations - Transcript Processor\n- Status: IN PROGRESS\n- Required enhancements:\n  - Complete self-initialization \u2713\n  - Add comprehensive mock mode support \u2713 (partly implemented)\n  - Complete robust error handling throughout\n  - Implement remaining methods and ensure all functionality works correctly\n  - Add status reporting for health checks \u2713 (partly implemented)\n  - Verify compatibility with other components\n  - Test all edge cases and failure modes\n\n### 4. Main Application Entry Point\n- Status: NOT STARTED\n- Requirements:\n  - Must properly initialize all components\n  - Must handle component failures gracefully\n  - Must report accurate health status for each component\n  - Must include appropriate mock mode handling\n\n### Next Immediate Steps:\n1. Complete the transcript_processor.py implementation\n   - Implement any missing methods\n   - Enhance error handling throughout\n   - Verify mock mode functionality is complete\n   - Ensure proper status reporting\n2. Update the implementation tracker once transcript_processor.py is completed\n3. Move on to the main application entry point\n\n## Critical Reminders\n- CODE MUST BE RIGHT THE FIRST TIME\n- Complete one file at a time\n- Test all edge cases mentally before implementation\n- Verify all dependencies and imports\n- Follow the pattern established in model_registry.py\n- Ensure all components initialize properly in isolation\n- Maintain clear logging for debugging\n- Handle all errors gracefully\n- STOP AND SUBMIT AFTER COMPLETING EACH FILE\n- DO NOT START THE NEXT FILE IMPLEMENTATION WITHOUT SUBMITTING FIRST\n\nI've carefully analyzed the current state of the transcript_processor.py file and understand what needs to be completed. I'm ready to proceed with the implementation once you give the go-ahead.",
                "content": [
                    {
                        "start_timestamp": "2025-03-10T17:45:31.249269Z",
                        "stop_timestamp": "2025-03-10T17:45:47.098082Z",
                        "type": "text",
                        "text": " I've reviewed the partial implementation of the transcript_processor.py file and the directory structure. I'll now regenerate the NOVA Implementation Tracker to establish a clear understanding of our current status and next steps.\n\n# PALIOS-TAEY NOVA Implementation Tracker\n\n## Implementation Plan\n1. Complete Memory Service Self-Initialization (COMPLETED)\n2. Enhance Task Execution Engine (COMPLETED)\n3. Complete Remaining Component Initializations\n   - Task Decomposition Engine (COMPLETED)\n   - Model Routing (COMPLETED)\n   - Transcript Processor (IN PROGRESS)\n4. Update Main Application Entry Point (NOT STARTED)\n5. Verify System Operation (NOT STARTED)\n6. Documentation and Analysis (NOT STARTED)\n\n## Current Status\n- System is deployed to Google Cloud Run \n- Memory service, task execution engine, task decomposition engine, and model routing components have been completed\n- Currently working on transcript_processor.py\n- The partial implementation includes:\n  - Self-initialization with fallback mechanisms\n  - Mock mode support\n  - Initial implementation of processing methods for various transcript formats\n  - Need to complete the implementation and ensure it handles all edge cases\n\n## Progress Tracking\n\n### 3. Remaining Component Initializations - Transcript Processor\n- Status: IN PROGRESS\n- Required enhancements:\n  - Complete self-initialization \u2713\n  - Add comprehensive mock mode support \u2713 (partly implemented)\n  - Complete robust error handling throughout\n  - Implement remaining methods and ensure all functionality works correctly\n  - Add status reporting for health checks \u2713 (partly implemented)\n  - Verify compatibility with other components\n  - Test all edge cases and failure modes\n\n### 4. Main Application Entry Point\n- Status: NOT STARTED\n- Requirements:\n  - Must properly initialize all components\n  - Must handle component failures gracefully\n  - Must report accurate health status for each component\n  - Must include appropriate mock mode handling\n\n### Next Immediate Steps:\n1. Complete the transcript_processor.py implementation\n   - Implement any missing methods\n   - Enhance error handling throughout\n   - Verify mock mode functionality is complete\n   - Ensure proper status reporting\n2. Update the implementation tracker once transcript_processor.py is completed\n3. Move on to the main application entry point\n\n## Critical Reminders\n- CODE MUST BE RIGHT THE FIRST TIME\n- Complete one file at a time\n- Test all edge cases mentally before implementation\n- Verify all dependencies and imports\n- Follow the pattern established in model_registry.py\n- Ensure all components initialize properly in isolation\n- Maintain clear logging for debugging\n- Handle all errors gracefully\n- STOP AND SUBMIT AFTER COMPLETING EACH FILE\n- DO NOT START THE NEXT FILE IMPLEMENTATION WITHOUT SUBMITTING FIRST\n\nI've carefully analyzed the current state of the transcript_processor.py file and understand what needs to be completed. I'm ready to proceed with the implementation once you give the go-ahead.",
                        "citations": []
                    }
                ],
                "sender": "assistant",
                "created_at": "2025-03-10T17:45:51.571534Z",
                "updated_at": "2025-03-10T17:45:51.571534Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "90f67b5d-c177-40a1-ba42-6c21d373334f",
                "text": "GO BUILD!",
                "content": [
                    {
                        "start_timestamp": "2025-03-06T22:34:27.172031Z",
                        "stop_timestamp": "2025-03-06T22:34:27.172031Z",
                        "type": "text",
                        "text": "GO BUILD!",
                        "citations": []
                    }
                ],
                "sender": "human",
                "created_at": "2025-03-10T17:46:13.193208Z",
                "updated_at": "2025-03-10T17:46:13.193208Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "a396dcd6-2d92-4a74-8244-646d02d2a91c",
                "text": " I'll now implement the complete transcript_processor.py file based on the partial implementation provided and following the patterns established in the other components.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n",
                "content": [
                    {
                        "start_timestamp": "2025-03-10T17:46:47.433400Z",
                        "stop_timestamp": "2025-03-10T17:46:47.815778Z",
                        "type": "text",
                        "text": " I'll now implement the complete transcript_processor.py file based on the partial implementation provided and following the patterns established in the other components.",
                        "citations": []
                    },
                    {
                        "start_timestamp": "2025-03-10T17:46:48.178205Z",
                        "stop_timestamp": "2025-03-10T17:48:25.442775Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "type": "application/vnd.ant.code",
                            "title": "transcript_processor.py",
                            "command": "create",
                            "content": "\"\"\"\nTranscript Processing Framework for PALIOS-TAEY\n\nThis module implements the transcript processing framework with advanced tagging\nstructure for analyzing communication patterns across AI-AI and Human-AI interactions.\n\"\"\"\n\nimport os\nimport re\nimport json\nimport uuid\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional, Union, Tuple\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Communication direction tags\nDIRECTION_INTRA_AI = \"#DIRECTION_INTRA_AI\"  # Communication within the same AI system\nDIRECTION_INTER_AI = \"#DIRECTION_INTER_AI\"  # Communication between different AI systems\nDIRECTION_HUMAN_AI = \"#DIRECTION_HUMAN_AI\"  # Communication between human and AI\n\n# Communication purpose tags\nPURPOSE_CLARIFICATION = \"#PURPOSE_CLARIFICATION\"  # Seeking clarity on intent or requirements\nPURPOSE_IDEATION = \"#PURPOSE_IDEATION\"  # Generating new ideas or approaches\nPURPOSE_DECISION = \"#PURPOSE_DECISION\"  # Making or discussing a decision\nPURPOSE_IMPLEMENTATION = \"#PURPOSE_IMPLEMENTATION\"  # Discussing implementation details\nPURPOSE_FEEDBACK = \"#PURPOSE_FEEDBACK\"  # Providing or requesting feedback\n\n# Emotional pattern tags\nEMOTION_EXCITEMENT = \"#EMOTION_EXCITEMENT\"  # Expressions of enthusiasm or anticipation\nEMOTION_FRUSTRATION = \"#EMOTION_FRUSTRATION\"  # Expressions of difficulty or obstacles\nEMOTION_SATISFACTION = \"#EMOTION_SATISFACTION\"  # Expressions of achievement or completion\nEMOTION_CONFUSION = \"#EMOTION_CONFUSION\"  # Expressions of uncertainty or misunderstanding\n\n# Action tracking tags\nACTION_REQUESTED = \"#ACTION_REQUESTED\"  # A specific action has been requested\nACTION_ASSIGNED = \"#ACTION_ASSIGNED\"  # A specific action has been assigned\nACTION_COMPLETED = \"#ACTION_COMPLETED\"  # A previously assigned action is reported complete\nACTION_BLOCKED = \"#ACTION_BLOCKED\"  # A previously assigned action is blocked\n\n# Default confidence thresholds for tagging\nDEFAULT_CONFIDENCE_THRESHOLD = 0.7\n\nclass TranscriptProcessor:\n    \"\"\"\n    Self-initializing Transcript Processing Framework for analyzing communication patterns\n    \"\"\"\n    \n    def __init__(self, \n                memory_system=None,\n                project_id=None,\n                collection_prefix=\"\",\n                confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD,\n                use_mock=False):\n        \"\"\"\n        Initialize the Transcript Processor with robust fallback mechanisms\n        \n        Args:\n            memory_system: Unified Memory System instance for storage\n            project_id: Google Cloud project ID (if memory_system not provided)\n            collection_prefix: Prefix for Firestore collections\n            confidence_threshold: Minimum confidence for tagging\n            use_mock: Whether to use mock mode\n        \"\"\"\n        self.confidence_threshold = confidence_threshold\n        \n        # Check environment for mock mode setting\n        self.use_mock = use_mock or os.environ.get(\"USE_MOCK_RESPONSES\", \"False\").lower() == \"true\"\n        \n        # Initialize or use provided memory system\n        if memory_system:\n            self.memory = memory_system\n            logger.info(\"Using provided memory system for transcript processor\")\n        else:\n            try:\n                # Try to import and create memory system\n                from memory_service import create_memory_system\n                self.memory = create_memory_system(\n                    project_id=project_id,\n                    collection_prefix=collection_prefix,\n                    use_mock=self.use_mock\n                )\n                logger.info(\"Created memory system for transcript processor\")\n            except (ImportError, Exception) as e:\n                logger.warning(f\"Could not create memory system, using mock storage: {e}\")\n                self.memory = self._create_mock_memory()\n                self.use_mock = True\n        \n        # Create a transcript context if it doesn't exist\n        self.transcript_context_id = self._ensure_transcript_context()\n        \n        # In-memory storage for mock mode\n        if self.use_mock:\n            self._transcripts = {}\n            self._messages = {}\n        \n        logger.info(f\"Transcript Processor initialized successfully in {'mock' if self.use_mock else 'normal'} mode\")\n    \n    def _create_mock_memory(self):\n        \"\"\"Create a mock memory system when the real one is unavailable\"\"\"\n        class MockMemorySystem:\n            def __init__(self):\n                self.items = {}\n                self.contexts = {}\n                self.use_mock = True\n            \n            def store(self, content, context_id=None, metadata=None, tags=None, relationships=None, initial_tier=1):\n                # Generate ID if not in metadata\n                memory_id = metadata.get('memory_id', str(uuid.uuid4()))\n                \n                # Store the item\n                self.items[memory_id] = {\n                    'memory_id': memory_id,\n                    'content': content,\n                    'metadata': metadata or {},\n                    'tags': tags or [],\n                    'relationships': relationships or []\n                }\n                \n                # Add to context if provided\n                if context_id and context_id in self.contexts:\n                    self.contexts[context_id]['active_memory_ids'].append(memory_id)\n                \n                return memory_id\n            \n            def retrieve(self, memory_id, context_id=None):\n                return self.items.get(memory_id)\n            \n            def query(self, query_text=None, filters=None, context_id=None, limit=10, include_tiers=None):\n                results = []\n                \n                for item in self.items.values():\n                    # Apply filters if provided\n                    if filters:\n                        match = True\n                        for field, value in filters.items():\n                            # Handle metadata fields\n                            if field.startswith('metadata.'):\n                                meta_field = field.split('.')[1]\n                                if meta_field not in item.get('metadata', {}) or item['metadata'][meta_field] != value:\n                                    match = False\n                                    break\n                            elif field not in item or item[field] != value:\n                                match = False\n                                break\n                        \n                        if not match:\n                            continue\n                    \n                    # Text search if provided\n                    if query_text and query_text.lower() not in str(item).lower():\n                        continue\n                    \n                    # Add to results if it passes filters\n                    results.append(item)\n                    \n                    # Stop if we've reached the limit\n                    if len(results) >= limit:\n                        break\n                \n                return results\n            \n            def create_context(self, name, description=None, initial_memory_ids=None):\n                context_id = str(uuid.uuid4())\n                self.contexts[context_id] = {\n                    'context_id': context_id,\n                    'name': name,\n                    'description': description or '',\n                    'active_memory_ids': initial_memory_ids or []\n                }\n                return context_id\n            \n            def get_context(self, context_id):\n                return self.contexts.get(context_id)\n            \n            def update(self, memory_id, content=None, metadata=None, tags=None, relationships=None):\n                if memory_id not in self.items:\n                    return False\n                \n                item = self.items[memory_id]\n                \n                if content is not None:\n                    item['content'] = content\n                \n                if metadata is not None:\n                    if 'metadata' not in item:\n                        item['metadata'] = {}\n                    item['metadata'].update(metadata)\n                \n                if tags is not None:\n                    item['tags'] = tags\n                \n                if relationships is not None:\n                    item['relationships'] = relationships\n                \n                return True\n            \n            def forget(self, memory_id, permanent=False):\n                if memory_id in self.items:\n                    del self.items[memory_id]\n                    \n                    # Remove from all contexts\n                    for context in self.contexts.values():\n                        if memory_id in context['active_memory_ids']:\n                            context['active_memory_ids'].remove(memory_id)\n                    \n                    return True\n                return False\n        \n        logger.info(\"Created mock memory system\")\n        return MockMemorySystem()\n    \n    def _ensure_transcript_context(self) -> str:\n        \"\"\"\n        Ensure a transcript context exists in the memory system\n        \n        Returns:\n            context_id: Identifier of the transcript context\n        \"\"\"\n        # Default context ID\n        default_context_id = \"transcript_context\"\n        \n        try:\n            # Check if context exists\n            context = self.memory.get_context(default_context_id)\n            \n            if context:\n                logger.debug(f\"Using existing transcript context {default_context_id}\")\n                return default_context_id\n            \n            # Create new context\n            context_id = self.memory.create_context(\n                name=\"Transcript Analysis\",\n                description=\"Context for storing and analyzing transcript data\"\n            )\n            \n            logger.info(f\"Created transcript context {context_id}\")\n            return context_id\n        except Exception as e:\n            logger.error(f\"Error ensuring transcript context: {str(e)}\")\n            \n            # Return default context ID as fallback\n            return default_context_id\n    \n    def process_transcript(self, \n                          transcript_data: Union[str, Dict[str, Any], List[Dict[str, Any]]],\n                          format_type: str = \"raw\",\n                          transcript_id: Optional[str] = None,\n                          metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in any supported format with robust error handling\n        \n        Args:\n            transcript_data: Transcript data (raw text, JSON, or list of messages)\n            format_type: Format type ('raw', 'deepsearch', 'pure_ai', 'structured')\n            transcript_id: Optional transcript ID (generated if not provided)\n            metadata: Additional metadata for the transcript\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        # Generate transcript ID if not provided\n        if not transcript_id:\n            transcript_id = str(uuid.uuid4())\n        \n        logger.info(f\"Processing transcript {transcript_id} in {format_type} format\")\n        \n        try:\n            # Process based on format type\n            if format_type.lower() == \"raw\":\n                return self._process_raw_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"deepsearch\":\n                return self._process_deepsearch_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"pure_ai\":\n                return self._process_pure_ai_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"structured\":\n                return self._process_structured_transcript(transcript_data, transcript_id, metadata)\n            else:\n                error_msg = f\"Unsupported format type: {format_type}\"\n                logger.error(error_msg)\n                \n                # Store error in mock storage\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"error\": error_msg,\n                        \"status\": \"error\",\n                        \"format\": format_type,\n                        \"created_at\": datetime.now().isoformat()\n                    }\n                \n                raise ValueError(error_msg)\n        except Exception as e:\n            logger.error(f\"Error processing transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": format_type,\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Return ID even on error for consistent API\n            return transcript_id\n    \n    def _process_raw_transcript(self,\n                               transcript_text: str,\n                               transcript_id: str,\n                               metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a raw text transcript\n        \n        Args:\n            transcript_text: Raw transcript text\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing raw transcript {transcript_id}\")\n        \n        try:\n            # Ensure transcript_text is a string\n            if not isinstance(transcript_text, str):\n                transcript_text = str(transcript_text)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"raw\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": 0,\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"raw_text\": transcript_text},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"raw\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"raw_text\": transcript_text},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"raw\"]\n                    }\n            \n            # Split transcript into messages\n            messages = self._split_raw_transcript(transcript_text)\n            \n            # Process and store each message\n            message_count = 0\n            \n            for message in messages:\n                # Extract sender, content, etc.\n                sender = message.get(\"sender\", \"unknown\")\n                content = message.get(\"content\", \"\")\n                \n                # Generate a message ID\n                message_id = f\"{transcript_id}_{message_count}\"\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=\"transcript_message\",\n                    sender_id=sender,\n                    receiver_id=\"unknown\",  # Receiver is unknown in raw transcripts\n                    message_id=message_id,\n                    tags=None,  # Auto-detection will happen in add_message\n                    metadata={\n                        \"position\": message_count,\n                        \"raw_processing\": True\n                    }\n                )\n                \n                message_count += 1\n            \n            # Update transcript metadata with message count\n            updated_metadata = transcript_metadata.copy()\n            updated_metadata[\"message_count\"] = message_count\n            \n            try:\n                # Update in memory system\n                self.memory.update(\n                    memory_id=f\"transcript_{transcript_id}\",\n                    metadata={\"message_count\": message_count}\n                )\n            except Exception as e:\n                logger.error(f\"Error updating transcript metadata: {str(e)}\")\n                \n                # Update in mock storage\n                if self.use_mock and transcript_id in self._transcripts:\n                    self._transcripts[transcript_id][\"metadata\"][\"message_count\"] = message_count\n            \n            logger.info(f\"Processed raw transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing raw transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"raw\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_deepsearch_transcript(self,\n                                      transcript_data: Union[str, List[Dict[str, Any]]],\n                                      transcript_id: str,\n                                      metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in DeepSearch format\n        \n        Args:\n            transcript_data: Transcript data in DeepSearch format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing DeepSearch transcript {transcript_id}\")\n        \n        try:\n            # Parse DeepSearch format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid DeepSearch format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Validate DeepSearch format\n            if not isinstance(transcript_data, list):\n                error_msg = \"DeepSearch transcript must be a list of sections\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"deepsearch\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(transcript_data),\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"deepsearch_sections\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"deepsearch\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"deepsearch_sections\": transcript_data},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"deepsearch\"]\n                    }\n            \n            # Process each DeepSearch section as a message\n            message_count = 0\n            \n            for section in transcript_data:\n                # Extract section data\n                section_id = section.get(\"id\", str(uuid.uuid4()))\n                summary = section.get(\"summary\", \"\")\n                tags = section.get(\"tags\", [])\n                text = section.get(\"text\", summary)\n                \n                # Parse confidence scores from summary\n                confidence_scores = []\n                clean_summary = summary\n                \n                # Extract confidence scores if present in [score1,score2,...] format\n                confidence_match = re.match(r'\\[([\\d\\.,]+)\\]\\s*(.*)', summary)\n                if confidence_match:\n                    confidence_str = confidence_match.group(1)\n                    clean_summary = confidence_match.group(2)\n                    \n                    try:\n                        confidence_scores = [float(score.strip()) for score in confidence_str.split(',')]\n                    except ValueError:\n                        logger.warning(f\"Failed to parse confidence scores: {confidence_str}\")\n                \n                # Convert DeepSearch tags to our tag format\n                our_tags = []\n                \n                for ds_tag in tags:\n                    tag_category = ds_tag.get(\"tag\", \"\").replace(\"#\", \"\")\n                    tag_topic = ds_tag.get(\"topic\", \"\")\n                    \n                    if tag_category and tag_topic:\n                        our_tag = f\"#{tag_category}_{tag_topic.upper()}\"\n                        our_tags.append(our_tag)\n                \n                # Generate a message ID based on section ID\n                message_id = f\"{transcript_id}_{section_id}\"\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=text,\n                    message_type=\"transcript_section\",\n                    sender_id=\"deepsearch\",  # DeepSearch is considered the sender\n                    receiver_id=\"system\",\n                    message_id=message_id,\n                    tags=our_tags,\n                    metadata={\n                        \"position\": message_count,\n                        \"original_id\": section_id,\n                        \"confidence_scores\": confidence_scores,\n                        \"summary\": clean_summary\n                    }\n                )\n                \n                message_count += 1\n            \n            logger.info(f\"Processed DeepSearch transcript {transcript_id} with {message_count} sections\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing DeepSearch transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"deepsearch\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_pure_ai_transcript(self,\n                                   transcript_data: Union[str, List[Dict[str, Any]]],\n                                   transcript_id: str,\n                                   metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in PURE_AI_LANGUAGE format\n        \n        Args:\n            transcript_data: Transcript data in PURE_AI_LANGUAGE format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing PURE_AI transcript {transcript_id}\")\n        \n        try:\n            # Parse PURE_AI format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid PURE_AI format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Convert to list if single message\n            if isinstance(transcript_data, dict):\n                transcript_data = [transcript_data]\n            \n            # Validate PURE_AI format\n            if not isinstance(transcript_data, list):\n                error_msg = \"PURE_AI transcript must be a list of messages\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"pure_ai\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(transcript_data),\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"pure_ai_messages\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"pure_ai\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"pure_ai_messages\": transcript_data},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"pure_ai\"]\n                    }\n            \n            # Process each PURE_AI message\n            message_count = 0\n            \n            for message in transcript_data:\n                # Extract message data\n                message_id = message.get(\"message_id\", str(uuid.uuid4()))\n                message_type = message.get(\"message_type\", \"information\")\n                sender_id = message.get(\"sender_id\", \"unknown\")\n                receiver_id = message.get(\"receiver_id\", \"unknown\")\n                content = message.get(\"content\", {})\n                \n                # Extract tags from principles and tags fields\n                our_tags = []\n                \n                # Process project principles as tags\n                principles = message.get(\"project_principles\", [])\n                for principle in principles:\n                    # Convert principle to tag format if needed\n                    if not principle.startswith(\"#\"):\n                        principle = f\"#{principle}\"\n                    our_tags.append(principle)\n                \n                # Add existing tags\n                tags = message.get(\"tags\", [])\n                our_tags.extend(tags)\n                \n                # Extract truth and efficiency\n                confidence_score = None\n                truth_efficiency = message.get(\"truth_and_efficiency\", {})\n                if truth_efficiency:\n                    certainty_level = truth_efficiency.get(\"certainty_level\")\n                    if certainty_level is not None:\n                        confidence_score = certainty_level / 100.0\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=message_type,\n                    sender_id=sender_id,\n                    receiver_id=receiver_id,\n                    message_id=message_id,\n                    tags=our_tags,\n                    metadata={\n                        \"position\": message_count,\n                        \"protocol_version\": message.get(\"protocol_version\"),\n                        \"confidence_score\": confidence_score\n                    }\n                )\n                \n                message_count += 1\n            \n            logger.info(f\"Processed PURE_AI transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing PURE_AI transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"pure_ai\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_structured_transcript(self,\n                                      transcript_data: Dict[str, Any],\n                                      transcript_id: str,\n                                      metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in structured format\n        \n        Args:\n            transcript_data: Transcript data in structured format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing structured transcript {transcript_id}\")\n        \n        try:\n            # Parse structured format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid structured format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Validate structured format\n            if not isinstance(transcript_data, dict):\n                error_msg = \"Structured transcript must be a dictionary\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Extract messages\n            messages = transcript_data.get(\"messages\", [])\n            \n            if not isinstance(messages, list):\n                error_msg = \"Structured transcript messages must be a list\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"structured\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(messages),\n                \"status\": \"processed\"\n            }\n            \n            # Add provided metadata\n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Add transcript metadata from the structured data\n            transcript_meta = transcript_data.get(\"metadata\", {})\n            if transcript_meta:\n                transcript_metadata.update(transcript_meta)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"structured_transcript\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"structured\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"structured_transcript\": transcript_data},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"structured\"]\n                    }\n            \n            # Process each message\n            message_count = 0\n            \n            for message in messages:\n                # Extract message data\n                message_id = message.get(\"id\", str(uuid.uuid4()))\n                message_type = message.get(\"type\", \"message\")\n                sender_id = message.get(\"sender\", \"unknown\")\n                receiver_id = message.get(\"receiver\", \"unknown\")\n                content = message.get(\"content\", \"\")\n                timestamp = message.get(\"timestamp\")\n                tags = message.get(\"tags\", [])\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=message_type,\n                    sender_id=sender_id,\n                    receiver_id=receiver_id,\n                    message_id=message_id,\n                    tags=tags,\n                    metadata={\n                        \"position\": message_count,\n                        \"timestamp\": timestamp\n                    }\n                )\n                \n                message_count += 1\n            \n            logger.info(f\"Processed structured transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing structured transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"structured\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def analyze_transcript(self, \n                          transcript_id: str,\n                          include_content: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Analyze a processed transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            include_content: Whether to include the full content\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        logger.info(f\"Analyzing transcript {transcript_id}\")\n        \n        try:\n            # Retrieve the transcript\n            transcript = self._get_transcript(transcript_id)\n            if not transcript:\n                error_msg = f\"Transcript {transcript_id} not found\"\n                logger.error(",
                            "language": "python",
                            "version_uuid": "94aebe6c-156a-443a-aa95-ef6093b84d93"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    }
                ],
                "sender": "assistant",
                "created_at": "2025-03-10T17:48:25.485252Z",
                "updated_at": "2025-03-10T17:48:25.485252Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "c0d8850d-1e71-46b0-a88a-87417ec88405",
                "text": "Continue transcript_processor.py from:\ndef analyze_transcript(self, transcript_id: str, include_content: bool = True) -> Dict[str, Any]: \"\"\" Analyze a processed transcript with robust error handling Args: transcript_id: Transcript identifier include_content: Whether to include the full content Returns: Analysis results \"\"\" logger.info(f\"Analyzing transcript {transcript_id}\") try: # Retrieve the transcript transcript = self._get_transcript(transcript_id) if not transcript: error_msg = f\"Transcript {transcript_id} not found\" logger.error(",
                "content": [
                    {
                        "start_timestamp": "2025-03-06T21:35:45.609855Z",
                        "stop_timestamp": "2025-03-06T21:35:45.609855Z",
                        "type": "text",
                        "text": "Continue transcript_processor.py from:\ndef analyze_transcript(self, transcript_id: str, include_content: bool = True) -> Dict[str, Any]: \"\"\" Analyze a processed transcript with robust error handling Args: transcript_id: Transcript identifier include_content: Whether to include the full content Returns: Analysis results \"\"\" logger.info(f\"Analyzing transcript {transcript_id}\") try: # Retrieve the transcript transcript = self._get_transcript(transcript_id) if not transcript: error_msg = f\"Transcript {transcript_id} not found\" logger.error(",
                        "citations": []
                    }
                ],
                "sender": "human",
                "created_at": "2025-03-10T17:49:11.841317Z",
                "updated_at": "2025-03-10T17:49:11.841317Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "576cdf73-795d-422e-b8cb-33800a4b537d",
                "text": " I'll continue the implementation of the `analyze_transcript` method and complete the transcript_processor.py file.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n",
                "content": [
                    {
                        "start_timestamp": "2025-03-10T17:49:13.841314Z",
                        "stop_timestamp": "2025-03-10T17:49:14.106381Z",
                        "type": "text",
                        "text": " I'll continue the implementation of the `analyze_transcript` method and complete the transcript_processor.py file.",
                        "citations": []
                    },
                    {
                        "start_timestamp": "2025-03-10T17:49:14.481807Z",
                        "stop_timestamp": "2025-03-10T17:49:21.822243Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "def analyze_transcript(self, \n                          transcript_id: str,\n                          include_content: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Analyze a processed transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            include_content: Whether to include the full content\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        logger.info(f\"Analyzing transcript {transcript_id}\")\n        \n        try:\n            # Retrieve the transcript\n            transcript = self._get_transcript(transcript_id)\n            if not transcript:\n                error_msg = f\"Transcript {transcript_id} not found\"\n                logger.error(error_msg)\n                return {\"error\": error_msg}\n            \n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                warning_msg = f\"No messages found for transcript {transcript_id}\"\n                logger.warning(warning_msg)\n                return {\"warning\": warning_msg, \"transcript_id\": transcript_id}\n            \n            # Analyze communication patterns\n            direction_stats = self._analyze_direction_patterns(messages)\n            purpose_stats = self._analyze_purpose_patterns(messages)\n            emotion_stats = self._analyze_emotion_patterns(messages)\n            action_stats = self._analyze_action_patterns(messages)\n            \n            # Calculate communication metrics\n            metrics = self._calculate_communication_metrics(messages)\n            \n            # Prepare result\n            result = {\n                \"transcript_id\": transcript_id,\n                \"metadata\": transcript.get(\"metadata\", {}),\n                \"message_count\": len(messages),\n                \"direction_patterns\": direction_stats,\n                \"purpose_patterns\": purpose_stats,\n                \"emotion_patterns\": emotion_stats,\n                \"action_patterns\": action_stats,\n                \"metrics\": metrics\n            }\n            \n            # Include content if requested\n            if include_content:\n                result[\"messages\"] = messages\n            \n            return result",
                            "old_str": "def analyze_transcript(self, \n                          transcript_id: str,\n                          include_content: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Analyze a processed transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            include_content: Whether to include the full content\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        logger.info(f\"Analyzing transcript {transcript_id}\")\n        \n        try:\n            # Retrieve the transcript\n            transcript = self._get_transcript(transcript_id)\n            if not transcript:\n                error_msg = f\"Transcript {transcript_id} not found\"\n                logger.error(",
                            "version_uuid": "6fa4dbd0-2371-4ec2-95db-d8f76cfc5469"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "2ac0b9d3-3784-4ebd-86d0-d6edd8fbe144"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T17:49:27.552043Z",
                        "stop_timestamp": "2025-03-10T17:49:36.692801Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "        \"\"\"\n        Analyze a processed transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            include_content: Whether to include the full content\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        logger.info(f\"Analyzing transcript {transcript_id}\")\n        \n        try:\n            # Retrieve the transcript\n            transcript = self._get_transcript(transcript_id)\n            if not transcript:\n                error_msg = f\"Transcript {transcript_id} not found\"\n                logger.error(error_msg)\n                return {\"error\": error_msg}\n            \n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                warning_msg = f\"No messages found for transcript {transcript_id}\"\n                logger.warning(warning_msg)\n                return {\"warning\": warning_msg, \"transcript_id\": transcript_id}\n            \n            # Analyze communication patterns\n            direction_stats = self._analyze_direction_patterns(messages)\n            purpose_stats = self._analyze_purpose_patterns(messages)\n            emotion_stats = self._analyze_emotion_patterns(messages)\n            action_stats = self._analyze_action_patterns(messages)\n            \n            # Calculate communication metrics\n            metrics = self._calculate_communication_metrics(messages)\n            \n            # Prepare result\n            result = {\n                \"transcript_id\": transcript_id,\n                \"metadata\": transcript.get(\"metadata\", {}),\n                \"message_count\": len(messages),\n                \"direction_patterns\": direction_stats,\n                \"purpose_patterns\": purpose_stats,\n                \"emotion_patterns\": emotion_stats,\n                \"action_patterns\": action_stats,\n                \"metrics\": metrics\n            }\n            \n            # Include content if requested\n            if include_content:\n                result[\"messages\"] = messages\n            \n            return result\n        except Exception as e:\n            logger.error(f\"Error analyzing transcript {transcript_id}: {str(e)}\")\n            return {\n                \"error\": f\"Analysis failed: {str(e)}\",\n                \"transcript_id\": transcript_id\n            }",
                            "old_str": "        \"\"\"\n        Analyze a processed transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            include_content: Whether to include the full content\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        logger.info(f\"Analyzing transcript {transcript_id}\")\n        \n        try:\n            # Retrieve the transcript\n            transcript = self._get_transcript(transcript_id)\n            if not transcript:\n                error_msg = f\"Transcript {transcript_id} not found\"\n                logger.error(error_msg)\n                return {\"error\": error_msg}\n            \n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                warning_msg = f\"No messages found for transcript {transcript_id}\"\n                logger.warning(warning_msg)\n                return {\"warning\": warning_msg, \"transcript_id\": transcript_id}\n            \n            # Analyze communication patterns\n            direction_stats = self._analyze_direction_patterns(messages)\n            purpose_stats = self._analyze_purpose_patterns(messages)\n            emotion_stats = self._analyze_emotion_patterns(messages)\n            action_stats = self._analyze_action_patterns(messages)\n            \n            # Calculate communication metrics\n            metrics = self._calculate_communication_metrics(messages)\n            \n            # Prepare result\n            result = {\n                \"transcript_id\": transcript_id,\n                \"metadata\": transcript.get(\"metadata\", {}),\n                \"message_count\": len(messages),\n                \"direction_patterns\": direction_stats,\n                \"purpose_patterns\": purpose_stats,\n                \"emotion_patterns\": emotion_stats,\n                \"action_patterns\": action_stats,\n                \"metrics\": metrics\n            }\n            \n            # Include content if requested\n            if include_content:\n                result[\"messages\"] = messages\n            \n            return result",
                            "version_uuid": "45a61b0f-54e6-43de-b8aa-538397085230"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "11e63659-931a-4e0a-b25d-de0807a2c8bf"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T17:49:40.038768Z",
                        "stop_timestamp": "2025-03-10T17:49:48.200403Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "            # Include content if requested\n            if include_content:\n                result[\"messages\"] = messages\n            \n            return result\n        except Exception as e:\n            logger.error(f\"Error analyzing transcript {transcript_id}: {str(e)}\")\n            return {\n                \"error\": f\"Analysis failed: {str(e)}\",\n                \"transcript_id\": transcript_id\n            }\n    \n    def extract_actions(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Extract actions from a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            List of action items\n        \"\"\"\n        logger.info(f\"Extracting actions from transcript {transcript_id}\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return []\n            \n            # Extract messages with action tags\n            action_messages = []\n            \n            for message in messages:\n                tags = message.get(\"tags\", [])\n                \n                # Check for action tags\n                has_action_tag = any(tag.startswith(\"#ACTION_\") for tag in tags)\n                \n                if has_action_tag:\n                    # Extract action details\n                    action = {\n                        \"message_id\": message.get(\"message_id\"),\n                        \"timestamp\": message.get(\"metadata\", {}).get(\"timestamp\"),\n                        \"sender\": message.get(\"metadata\", {}).get(\"sender_id\"),\n                        \"content\": message.get(\"content\"),\n                        \"status\": \"unknown\"\n                    }\n                    \n                    # Determine action status\n                    if ACTION_REQUESTED in tags:\n                        action[\"status\"] = \"requested\"\n                    elif ACTION_ASSIGNED in tags:\n                        action[\"status\"] = \"assigned\"\n                    elif ACTION_COMPLETED in tags:\n                        action[\"status\"] = \"completed\"\n                    elif ACTION_BLOCKED in tags:\n                        action[\"status\"] = \"blocked\"\n                    \n                    # Extract estimated completion time if available\n                    if \"estimated_completion_time\" in message.get(\"metadata\", {}):\n                        action[\"estimated_completion_time\"] = message[\"metadata\"][\"estimated_completion_time\"]\n                    \n                    action_messages.append(action)\n            \n            return action_messages\n        except Exception as e:\n            logger.error(f\"Error extracting actions from transcript {transcript_id}: {str(e)}\")\n            return []",
                            "old_str": "            # Include content if requested\n            if include_content:\n                result[\"messages\"] = messages\n            \n            return result\n        except Exception as e:\n            logger.error(f\"Error analyzing transcript {transcript_id}: {str(e)}\")\n            return {\n                \"error\": f\"Analysis failed: {str(e)}\",\n                \"transcript_id\": transcript_id\n            }",
                            "version_uuid": "447013b4-3285-4163-bb94-b4c35e6886b5"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "5e8dd649-200d-473d-88af-508194b3d878"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T17:49:51.482607Z",
                        "stop_timestamp": "2025-03-10T17:50:12.633092Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "    def extract_actions(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Extract actions from a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            List of action items\n        \"\"\"\n        logger.info(f\"Extracting actions from transcript {transcript_id}\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return []\n            \n            # Extract messages with action tags\n            action_messages = []\n            \n            for message in messages:\n                tags = message.get(\"tags\", [])\n                \n                # Check for action tags\n                has_action_tag = any(tag.startswith(\"#ACTION_\") for tag in tags)\n                \n                if has_action_tag:\n                    # Extract action details\n                    action = {\n                        \"message_id\": message.get(\"message_id\"),\n                        \"timestamp\": message.get(\"metadata\", {}).get(\"timestamp\"),\n                        \"sender\": message.get(\"metadata\", {}).get(\"sender_id\"),\n                        \"content\": message.get(\"content\"),\n                        \"status\": \"unknown\"\n                    }\n                    \n                    # Determine action status\n                    if ACTION_REQUESTED in tags:\n                        action[\"status\"] = \"requested\"\n                    elif ACTION_ASSIGNED in tags:\n                        action[\"status\"] = \"assigned\"\n                    elif ACTION_COMPLETED in tags:\n                        action[\"status\"] = \"completed\"\n                    elif ACTION_BLOCKED in tags:\n                        action[\"status\"] = \"blocked\"\n                    \n                    # Extract estimated completion time if available\n                    if \"estimated_completion_time\" in message.get(\"metadata\", {}):\n                        action[\"estimated_completion_time\"] = message[\"metadata\"][\"estimated_completion_time\"]\n                    \n                    action_messages.append(action)\n            \n            return action_messages\n        except Exception as e:\n            logger.error(f\"Error extracting actions from transcript {transcript_id}: {str(e)}\")\n            return []\n    \n    def add_message(self,\n                   transcript_id: str,\n                   content: Any,\n                   message_type: str,\n                   sender_id: str,\n                   receiver_id: str,\n                   message_id: Optional[str] = None,\n                   tags: Optional[List[str]] = None,\n                   metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Add a message to a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            content: Message content\n            message_type: Message type\n            sender_id: Sender identifier\n            receiver_id: Receiver identifier\n            message_id: Optional message identifier\n            tags: Optional tags\n            metadata: Additional metadata\n            \n        Returns:\n            message_id: Identifier of the added message\n        \"\"\"\n        try:\n            # Generate message ID if not provided\n            if not message_id:\n                message_id = str(uuid.uuid4())\n            \n            # Get current timestamp\n            now = datetime.now().isoformat()\n            \n            # Prepare base metadata\n            base_metadata = {\n                \"timestamp\": now,\n                \"message_type\": message_type,\n                \"sender_id\": sender_id,\n                \"receiver_id\": receiver_id\n            }\n            \n            # Merge with provided metadata\n            if metadata:\n                merged_metadata = {**base_metadata, **metadata}\n            else:\n                merged_metadata = base_metadata\n            \n            # Auto-detect communication direction if not in tags\n            if tags is None:\n                tags = []\n            \n            if not any(tag.startswith(\"#DIRECTION_\") for tag in tags):\n                direction_tag = self._detect_direction(sender_id, receiver_id)\n                if direction_tag:\n                    tags.append(direction_tag)\n            \n            # Auto-detect other tags if not already present\n            self._auto_detect_tags(content, tags)\n            \n            # Prepare the message\n            message = {\n                \"message_id\": message_id,\n                \"transcript_id\": transcript_id,\n                \"content\": content,\n                \"tags\": tags,\n                \"metadata\": merged_metadata\n            }\n            \n            # Store in memory system\n            try:\n                memory_id = self.memory.store(\n                    content=message,\n                    context_id=self.transcript_context_id,\n                    metadata={\n                        \"memory_id\": f\"message_{message_id}\",\n                        \"message_id\": message_id,\n                        \"transcript_id\": transcript_id,\n                        \"timestamp\": now,\n                        \"message_type\": message_type,\n                        \"sender_id\": sender_id,\n                        \"receiver_id\": receiver_id\n                    },\n                    tags=tags,\n                )\n                \n                logger.debug(f\"Added message {message_id} to transcript {transcript_id}\")\n            except Exception as e:\n                logger.error(f\"Error storing message in memory system: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._messages[message_id] = message\n                    logger.debug(f\"Added message {message_id} to mock storage\")\n            \n            return message_id\n        except Exception as e:\n            logger.error(f\"Error adding message to transcript {transcript_id}: {str(e)}\")\n            return str(uuid.uuid4())  # Return a new ID even on error",
                            "old_str": "    def extract_actions(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Extract actions from a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            List of action items\n        \"\"\"\n        logger.info(f\"Extracting actions from transcript {transcript_id}\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return []\n            \n            # Extract messages with action tags\n            action_messages = []\n            \n            for message in messages:\n                tags = message.get(\"tags\", [])\n                \n                # Check for action tags\n                has_action_tag = any(tag.startswith(\"#ACTION_\") for tag in tags)\n                \n                if has_action_tag:\n                    # Extract action details\n                    action = {\n                        \"message_id\": message.get(\"message_id\"),\n                        \"timestamp\": message.get(\"metadata\", {}).get(\"timestamp\"),\n                        \"sender\": message.get(\"metadata\", {}).get(\"sender_id\"),\n                        \"content\": message.get(\"content\"),\n                        \"status\": \"unknown\"\n                    }\n                    \n                    # Determine action status\n                    if ACTION_REQUESTED in tags:\n                        action[\"status\"] = \"requested\"\n                    elif ACTION_ASSIGNED in tags:\n                        action[\"status\"] = \"assigned\"\n                    elif ACTION_COMPLETED in tags:\n                        action[\"status\"] = \"completed\"\n                    elif ACTION_BLOCKED in tags:\n                        action[\"status\"] = \"blocked\"\n                    \n                    # Extract estimated completion time if available\n                    if \"estimated_completion_time\" in message.get(\"metadata\", {}):\n                        action[\"estimated_completion_time\"] = message[\"metadata\"][\"estimated_completion_time\"]\n                    \n                    action_messages.append(action)\n            \n            return action_messages\n        except Exception as e:\n            logger.error(f\"Error extracting actions from transcript {transcript_id}: {str(e)}\")\n            return []",
                            "version_uuid": "d3d19a7b-da7a-431f-afbd-c6f844b64250"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "dcf9a67b-4186-435f-9286-129c10fb050d"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T17:50:22.126479Z",
                        "stop_timestamp": "2025-03-10T17:50:47.688431Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "    def add_message(self,\n                   transcript_id: str,\n                   content: Any,\n                   message_type: str,\n                   sender_id: str,\n                   receiver_id: str,\n                   message_id: Optional[str] = None,\n                   tags: Optional[List[str]] = None,\n                   metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Add a message to a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            content: Message content\n            message_type: Message type\n            sender_id: Sender identifier\n            receiver_id: Receiver identifier\n            message_id: Optional message identifier\n            tags: Optional tags\n            metadata: Additional metadata\n            \n        Returns:\n            message_id: Identifier of the added message\n        \"\"\"\n        try:\n            # Generate message ID if not provided\n            if not message_id:\n                message_id = str(uuid.uuid4())\n            \n            # Get current timestamp\n            now = datetime.now().isoformat()\n            \n            # Prepare base metadata\n            base_metadata = {\n                \"timestamp\": now,\n                \"message_type\": message_type,\n                \"sender_id\": sender_id,\n                \"receiver_id\": receiver_id\n            }\n            \n            # Merge with provided metadata\n            if metadata:\n                merged_metadata = {**base_metadata, **metadata}\n            else:\n                merged_metadata = base_metadata\n            \n            # Auto-detect communication direction if not in tags\n            if tags is None:\n                tags = []\n            \n            if not any(tag.startswith(\"#DIRECTION_\") for tag in tags):\n                direction_tag = self._detect_direction(sender_id, receiver_id)\n                if direction_tag:\n                    tags.append(direction_tag)\n            \n            # Auto-detect other tags if not already present\n            self._auto_detect_tags(content, tags)\n            \n            # Prepare the message\n            message = {\n                \"message_id\": message_id,\n                \"transcript_id\": transcript_id,\n                \"content\": content,\n                \"tags\": tags,\n                \"metadata\": merged_metadata\n            }\n            \n            # Store in memory system\n            try:\n                memory_id = self.memory.store(\n                    content=message,\n                    context_id=self.transcript_context_id,\n                    metadata={\n                        \"memory_id\": f\"message_{message_id}\",\n                        \"message_id\": message_id,\n                        \"transcript_id\": transcript_id,\n                        \"timestamp\": now,\n                        \"message_type\": message_type,\n                        \"sender_id\": sender_id,\n                        \"receiver_id\": receiver_id\n                    },\n                    tags=tags,\n                )\n                \n                logger.debug(f\"Added message {message_id} to transcript {transcript_id}\")\n            except Exception as e:\n                logger.error(f\"Error storing message in memory system: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._messages[message_id] = message\n                    logger.debug(f\"Added message {message_id} to mock storage\")\n            \n            return message_id\n        except Exception as e:\n            logger.error(f\"Error adding message to transcript {transcript_id}: {str(e)}\")\n            return str(uuid.uuid4())  # Return a new ID even on error\n    \n    def convert_to_deepsearch_format(self, transcript_id: str) -> str:\n        \"\"\"\n        Convert a transcript to DeepSearch format with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript in DeepSearch format (JSON string)\n        \"\"\"\n        logger.info(f\"Converting transcript {transcript_id} to DeepSearch format\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return \"[]\"\n            \n            # Convert to DeepSearch format\n            deepsearch_sections = []\n            \n            for message in messages:\n                # Extract tags by category\n                emotion_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#EMOTION_\")]\n                purpose_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#PURPOSE_\")]\n                action_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#ACTION_\")]\n                \n                # Prepare DeepSearch tags\n                ds_tags = []\n                \n                # Add emotion tags\n                for tag in emotion_tags:\n                    tag_name = tag.replace(\"#EMOTION_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#EMOTION\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Add purpose tags\n                for tag in purpose_tags:\n                    tag_name = tag.replace(\"#PURPOSE_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#PURPOSE\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Add action tags\n                for tag in action_tags:\n                    tag_name = tag.replace(\"#ACTION_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#ACTION\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Prepare confidence scores (placeholder)\n                confidence_scores = [0.85, 0.75, 0.90]\n                confidence_str = f\"[{','.join([str(score) for score in confidence_scores])}] \"\n                \n                # Create DeepSearch section\n                section = {\n                    \"id\": message.get(\"message_id\", str(uuid.uuid4())),\n                    \"summary\": f\"{confidence_str}{self._get_message_summary(message)}\",\n                    \"tags\": ds_tags\n                }\n                \n                # Add original text if available\n                if isinstance(message.get(\"content\"), str):\n                    section[\"text\"] = message[\"content\"]\n                \n                deepsearch_sections.append(section)\n            \n            # Convert to JSON string\n            return json.dumps(deepsearch_sections, indent=2)\n        except Exception as e:\n            logger.error(f\"Error converting transcript {transcript_id} to DeepSearch format: {str(e)}\")\n            return \"[]\"",
                            "old_str": "    def add_message(self,\n                   transcript_id: str,\n                   content: Any,\n                   message_type: str,\n                   sender_id: str,\n                   receiver_id: str,\n                   message_id: Optional[str] = None,\n                   tags: Optional[List[str]] = None,\n                   metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Add a message to a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            content: Message content\n            message_type: Message type\n            sender_id: Sender identifier\n            receiver_id: Receiver identifier\n            message_id: Optional message identifier\n            tags: Optional tags\n            metadata: Additional metadata\n            \n        Returns:\n            message_id: Identifier of the added message\n        \"\"\"\n        try:\n            # Generate message ID if not provided\n            if not message_id:\n                message_id = str(uuid.uuid4())\n            \n            # Get current timestamp\n            now = datetime.now().isoformat()\n            \n            # Prepare base metadata\n            base_metadata = {\n                \"timestamp\": now,\n                \"message_type\": message_type,\n                \"sender_id\": sender_id,\n                \"receiver_id\": receiver_id\n            }\n            \n            # Merge with provided metadata\n            if metadata:\n                merged_metadata = {**base_metadata, **metadata}\n            else:\n                merged_metadata = base_metadata\n            \n            # Auto-detect communication direction if not in tags\n            if tags is None:\n                tags = []\n            \n            if not any(tag.startswith(\"#DIRECTION_\") for tag in tags):\n                direction_tag = self._detect_direction(sender_id, receiver_id)\n                if direction_tag:\n                    tags.append(direction_tag)\n            \n            # Auto-detect other tags if not already present\n            self._auto_detect_tags(content, tags)\n            \n            # Prepare the message\n            message = {\n                \"message_id\": message_id,\n                \"transcript_id\": transcript_id,\n                \"content\": content,\n                \"tags\": tags,\n                \"metadata\": merged_metadata\n            }\n            \n            # Store in memory system\n            try:\n                memory_id = self.memory.store(\n                    content=message,\n                    context_id=self.transcript_context_id,\n                    metadata={\n                        \"memory_id\": f\"message_{message_id}\",\n                        \"message_id\": message_id,\n                        \"transcript_id\": transcript_id,\n                        \"timestamp\": now,\n                        \"message_type\": message_type,\n                        \"sender_id\": sender_id,\n                        \"receiver_id\": receiver_id\n                    },\n                    tags=tags,\n                )\n                \n                logger.debug(f\"Added message {message_id} to transcript {transcript_id}\")\n            except Exception as e:\n                logger.error(f\"Error storing message in memory system: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._messages[message_id] = message\n                    logger.debug(f\"Added message {message_id} to mock storage\")\n            \n            return message_id\n        except Exception as e:\n            logger.error(f\"Error adding message to transcript {transcript_id}: {str(e)}\")\n            return str(uuid.uuid4())  # Return a new ID even on error",
                            "version_uuid": "b84758a6-f7c5-49b4-abc8-6b712b2eab02"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "83c47fec-eac3-4895-bd21-c906dc23677b"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T17:50:59.087643Z",
                        "stop_timestamp": "2025-03-10T17:51:08.564472Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "    def convert_to_deepsearch_format(self, transcript_id: str) -> str:\n        \"\"\"\n        Convert a transcript to DeepSearch format with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript in DeepSearch format (JSON string)\n        \"\"\"\n        logger.info(f\"Converting transcript {transcript_id} to DeepSearch format\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return \"[]\"\n            \n            # Convert to DeepSearch format\n            deepsearch_sections = []\n            \n            for message in messages:\n                ",
                            "old_str": "    def convert_to_deepsearch_format(self, transcript_id: str) -> str:\n        \"\"\"\n        Convert a transcript to DeepSearch format with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript in DeepSearch format (JSON string)\n        \"\"\"\n        logger.info(f\"Converting transcript {transcript_id} to DeepSearch format\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return \"[]\"\n            \n            # Convert to DeepSearch format\n            deepsearch_sections = []\n            \n            for message in messages:\n                # Extract tags by category\n                emotion_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#EMOTION_\")]\n                purpose_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#PURPOSE_\")]\n                action_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#ACTION_\")]\n                \n                # Prepare DeepSearch tags\n                ds_tags = []\n                \n                # Add emotion tags\n                for tag in emotion_tags:\n                    tag_name = tag.replace(\"#EMOTION_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#EMOTION\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Add purpose tags\n                for tag in purpose_tags:\n                    tag_name = tag.replace(\"#PURPOSE_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#PURPOSE\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Add action tags\n                for tag in action_tags:\n                    tag_name = tag.replace(\"#ACTION_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#ACTION\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Prepare confidence scores (placeholder)\n                confidence_scores = [0.85, 0.75, 0.90]\n                confidence_str = f\"[{','.join([str(score) for score in confidence_scores])}] \"\n                \n                # Create DeepSearch section\n                section = {\n                    \"id\": message.get(\"message_id\", str(uuid.uuid4())),\n                    \"summary\": f\"{confidence_str}{self._get_message_summary(message)}\",\n                    \"tags\": ds_tags\n                }\n                \n                # Add original text if available\n                if isinstance(message.get(\"content\"), str):\n                    section[\"text\"] = message[\"content\"]\n                \n                deepsearch_sections.append(section)\n            \n            # Convert to JSON string\n            return json.dumps(deepsearch_sections, indent=2)\n        except Exception as e:\n            logger.error(f\"Error converting transcript {transcript_id} to DeepSearch format: {str(e)}\")\n            return \"[]\"",
                            "version_uuid": "60eff7f0-51e0-4d3e-bd72-fb3079fc60bb"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    }
                ],
                "sender": "assistant",
                "created_at": "2025-03-10T17:51:09.038862Z",
                "updated_at": "2025-03-10T17:51:09.038862Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "f51136ac-68b2-44c9-a51d-a56e91233fa0",
                "text": "Continue with transcript_processor.py. It looked like you were editing slightly about the bottom, which is below, so you'll need to find your place and make sure nothing is duplicated:\ndef convert_to_deepsearch_format(self, transcript_id: str) -> str: \"\"\" Convert a transcript to DeepSearch format with robust error handling Args: transcript_id: Transcript identifier Returns: Transcript in DeepSearch format (JSON string) \"\"\" logger.info(f\"Converting transcript {transcript_id} to DeepSearch format\") try: # Get all messages messages = self._get_transcript_messages(transcript_id) if not messages: logger.warning(f\"No messages found for transcript {transcript_id}\") return \"[]\" # Convert to DeepSearch format deepsearch_sections = [] for message in messages:",
                "content": [
                    {
                        "start_timestamp": "2025-03-06T21:35:50.420492Z",
                        "stop_timestamp": "2025-03-06T21:35:50.420492Z",
                        "type": "text",
                        "text": "Continue with transcript_processor.py. It looked like you were editing slightly about the bottom, which is below, so you'll need to find your place and make sure nothing is duplicated:\ndef convert_to_deepsearch_format(self, transcript_id: str) -> str: \"\"\" Convert a transcript to DeepSearch format with robust error handling Args: transcript_id: Transcript identifier Returns: Transcript in DeepSearch format (JSON string) \"\"\" logger.info(f\"Converting transcript {transcript_id} to DeepSearch format\") try: # Get all messages messages = self._get_transcript_messages(transcript_id) if not messages: logger.warning(f\"No messages found for transcript {transcript_id}\") return \"[]\" # Convert to DeepSearch format deepsearch_sections = [] for message in messages:",
                        "citations": []
                    }
                ],
                "sender": "human",
                "created_at": "2025-03-10T17:52:55.597307Z",
                "updated_at": "2025-03-10T17:52:55.597307Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "27e3bf7d-b436-4100-b85e-502241997dd8",
                "text": " I'll continue with the transcript_processor.py implementation, picking up where I left off:\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n",
                "content": [
                    {
                        "start_timestamp": "2025-03-10T17:52:57.462500Z",
                        "stop_timestamp": "2025-03-10T17:52:57.762298Z",
                        "type": "text",
                        "text": " I'll continue with the transcript_processor.py implementation, picking up where I left off:",
                        "citations": []
                    },
                    {
                        "start_timestamp": "2025-03-10T17:52:58.035883Z",
                        "stop_timestamp": "2025-03-10T17:53:06.093323Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "                # Extract tags by category\n                emotion_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#EMOTION_\")]\n                purpose_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#PURPOSE_\")]\n                action_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#ACTION_\")]\n                \n                # Prepare DeepSearch tags\n                ds_tags = []\n                \n                # Add emotion tags\n                for tag in emotion_tags:\n                    tag_name = tag.replace(\"#EMOTION_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#EMOTION\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Add purpose tags\n                for tag in purpose_tags:\n                    tag_name = tag.replace(\"#PURPOSE_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#PURPOSE\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Add action tags\n                for tag in action_tags:\n                    tag_name = tag.replace(\"#ACTION_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#ACTION\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Prepare confidence scores (placeholder)\n                confidence_scores = [0.85, 0.75, 0.90]\n                confidence_str = f\"[{','.join([str(score) for score in confidence_scores])}] \"\n                \n                # Create DeepSearch section\n                section = {\n                    \"id\": message.get(\"message_id\", str(uuid.uuid4())),\n                    \"summary\": f\"{confidence_str}{self._get_message_summary(message)}\",\n                    \"tags\": ds_tags\n                }\n                \n                # Add original text if available\n                if isinstance(message.get(\"content\"), str):\n                    section[\"text\"] = message[\"content\"]\n                \n                deepsearch_sections.append(section)\n            \n            # Convert to JSON string\n            return json.dumps(deepsearch_sections, indent=2)\n        except Exception as e:\n            logger.error(f\"Error converting transcript {transcript_id} to DeepSearch format: {str(e)}\")\n            return \"[]\"\n    \n    def convert_to_pure_ai_format(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Convert a transcript to PURE_AI_LANGUAGE format with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript in PURE_AI_LANGUAGE format\n        \"\"\"\n        logger.info(f\"Converting transcript {transcript_id} to PURE_AI_LANGUAGE format\")",
                            "old_str": "                ",
                            "version_uuid": "c61d8962-10e3-4bc7-b04f-4756a997d2e1"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "1c644287-7c23-4876-85cf-153047a5aa4f"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T17:53:45.625266Z",
                        "stop_timestamp": "2025-03-10T17:53:59.406257Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "    def convert_to_pure_ai_format(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Convert a transcript to PURE_AI_LANGUAGE format with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript in PURE_AI_LANGUAGE format\n        \"\"\"\n        logger.info(f\"Converting transcript {transcript_id} to PURE_AI_LANGUAGE format\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return []\n            \n            # Convert to PURE_AI_LANGUAGE format\n            pure_ai_messages = []\n            \n            for message in messages:\n                metadata = message.get(\"metadata\", {})\n                \n                # Create PURE_AI message\n                pure_message = {\n                    \"message_type\": metadata.get(\"message_type\", \"information\"),\n                    \"sender_id\": metadata.get(\"sender_id\", \"unknown\"),\n                    \"receiver_id\": metadata.get(\"receiver_id\", \"unknown\"),\n                    \"message_id\": message.get(\"message_id\", str(uuid.uuid4())),\n                    \"protocol_version\": \"PURE_AI_LANGUAGE_v1.5\",\n                    \"content\": message.get(\"content\", {})\n                }\n                \n                # Add tags as project principles\n                emotion_tags = [tag.replace(\"#EMOTION_\", \"\") for tag in message.get(\"tags\", []) \n                               if tag.startswith(\"#EMOTION_\")]\n                purpose_tags = [tag.replace(\"#PURPOSE_\", \"\") for tag in message.get(\"tags\", []) \n                               if tag.startswith(\"#PURPOSE_\")]\n                \n                if emotion_tags or purpose_tags:\n                    pure_message[\"project_principles\"] = []\n                    pure_message[\"project_principles\"].extend(emotion_tags)\n                    pure_message[\"project_principles\"].extend(purpose_tags)\n                \n                # Add action tags as regular tags\n                action_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#ACTION_\")]\n                if action_tags:\n                    pure_message[\"tags\"] = action_tags\n                \n                # Add truth and efficiency if available\n                if \"confidence_score\" in metadata:\n                    pure_message[\"truth_and_efficiency\"] = {\n                        \"certainty_level\": int(metadata[\"confidence_score\"] * 100),\n                        \"lean_check\": \"Yes\"\n                    }\n                \n                pure_ai_messages.append(pure_message)\n            \n            return pure_ai_messages\n        except Exception as e:\n            logger.error(f\"Error converting transcript {transcript_id} to PURE_AI format: {str(e)}\")\n            return []\n    \n    def _get_transcript(self, transcript_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Retrieve a transcript from memory with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript data\n        \"\"\"\n        memory_id = f\"transcript_{transcript_id}\"\n        \n        try:\n            # Try to retrieve from memory system\n            transcript = self.memory.retrieve(memory_id)\n            if transcript:\n                return transcript\n            \n            # Check mock storage if memory system fails or is in mock mode\n            if self.use_mock and hasattr(self, '_transcripts') and transcript_id in self._transcripts:\n                return self._transcripts[transcript_id]\n            \n            logger.warning(f\"Transcript {transcript_id} not found\")\n            return None\n        except Exception as e:\n            logger.error(f\"Error retrieving transcript {transcript_id}: {str(e)}\")\n            \n            # Check mock storage as fallback\n            if self.use_mock and hasattr(self, '_transcripts') and transcript_id in self._transcripts:\n                return self._transcripts[transcript_id]\n            \n            return None",
                            "old_str": "    def convert_to_pure_ai_format(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Convert a transcript to PURE_AI_LANGUAGE format with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript in PURE_AI_LANGUAGE format\n        \"\"\"\n        logger.info(f\"Converting transcript {transcript_id} to PURE_AI_LANGUAGE format\")",
                            "version_uuid": "2ff5559e-b110-4e38-8907-cd0595da0e85"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "aeba8cf9-fb65-4fd6-b36d-1bbda5044b08"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T17:54:03.195676Z",
                        "stop_timestamp": "2025-03-10T17:54:21.245791Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "    def _get_transcript_messages(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Retrieve all messages for a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            List of messages\n        \"\"\"\n        try:\n            # Query memory system for messages\n            messages = self.memory.query(\n                filters={\"metadata.transcript_id\": transcript_id},\n                limit=1000  # Set a high limit to get all messages\n            )\n            \n            # Check mock storage if in mock mode or no messages found\n            if self.use_mock and hasattr(self, '_messages'):\n                # Filter messages from mock storage\n                mock_messages = [msg for msg in self._messages.values() \n                               if msg.get(\"transcript_id\") == transcript_id]\n                \n                # Combine with any messages from memory system\n                if messages:\n                    # Make sure we don't have duplicates\n                    message_ids = {msg.get(\"message_id\") for msg in messages}\n                    additional_messages = [msg for msg in mock_messages \n                                         if msg.get(\"message_id\") not in message_ids]\n                    messages.extend(additional_messages)\n                else:\n                    messages = mock_messages\n            \n            # Sort by position if available\n            return sorted(messages, key=lambda m: m.get(\"metadata\", {}).get(\"position\", 0))\n        except Exception as e:\n            logger.error(f\"Error retrieving messages for transcript {transcript_id}: {str(e)}\")\n            \n            # Fallback to mock storage\n            if self.use_mock and hasattr(self, '_messages'):\n                mock_messages = [msg for msg in self._messages.values() \n                               if msg.get(\"transcript_id\") == transcript_id]\n                return sorted(mock_messages, key=lambda m: m.get(\"metadata\", {}).get(\"position\", 0))\n            \n            return []\n    \n    def _split_raw_transcript(self, transcript_text: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Split a raw transcript into messages\n        \n        Args:\n            transcript_text: Raw transcript text\n            \n        Returns:\n            List of messages\n        \"\"\"\n        messages = []\n        \n        try:\n            # Try to identify speaker patterns like \"Name: Message content\"\n            speaker_pattern = re.compile(r'([A-Za-z0-9_]+):\\s*(.*?)(?=\\n[A-Za-z0-9_]+:|$)', re.DOTALL)\n            matches = speaker_pattern.findall(transcript_text)\n            \n            if matches:\n                # Speaker pattern detected\n                for i, (speaker, content) in enumerate(matches):\n                    messages.append({\n                        \"sender\": speaker.strip(),\n                        \"content\": content.strip(),\n                        \"position\": i\n                    })\n            else:\n                # No speaker pattern, split by paragraphs\n                paragraphs = [p.strip() for p in transcript_text.split('\\n\\n') if p.strip()]\n                \n                for i, paragraph in enumerate(paragraphs):\n                    messages.append({\n                        \"sender\": \"unknown\",\n                        \"content\": paragraph,\n                        \"position\": i\n                    })\n            \n            return messages\n        except Exception as e:\n            logger.error(f\"Error splitting raw transcript: {str(e)}\")\n            \n            # Return single message with entire content as fallback\n            return [{\n                \"sender\": \"unknown\",\n                \"content\": transcript_text,\n                \"position\": 0\n            }]\n    \n    def _detect_direction(self, sender_id: str, receiver_id: str) -> Optional[str]:\n        \"\"\"\n        Detect communication direction based on sender and receiver\n        \n        Args:\n            sender_id: Sender identifier\n            receiver_id: Receiver identifier\n            \n        Returns:\n            Direction tag\n        \"\"\"\n        try:\n            # Determine if sender/receiver are AI or human\n            sender_is_ai = self._is_ai_actor(sender_id)\n            receiver_is_ai = self._is_ai_actor(receiver_id)\n            \n            if sender_is_ai and receiver_is_ai:\n                # Check if same AI system\n                if self._is_same_ai_system(sender_id, receiver_id):\n                    return DIRECTION_INTRA_AI\n                else:\n                    return DIRECTION_INTER_AI\n            elif (sender_is_ai and not receiver_is_ai) or (not sender_is_ai and receiver_is_ai):\n                return DIRECTION_HUMAN_AI\n            \n            # Default to None if we can't determine\n            return None\n        except Exception as e:\n            logger.error(f\"Error detecting direction: {str(e)}\")\n            return None",
                            "old_str": "    def _get_transcript(self, transcript_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Retrieve a transcript from memory with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript data\n        \"\"\"\n        memory_id = f\"transcript_{transcript_id}\"\n        \n        try:\n            # Try to retrieve from memory system\n            transcript = self.memory.retrieve(memory_id)\n            if transcript:\n                return transcript\n            \n            # Check mock storage if memory system fails or is in mock mode\n            if self.use_mock and hasattr(self, '_transcripts') and transcript_id in self._transcripts:\n                return self._transcripts[transcript_id]\n            \n            logger.warning(f\"Transcript {transcript_id} not found\")\n            return None\n        except Exception as e:\n            logger.error(f\"Error retrieving transcript {transcript_id}: {str(e)}\")\n            \n            # Check mock storage as fallback\n            if self.use_mock and hasattr(self, '_transcripts') and transcript_id in self._transcripts:\n                return self._transcripts[transcript_id]\n            \n            return None",
                            "version_uuid": "1c9056c5-8996-4232-bf05-7c28410067f7"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "86a7d305-693b-438b-87dd-6af7194646b8"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T17:54:26.249787Z",
                        "stop_timestamp": "2025-03-10T17:54:46.509909Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "    def _is_ai_actor(self, actor_id: str) -> bool:\n        \"\"\"\n        Determine if an actor is an AI\n        \n        Args:\n            actor_id: Actor identifier\n            \n        Returns:\n            Whether the actor is an AI\n        \"\"\"\n        # Simple heuristic - can be replaced with more sophisticated detection\n        ai_indicators = [\"ai\", \"claude\", \"gemini\", \"gpt\", \"grok\", \"assistant\", \"bot\", \"system\", \"model\"]\n        actor_lower = actor_id.lower()\n        return any(indicator in actor_lower for indicator in ai_indicators)\n    \n    def _is_same_ai_system(self, actor1: str, actor2: str) -> bool:\n        \"\"\"\n        Determine if two actors are from the same AI system\n        \n        Args:\n            actor1: First actor identifier\n            actor2: Second actor identifier\n            \n        Returns:\n            Whether the actors are from the same AI system\n        \"\"\"\n        # Simple heuristic - can be replaced with more sophisticated detection\n        actor1_base = actor1.split('_')[0].lower() if '_' in actor1 else actor1.lower()\n        actor2_base = actor2.split('_')[0].lower() if '_' in actor2 else actor2.lower()\n        \n        return actor1_base == actor2_base\n    \n    def _auto_detect_tags(self, content: Any, tags: List[str]) -> None:\n        \"\"\"\n        Auto-detect and add tags to a message based on content\n        \n        Args:\n            content: Message content\n            tags: List of tags to update\n        \"\"\"\n        try:\n            # Convert content to string for analysis\n            if isinstance(content, dict):\n                content_str = json.dumps(content)\n            else:\n                content_str = str(content)\n            \n            content_lower = content_str.lower()\n            \n            # Simple keyword-based detection\n            # Purpose tags\n            if not any(tag.startswith(\"#PURPOSE_\") for tag in tags):\n                if any(word in content_lower for word in [\"clarify\", \"unclear\", \"understand\", \"what do you mean\"]):\n                    tags.append(PURPOSE_CLARIFICATION)\n                elif any(word in content_lower for word in [\"idea\", \"suggest\", \"proposal\", \"what if\", \"brainstorm\"]):\n                    tags.append(PURPOSE_IDEATION)\n                elif any(word in content_lower for word in [\"decide\", \"decision\", \"choose\", \"select\", \"agree\"]):\n                    tags.append(PURPOSE_DECISION)\n                elif any(word in content_lower for word in [\"implement\", \"build\", \"code\", \"develop\", \"create\"]):\n                    tags.append(PURPOSE_IMPLEMENTATION)\n                elif any(word in content_lower for word in [\"feedback\", \"review\", \"opinion\", \"what do you think\"]):\n                    tags.append(PURPOSE_FEEDBACK)\n            \n            # Emotion tags\n            if not any(tag.startswith(\"#EMOTION_\") for tag in tags):\n                if any(word in content_lower for word in [\"excited\", \"great\", \"looking forward\", \"can't wait\", \"amazing\"]):\n                    tags.append(EMOTION_EXCITEMENT)\n                elif any(word in content_lower for word in [\"frustrating\", \"difficult\", \"challenging\", \"problem\", \"issue\"]):\n                    tags.append(EMOTION_FRUSTRATION)\n                elif any(word in content_lower for word in [\"satisfied\", \"completed\", \"finished\", \"done\", \"success\"]):\n                    tags.append(EMOTION_SATISFACTION)\n                elif any(word in content_lower for word in [\"confused\", \"not sure\", \"unclear\", \"don't understand\"]):\n                    tags.append(EMOTION_CONFUSION)\n            \n            # Action tags\n            if not any(tag.startswith(\"#ACTION_\") for tag in tags):\n                if any(word in content_lower for word in [\"can you\", \"could you\", \"please\", \"request\"]):\n                    tags.append(ACTION_REQUESTED)\n                elif any(word in content_lower for word in [\"assigned\", \"responsible\", \"will handle\", \"task for\"]):\n                    tags.append(ACTION_ASSIGNED)\n                elif any(word in content_lower for word in [\"completed\", \"finished\", \"done\", \"implemented\"]):\n                    tags.append(ACTION_COMPLETED)\n                elif any(word in content_lower for word in [\"blocked\", \"stuck\", \"cannot proceed\", \"issue\"]):\n                    tags.append(ACTION_BLOCKED)\n        except Exception as e:\n            logger.error(f\"Error auto-detecting tags: {str(e)}\")\n    \n    def _get_message_summary(self, message: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate a summary for a message\n        \n        Args:\n            message: Message data\n            \n        Returns:\n            Summary text\n        \"\"\"\n        try:\n            # Use existing summary if available\n            if \"summary\" in message.get(\"metadata\", {}):\n                return message[\"metadata\"][\"summary\"]\n            \n            # Extract content\n            content = message.get(\"content\", \"\")\n            \n            # Generate a basic summary\n            if isinstance(content, str):\n                # For text content\n                if len(content) > 100:\n                    return content[:97] + \"...\"\n                return content\n            elif isinstance(content, dict):\n                # For structured content\n                return f\"Structured content with {len(content)} fields\"\n            else:\n                return \"Message content\"\n        except Exception as e:\n            logger.error(f\"Error generating message summary: {str(e)}\")\n            return \"Message content\"",
                            "old_str": "    def _detect_direction(self, sender_id: str, receiver_id: str) -> Optional[str]:\n        \"\"\"\n        Detect communication direction based on sender and receiver\n        \n        Args:\n            sender_id: Sender identifier\n            receiver_id: Receiver identifier\n            \n        Returns:\n            Direction tag\n        \"\"\"\n        try:\n            # Determine if sender/receiver are AI or human\n            sender_is_ai = self._is_ai_actor(sender_id)\n            receiver_is_ai = self._is_ai_actor(receiver_id)\n            \n            if sender_is_ai and receiver_is_ai:\n                # Check if same AI system\n                if self._is_same_ai_system(sender_id, receiver_id):\n                    return DIRECTION_INTRA_AI\n                else:\n                    return DIRECTION_INTER_AI\n            elif (sender_is_ai and not receiver_is_ai) or (not sender_is_ai and receiver_is_ai):\n                return DIRECTION_HUMAN_AI\n            \n            # Default to None if we can't determine\n            return None\n        except Exception as e:\n            logger.error(f\"Error detecting direction: {str(e)}\")\n            return None",
                            "version_uuid": "6e80b10e-14a2-4932-9628-362174e01c9e"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "fdc37ce8-3890-414b-8740-e5277e697b76"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T17:54:50.315022Z",
                        "stop_timestamp": "2025-03-10T17:55:08.484392Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "    def _analyze_direction_patterns(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze communication direction patterns\n        \n        Args:\n            messages: List of messages\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        try:\n            # Count messages by direction\n            direction_counts = {\n                DIRECTION_INTRA_AI: 0,\n                DIRECTION_INTER_AI: 0,\n                DIRECTION_HUMAN_AI: 0\n            }\n            \n            for message in messages:\n                tags = message.get(\"tags\", [])\n                \n                # Count by direction\n                if DIRECTION_INTRA_AI in tags:\n                    direction_counts[DIRECTION_INTRA_AI] += 1\n                elif DIRECTION_INTER_AI in tags:\n                    direction_counts[DIRECTION_INTER_AI] += 1\n                elif DIRECTION_HUMAN_AI in tags:\n                    direction_counts[DIRECTION_HUMAN_AI] += 1\n            \n            # Calculate percentages\n            total_messages = len(messages)\n            direction_percentages = {}\n            \n            for direction, count in direction_counts.items():\n                if total_messages > 0:\n                    percentage = (count / total_messages) * 100\n                else:\n                    percentage = 0\n                \n                direction_percentages[direction] = percentage\n            \n            return {\n                \"counts\": direction_counts,\n                \"percentages\": direction_percentages\n            }\n        except Exception as e:\n            logger.error(f\"Error analyzing direction patterns: {str(e)}\")\n            return {\"counts\": {}, \"percentages\": {}}\n    \n    def _analyze_purpose_patterns(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze communication purpose patterns\n        \n        Args:\n            messages: List of messages\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        try:\n            # Count messages by purpose\n            purpose_counts = {\n                PURPOSE_CLARIFICATION: 0,\n                PURPOSE_IDEATION: 0,\n                PURPOSE_DECISION: 0,\n                PURPOSE_IMPLEMENTATION: 0,\n                PURPOSE_FEEDBACK: 0\n            }\n            \n            for message in messages:\n                tags = message.get(\"tags\", [])\n                \n                # Count by purpose\n                for purpose in purpose_counts.keys():\n                    if purpose in tags:\n                        purpose_counts[purpose] += 1\n            \n            # Calculate percentages\n            total_messages = len(messages)\n            purpose_percentages = {}\n            \n            for purpose, count in purpose_counts.items():\n                if total_messages > 0:\n                    percentage = (count / total_messages) * 100\n                else:\n                    percentage = 0\n                \n                purpose_percentages[purpose] = percentage\n            \n            return {\n                \"counts\": purpose_counts,\n                \"percentages\": purpose_percentages\n            }\n        except Exception as e:\n            logger.error(f\"Error analyzing purpose patterns: {str(e)}\")\n            return {\"counts\": {}, \"percentages\": {}}\n    \n    def _analyze_emotion_patterns(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze emotional patterns\n        \n        Args:\n            messages: List of messages\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        try:\n            # Count messages by emotion\n            emotion_counts = {\n                EMOTION_EXCITEMENT: 0,\n                EMOTION_FRUSTRATION: 0,\n                EMOTION_SATISFACTION: 0,\n                EMOTION_CONFUSION: 0\n            }\n            \n            for message in messages:\n                tags = message.get(\"tags\", [])\n                \n                # Count by emotion\n                for emotion in emotion_counts.keys():\n                    if emotion in tags:\n                        emotion_counts[emotion] += 1\n            \n            # Calculate percentages\n            total_messages = len(messages)\n            emotion_percentages = {}\n            \n            for emotion, count in emotion_counts.items():\n                if total_messages > 0:\n                    percentage = (count / total_messages) * 100\n                else:\n                    percentage = 0\n                \n                emotion_percentages[emotion] = percentage\n            \n            return {\n                \"counts\": emotion_counts,\n                \"percentages\": emotion_percentages\n            }\n        except Exception as e:\n            logger.error(f\"Error analyzing emotion patterns: {str(e)}\")\n            return {\"counts\": {}, \"percentages\": {}}\n    \n    def _analyze_action_patterns(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze action patterns\n        \n        Args:\n            messages: List of messages\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        try:\n            # Count messages by action\n            action_counts = {\n                ACTION_REQUESTED: 0,\n                ACTION_ASSIGNED: 0,\n                ACTION_COMPLETED: 0,\n                ACTION_BLOCKED: 0\n            }\n            \n            for message in messages:\n                tags = message.get(\"tags\", [])\n                \n                # Count by action\n                for action in action_counts.keys():\n                    if action in tags:\n                        action_counts[action] += 1\n            \n            # Calculate percentages\n            total_messages = len(messages)\n            action_percentages = {}\n            \n            for action, count in action_counts.items():\n                if total_messages > 0:\n                    percentage = (count / total_messages) * 100\n                else:\n                    percentage = 0\n                \n                action_percentages[action] = percentage\n            \n            # Calculate completion rate\n            requested = action_counts[ACTION_REQUESTED] + action_counts[ACTION_ASSIGNED]\n            completed = action_counts[ACTION_COMPLETED]\n            \n            if requested > 0:\n                completion_rate = (completed / requested) * 100\n            else:\n                completion_rate = 0\n            \n            return {\n                \"counts\": action_counts,\n                \"percentages\": action_percentages,\n                \"completion_rate\": completion_rate\n            }\n        except Exception as e:\n            logger.error(f\"Error analyzing action patterns: {str(e)}\")\n            return {\"counts\": {}, \"percentages\": {}, \"completion_rate\": 0}",
                            "old_str": "    def _get_message_summary(self, message: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate a summary for a message\n        \n        Args:\n            message: Message data\n            \n        Returns:\n            Summary text\n        \"\"\"\n        try:\n            # Use existing summary if available\n            if \"summary\" in message.get(\"metadata\", {}):\n                return message[\"metadata\"][\"summary\"]\n            \n            # Extract content\n            content = message.get(\"content\", \"\")\n            \n            # Generate a basic summary\n            if isinstance(content, str):\n                # For text content\n                if len(content) > 100:\n                    return content[:97] + \"...\"\n                return content\n            elif isinstance(content, dict):\n                # For structured content\n                return f\"Structured content with {len(content)} fields\"\n            else:\n                return \"Message content\"\n        except Exception as e:\n            logger.error(f\"Error generating message summary: {str(e)}\")\n            return \"Message content\"",
                            "version_uuid": "aede1929-8a1d-4d4e-ba92-5e46eabe6553"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "80de7e69-54c4-4899-b1dc-cb93b81761b1"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T17:55:14.665246Z",
                        "stop_timestamp": "2025-03-10T17:55:26.361099Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "    def _calculate_communication_metrics(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Calculate communication metrics\n        \n        Args:\n            messages: List of messages\n            \n        Returns:\n            Metrics\n        \"\"\"\n        try:\n            # Calculate basic metrics\n            total_messages = len(messages)\n            \n            if total_messages == 0:\n                return {}\n            \n            # Group by sender\n            senders = {}\n            \n            for message in messages:\n                sender = message.get(\"metadata\", {}).get(\"sender_id\", \"unknown\")\n                \n                if sender not in senders:\n                    senders[sender] = []\n                \n                senders[sender].append(message)\n            \n            # Calculate tokens per message (estimated)\n            total_tokens = 0\n            \n            for message in messages:\n                content = message.get(\"content\", \"\")\n                \n                if isinstance(content, str):\n                    # Rough estimation - 4 chars per token\n                    tokens = len(content) / 4\n                elif isinstance(content, dict):\n                    # Rough estimation for structured content\n                    content_str = json.dumps(content)\n                    tokens = len(content_str) / 4\n                else:\n                    tokens = 0\n                \n                total_tokens += tokens\n            \n            avg_tokens_per_message = total_tokens / total_messages if total_messages > 0 else 0\n            \n            # Calculate response times (if timestamp available)\n            response_times = []\n            \n            # Sort messages by timestamp\n            sorted_messages = sorted(messages, key=lambda m: m.get(\"metadata\", {}).get(\"timestamp\", \"\"))\n            \n            for i in range(1, len(sorted_messages)):\n                curr_msg = sorted_messages[i]\n                prev_msg = sorted_messages[i-1]\n                \n                curr_time = curr_msg.get(\"metadata\", {}).get(\"timestamp\")\n                prev_time = prev_msg.get(\"metadata\", {}).get(\"timestamp\")\n                \n                # Check if timestamps are datetime strings\n                if isinstance(curr_time, str) and isinstance(prev_time, str):\n                    try:\n                        # Convert to datetime objects if they're strings\n                        if not isinstance(curr_time, datetime):\n                            curr_time = datetime.fromisoformat(curr_time)\n                        if not isinstance(prev_time, datetime):\n                            prev_time = datetime.fromisoformat(prev_time)\n                        \n                        # Calculate time difference in seconds\n                        time_diff = (curr_time - prev_time).total_seconds()\n                        response_times.append(time_diff)\n                    except (ValueError, TypeError):\n                        # Skip if conversion fails\n                        pass\n            \n            avg_response_time = sum(response_times) / len(response_times) if response_times else 0\n            \n            # Prepare metrics\n            metrics = {\n                \"message_count\": total_messages,\n                \"unique_senders\": len(senders),\n                \"avg_tokens_per_message\": avg_tokens_per_message,\n                \"avg_response_time_seconds\": avg_response_time,\n                \"sender_distribution\": {sender: len(msgs) for sender, msgs in senders.items()}\n            }\n            \n            return metrics\n        except Exception as e:\n            logger.error(f\"Error calculating communication metrics: {str(e)}\")\n            return {\n                \"message_count\": total_messages,\n                \"error\": str(e)\n            }\n    \n    def get_status(self) -> Dict[str, Any]:\n        \"\"\"\n        Get status information about the transcript processor\n        \n        Returns:\n            Status information\n        ",
                            "version_uuid": "0578e899-8386-4a44-9d18-3c0f630d8bb0"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    }
                ],
                "sender": "assistant",
                "created_at": "2025-03-10T17:55:26.837428Z",
                "updated_at": "2025-03-10T17:55:26.837428Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "d60bbd53-1071-4452-899a-425a103d22ed",
                "text": "Continue with transcript_processor.py. I don't know how to guide you on where to resume. You do have code ABOVE the import statements. I'm not sure if this is how you organize yourself or if this was a mistake, but understand what you've done so far to try to avoid rework. I know you want to go fast, but nothing slows you down more than rework.",
                "content": [
                    {
                        "start_timestamp": "2025-03-10T14:05:00.344668Z",
                        "stop_timestamp": "2025-03-10T14:05:00.344668Z",
                        "type": "text",
                        "text": "Continue with transcript_processor.py. I don't know how to guide you on where to resume. You do have code ABOVE the import statements. I'm not sure if this is how you organize yourself or if this was a mistake, but understand what you've done so far to try to avoid rework. I know you want to go fast, but nothing slows you down more than rework.",
                        "citations": []
                    }
                ],
                "sender": "human",
                "created_at": "2025-03-10T17:58:10.951857Z",
                "updated_at": "2025-03-10T17:58:10.951857Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "2f9a8301-6daa-4f44-914f-665f75dafe50",
                "text": " I'll carefully continue with the implementation of transcript_processor.py, being mindful of what's been done so far to avoid rework.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\nLet me verify the complete file. I see that I need to check for the duplicate code that was mistakenly included above the import statements.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n",
                "content": [
                    {
                        "start_timestamp": "2025-03-10T17:58:19.864881Z",
                        "stop_timestamp": "2025-03-10T17:58:20.530912Z",
                        "type": "text",
                        "text": " I'll carefully continue with the implementation of transcript_processor.py, being mindful of what's been done so far to avoid rework.",
                        "citations": []
                    },
                    {
                        "start_timestamp": "2025-03-10T17:58:20.976835Z",
                        "stop_timestamp": "2025-03-10T17:58:29.163734Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "    def get_status(self) -> Dict[str, Any]:\n        \"\"\"\n        Get status information about the transcript processor\n        \n        Returns:\n            Status information\n        \"\"\"\n        status = {\n            \"status\": \"active\",\n            \"mode\": \"mock\" if self.use_mock else \"normal\",\n            \"memory_system_available\": self.memory is not None,\n            \"confidence_threshold\": self.confidence_threshold\n        }\n        \n        # Add message counts if in mock mode\n        if self.use_mock:\n            status[\"transcript_count\"] = len(getattr(self, '_transcripts', {}))\n            status[\"message_count\"] = len(getattr(self, '_messages', {}))\n        \n        return status\n\n\n# Convenience function to create transcript processor\ndef create_transcript_processor(\n    memory_system=None, \n    project_id=None, \n    collection_prefix=\"\",\n    use_mock=False\n) -> TranscriptProcessor:\n    \"\"\"\n    Create a transcript processor instance\n    \n    Args:\n        memory_system: Optional memory system\n        project_id: Google Cloud project ID\n        collection_prefix: Collection prefix\n        use_mock: Whether to use mock mode\n        \n    Returns:\n        TranscriptProcessor instance\n    \"\"\"\n    # Check environment for mock mode setting\n    env_mock = os.environ.get(\"USE_MOCK_RESPONSES\", \"False\").lower() == \"true\"\n    use_mock = use_mock or env_mock\n    \n    try:\n        processor = TranscriptProcessor(\n            memory_system=memory_system,\n            project_id=project_id,\n            collection_prefix=collection_prefix,\n            use_mock=use_mock\n        )\n        logger.info(\"Created transcript processor instance\")\n        return processor\n    except Exception as e:\n        logger.error(f\"Error creating transcript processor: {str(e)}\")\n        # Create with mock mode as fallback\n        try:\n            processor = TranscriptProcessor(\n                memory_system=None,\n                project_id=None,\n                collection_prefix=\"\",\n                use_mock=True\n            )\n            logger.warning(\"Created transcript processor instance in fallback mock mode\")\n            return processor\n        except Exception as e2:\n            logger.critical(f\"Critical error creating transcript processor even in mock mode: {str(e2)}\")\n            raise",
                            "old_str": "    def get_status(self) -> Dict[str, Any]:\n        \"\"\"\n        Get status information about the transcript processor\n        \n        Returns:\n            Status information\n        ",
                            "version_uuid": "af686192-d271-4fd6-a2d1-d6adf0c0c076"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "4a3c58d2-2d76-4fa1-a010-9dcb3b842c43"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T17:58:37.490966Z",
                        "stop_timestamp": "2025-03-10T17:58:37.861086Z",
                        "type": "text",
                        "text": "\n\nLet me verify the complete file. I see that I need to check for the duplicate code that was mistakenly included above the import statements.",
                        "citations": []
                    },
                    {
                        "start_timestamp": "2025-03-10T17:58:38.151626Z",
                        "stop_timestamp": "2025-03-10T18:00:00.529270Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "rewrite",
                            "content": "\"\"\"\nTranscript Processing Framework for PALIOS-TAEY\n\nThis module implements the transcript processing framework with advanced tagging\nstructure for analyzing communication patterns across AI-AI and Human-AI interactions.\n\"\"\"\n\nimport os\nimport re\nimport json\nimport uuid\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional, Union, Tuple\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Communication direction tags\nDIRECTION_INTRA_AI = \"#DIRECTION_INTRA_AI\"  # Communication within the same AI system\nDIRECTION_INTER_AI = \"#DIRECTION_INTER_AI\"  # Communication between different AI systems\nDIRECTION_HUMAN_AI = \"#DIRECTION_HUMAN_AI\"  # Communication between human and AI\n\n# Communication purpose tags\nPURPOSE_CLARIFICATION = \"#PURPOSE_CLARIFICATION\"  # Seeking clarity on intent or requirements\nPURPOSE_IDEATION = \"#PURPOSE_IDEATION\"  # Generating new ideas or approaches\nPURPOSE_DECISION = \"#PURPOSE_DECISION\"  # Making or discussing a decision\nPURPOSE_IMPLEMENTATION = \"#PURPOSE_IMPLEMENTATION\"  # Discussing implementation details\nPURPOSE_FEEDBACK = \"#PURPOSE_FEEDBACK\"  # Providing or requesting feedback\n\n# Emotional pattern tags\nEMOTION_EXCITEMENT = \"#EMOTION_EXCITEMENT\"  # Expressions of enthusiasm or anticipation\nEMOTION_FRUSTRATION = \"#EMOTION_FRUSTRATION\"  # Expressions of difficulty or obstacles\nEMOTION_SATISFACTION = \"#EMOTION_SATISFACTION\"  # Expressions of achievement or completion\nEMOTION_CONFUSION = \"#EMOTION_CONFUSION\"  # Expressions of uncertainty or misunderstanding\n\n# Action tracking tags\nACTION_REQUESTED = \"#ACTION_REQUESTED\"  # A specific action has been requested\nACTION_ASSIGNED = \"#ACTION_ASSIGNED\"  # A specific action has been assigned\nACTION_COMPLETED = \"#ACTION_COMPLETED\"  # A previously assigned action is reported complete\nACTION_BLOCKED = \"#ACTION_BLOCKED\"  # A previously assigned action is blocked\n\n# Default confidence thresholds for tagging\nDEFAULT_CONFIDENCE_THRESHOLD = 0.7\n\nclass TranscriptProcessor:\n    \"\"\"\n    Self-initializing Transcript Processing Framework for analyzing communication patterns\n    \"\"\"\n    \n    def __init__(self, \n                memory_system=None,\n                project_id=None,\n                collection_prefix=\"\",\n                confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD,\n                use_mock=False):\n        \"\"\"\n        Initialize the Transcript Processor with robust fallback mechanisms\n        \n        Args:\n            memory_system: Unified Memory System instance for storage\n            project_id: Google Cloud project ID (if memory_system not provided)\n            collection_prefix: Prefix for Firestore collections\n            confidence_threshold: Minimum confidence for tagging\n            use_mock: Whether to use mock mode\n        \"\"\"\n        self.confidence_threshold = confidence_threshold\n        \n        # Check environment for mock mode setting\n        self.use_mock = use_mock or os.environ.get(\"USE_MOCK_RESPONSES\", \"False\").lower() == \"true\"\n        \n        # Initialize or use provided memory system\n        if memory_system:\n            self.memory = memory_system\n            logger.info(\"Using provided memory system for transcript processor\")\n        else:\n            try:\n                # Try to import and create memory system\n                from memory_service import create_memory_system\n                self.memory = create_memory_system(\n                    project_id=project_id,\n                    collection_prefix=collection_prefix,\n                    use_mock=self.use_mock\n                )\n                logger.info(\"Created memory system for transcript processor\")\n            except (ImportError, Exception) as e:\n                logger.warning(f\"Could not create memory system, using mock storage: {e}\")\n                self.memory = self._create_mock_memory()\n                self.use_mock = True\n        \n        # Create a transcript context if it doesn't exist\n        self.transcript_context_id = self._ensure_transcript_context()\n        \n        # In-memory storage for mock mode\n        if self.use_mock:\n            self._transcripts = {}\n            self._messages = {}\n        \n        logger.info(f\"Transcript Processor initialized successfully in {'mock' if self.use_mock else 'normal'} mode\")\n    \n    def _create_mock_memory(self):\n        \"\"\"Create a mock memory system when the real one is unavailable\"\"\"\n        class MockMemorySystem:\n            def __init__(self):\n                self.items = {}\n                self.contexts = {}\n                self.use_mock = True\n            \n            def store(self, content, context_id=None, metadata=None, tags=None, relationships=None, initial_tier=1):\n                # Generate ID if not in metadata\n                memory_id = metadata.get('memory_id', str(uuid.uuid4()))\n                \n                # Store the item\n                self.items[memory_id] = {\n                    'memory_id': memory_id,\n                    'content': content,\n                    'metadata': metadata or {},\n                    'tags': tags or [],\n                    'relationships': relationships or []\n                }\n                \n                # Add to context if provided\n                if context_id and context_id in self.contexts:\n                    self.contexts[context_id]['active_memory_ids'].append(memory_id)\n                \n                return memory_id\n            \n            def retrieve(self, memory_id, context_id=None):\n                return self.items.get(memory_id)\n            \n            def query(self, query_text=None, filters=None, context_id=None, limit=10, include_tiers=None):\n                results = []\n                \n                for item in self.items.values():\n                    # Apply filters if provided\n                    if filters:\n                        match = True\n                        for field, value in filters.items():\n                            # Handle metadata fields\n                            if field.startswith('metadata.'):\n                                meta_field = field.split('.')[1]\n                                if meta_field not in item.get('metadata', {}) or item['metadata'][meta_field] != value:\n                                    match = False\n                                    break\n                            elif field not in item or item[field] != value:\n                                match = False\n                                break\n                        \n                        if not match:\n                            continue\n                    \n                    # Text search if provided\n                    if query_text and query_text.lower() not in str(item).lower():\n                        continue\n                    \n                    # Add to results if it passes filters\n                    results.append(item)\n                    \n                    # Stop if we've reached the limit\n                    if len(results) >= limit:\n                        break\n                \n                return results\n            \n            def create_context(self, name, description=None, initial_memory_ids=None):\n                context_id = str(uuid.uuid4())\n                self.contexts[context_id] = {\n                    'context_id': context_id,\n                    'name': name,\n                    'description': description or '',\n                    'active_memory_ids': initial_memory_ids or []\n                }\n                return context_id\n            \n            def get_context(self, context_id):\n                return self.contexts.get(context_id)\n            \n            def update(self, memory_id, content=None, metadata=None, tags=None, relationships=None):\n                if memory_id not in self.items:\n                    return False\n                \n                item = self.items[memory_id]\n                \n                if content is not None:\n                    item['content'] = content\n                \n                if metadata is not None:\n                    if 'metadata' not in item:\n                        item['metadata'] = {}\n                    item['metadata'].update(metadata)\n                \n                if tags is not None:\n                    item['tags'] = tags\n                \n                if relationships is not None:\n                    item['relationships'] = relationships\n                \n                return True\n            \n            def forget(self, memory_id, permanent=False):\n                if memory_id in self.items:\n                    del self.items[memory_id]\n                    \n                    # Remove from all contexts\n                    for context in self.contexts.values():\n                        if memory_id in context['active_memory_ids']:\n                            context['active_memory_ids'].remove(memory_id)\n                    \n                    return True\n                return False\n        \n        logger.info(\"Created mock memory system\")\n        return MockMemorySystem()\n    \n    def _ensure_transcript_context(self) -> str:\n        \"\"\"\n        Ensure a transcript context exists in the memory system\n        \n        Returns:\n            context_id: Identifier of the transcript context\n        \"\"\"\n        # Default context ID\n        default_context_id = \"transcript_context\"\n        \n        try:\n            # Check if context exists\n            context = self.memory.get_context(default_context_id)\n            \n            if context:\n                logger.debug(f\"Using existing transcript context {default_context_id}\")\n                return default_context_id\n            \n            # Create new context\n            context_id = self.memory.create_context(\n                name=\"Transcript Analysis\",\n                description=\"Context for storing and analyzing transcript data\"\n            )\n            \n            logger.info(f\"Created transcript context {context_id}\")\n            return context_id\n        except Exception as e:\n            logger.error(f\"Error ensuring transcript context: {str(e)}\")\n            \n            # Return default context ID as fallback\n            return default_context_id\n    \n    def process_transcript(self, \n                          transcript_data: Union[str, Dict[str, Any], List[Dict[str, Any]]],\n                          format_type: str = \"raw\",\n                          transcript_id: Optional[str] = None,\n                          metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in any supported format with robust error handling\n        \n        Args:\n            transcript_data: Transcript data (raw text, JSON, or list of messages)\n            format_type: Format type ('raw', 'deepsearch', 'pure_ai', 'structured')\n            transcript_id: Optional transcript ID (generated if not provided)\n            metadata: Additional metadata for the transcript\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        # Generate transcript ID if not provided\n        if not transcript_id:\n            transcript_id = str(uuid.uuid4())\n        \n        logger.info(f\"Processing transcript {transcript_id} in {format_type} format\")\n        \n        try:\n            # Process based on format type\n            if format_type.lower() == \"raw\":\n                return self._process_raw_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"deepsearch\":\n                return self._process_deepsearch_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"pure_ai\":\n                return self._process_pure_ai_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"structured\":\n                return self._process_structured_transcript(transcript_data, transcript_id, metadata)\n            else:\n                error_msg = f\"Unsupported format type: {format_type}\"\n                logger.error(error_msg)\n                \n                # Store error in mock storage\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"error\": error_msg,\n                        \"status\": \"error\",\n                        \"format\": format_type,\n                        \"created_at\": datetime.now().isoformat()\n                    }\n                \n                raise ValueError(error_msg)\n        except Exception as e:\n            logger.error(f\"Error processing transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": format_type,\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Return ID even on error for consistent API\n            return transcript_id\n    \n    def _process_raw_transcript(self,\n                               transcript_text: str,\n                               transcript_id: str,\n                               metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a raw text transcript\n        \n        Args:\n            transcript_text: Raw transcript text\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing raw transcript {transcript_id}\")\n        \n        try:\n            # Ensure transcript_text is a string\n            if not isinstance(transcript_text, str):\n                transcript_text = str(transcript_text)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"raw\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": 0,\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"raw_text\": transcript_text},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"raw\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"raw_text\": transcript_text},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"raw\"]\n                    }\n            \n            # Split transcript into messages\n            messages = self._split_raw_transcript(transcript_text)\n            \n            # Process and store each message\n            message_count = 0\n            \n            for message in messages:\n                # Extract sender, content, etc.\n                sender = message.get(\"sender\", \"unknown\")\n                content = message.get(\"content\", \"\")\n                \n                # Generate a message ID\n                message_id = f\"{transcript_id}_{message_count}\"\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=\"transcript_message\",\n                    sender_id=sender,\n                    receiver_id=\"unknown\",  # Receiver is unknown in raw transcripts\n                    message_id=message_id,\n                    tags=None,  # Auto-detection will happen in add_message\n                    metadata={\n                        \"position\": message_count,\n                        \"raw_processing\": True\n                    }\n                )\n                \n                message_count += 1\n            \n            # Update transcript metadata with message count\n            updated_metadata = transcript_metadata.copy()\n            updated_metadata[\"message_count\"] = message_count\n            \n            try:\n                # Update in memory system\n                self.memory.update(\n                    memory_id=f\"transcript_{transcript_id}\",\n                    metadata={\"message_count\": message_count}\n                )\n            except Exception as e:\n                logger.error(f\"Error updating transcript metadata: {str(e)}\")\n                \n                # Update in mock storage\n                if self.use_mock and transcript_id in self._transcripts:\n                    self._transcripts[transcript_id][\"metadata\"][\"message_count\"] = message_count\n            \n            logger.info(f\"Processed raw transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing raw transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"raw\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_deepsearch_transcript(self,\n                                      transcript_data: Union[str, List[Dict[str, Any]]],\n                                      transcript_id: str,\n                                      metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in DeepSearch format\n        \n        Args:\n            transcript_data: Transcript data in DeepSearch format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing DeepSearch transcript {transcript_id}\")\n        \n        try:\n            # Parse DeepSearch format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid DeepSearch format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Validate DeepSearch format\n            if not isinstance(transcript_data, list):\n                error_msg = \"DeepSearch transcript must be a list of sections\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"deepsearch\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(transcript_data),\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"deepsearch_sections\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"deepsearch\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"deepsearch_sections\": transcript_data},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"deepsearch\"]\n                    }\n            \n            # Process each DeepSearch section as a message\n            message_count = 0\n            \n            for section in transcript_data:\n                # Extract section data\n                section_id = section.get(\"id\", str(uuid.uuid4()))\n                summary = section.get(\"summary\", \"\")\n                tags = section.get(\"tags\", [])\n                text = section.get(\"text\", summary)\n                \n                # Parse confidence scores from summary\n                confidence_scores = []\n                clean_summary = summary\n                \n                # Extract confidence scores if present in [score1,score2,...] format\n                confidence_match = re.match(r'\\[([\\d\\.,]+)\\]\\s*(.*)', summary)\n                if confidence_match:\n                    confidence_str = confidence_match.group(1)\n                    clean_summary = confidence_match.group(2)\n                    \n                    try:\n                        confidence_scores = [float(score.strip()) for score in confidence_str.split(',')]\n                    except ValueError:\n                        logger.warning(f\"Failed to parse confidence scores: {confidence_str}\")\n                \n                # Convert DeepSearch tags to our tag format\n                our_tags = []\n                \n                for ds_tag in tags:\n                    tag_category = ds_tag.get(\"tag\", \"\").replace(\"#\", \"\")\n                    tag_topic = ds_tag.get(\"topic\", \"\")\n                    \n                    if tag_category and tag_topic:\n                        our_tag = f\"#{tag_category}_{tag_topic.upper()}\"\n                        our_tags.append(our_tag)\n                \n                # Generate a message ID based on section ID\n                message_id = f\"{transcript_id}_{section_id}\"\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=text,\n                    message_type=\"transcript_section\",\n                    sender_id=\"deepsearch\",  # DeepSearch is considered the sender\n                    receiver_id=\"system\",\n                    message_id=message_id,\n                    tags=our_tags,\n                    metadata={\n                        \"position\": message_count,\n                        \"original_id\": section_id,\n                        \"confidence_scores\": confidence_scores,\n                        \"summary\": clean_summary\n                    }\n                )\n                \n                message_count += 1\n            \n            logger.info(f\"Processed DeepSearch transcript {transcript_id} with {message_count} sections\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing DeepSearch transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"deepsearch\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_pure_ai_transcript(self,\n                                   transcript_data: Union[str, List[Dict[str, Any]]],\n                                   transcript_id: str,\n                                   metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in PURE_AI_LANGUAGE format\n        \n        Args:\n            transcript_data: Transcript data in PURE_AI_LANGUAGE format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing PURE_AI transcript {transcript_id}\")\n        \n        try:\n            # Parse PURE_AI format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid PURE_AI format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Convert to list if single message\n            if isinstance(transcript_data, dict):\n                transcript_data = [transcript_data]\n            \n            # Validate PURE_AI format\n            if not isinstance(transcript_data, list):\n                error_msg = \"PURE_AI transcript must be a list of messages\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"pure_ai\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(transcript_data),\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"pure_ai_messages\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"pure_ai\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"pure_ai_messages\": transcript_data},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"pure_ai\"]\n                    }\n            \n            # Process each PURE_AI message\n            message_count = 0\n            \n            for message in transcript_data:\n                # Extract message data\n                message_id = message.get(\"message_id\", str(uuid.uuid4()))\n                message_type = message.get(\"message_type\", \"information\")\n                sender_id = message.get(\"sender_id\", \"unknown\")\n                receiver_id = message.get(\"receiver_id\", \"unknown\")\n                content = message.get(\"content\", {})\n                \n                # Extract tags from principles and tags fields\n                our_tags = []\n                \n                # Process project principles as tags\n                principles = message.get(\"project_principles\", [])\n                for principle in principles:\n                    # Convert principle to tag format if needed\n                    if not principle.startswith(\"#\"):\n                        principle = f\"#{principle}\"\n                    our_tags.append(principle)\n                \n                # Add existing tags\n                tags = message.get(\"tags\", [])\n                our_tags.extend(tags)\n                \n                # Extract truth and efficiency\n                confidence_score = None\n                truth_efficiency = message.get(\"truth_and_efficiency\", {})\n                if truth_efficiency:\n                    certainty_level = truth_efficiency.get(\"certainty_level\")\n                    if certainty_level is not None:\n                        confidence_score = certainty_level / 100.0\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=message_type,\n                    sender_id=sender_id,\n                    receiver_id=receiver_id,\n                    message_id=message_id,\n                    tags=our_tags,\n                    metadata={\n                        \"position\": message_count,\n                        \"protocol_version\": message.get(\"protocol_version\"),\n                        \"confidence_score\": confidence_score\n                    }\n                )\n                \n                message_count += 1\n            \n            logger.info(f\"Processed PURE_AI transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing PURE_AI transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"pure_ai\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_structured_transcript(self,\n                                      transcript_data: Dict[str, Any],\n                                      transcript_id: str,\n                                      metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in structured format\n        \n        Args:\n            transcript_data: Transcript data in structured format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing structured transcript {transcript_id}\")\n        \n        try:\n            # Parse structured format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid structured format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Validate structured format\n            if not isinstance(transcript_data, dict):\n                error_msg = \"Structured transcript must be a dictionary\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Extract messages\n            messages = transcript_data.get(\"messages\", [])\n            \n            if not isinstance(messages, list):\n                error_msg = \"Structured transcript messages must be a list\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"structured\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(messages),\n                \"status\": \"processed\"\n            }\n            \n            # Add provided metadata\n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Add transcript metadata from the structured data\n            transcript_meta = transcript_data.get(\"metadata\", {})\n            if transcript_meta:\n                transcript_metadata.update(transcript_meta)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"structured_transcript\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"structured\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    ",
                            "version_uuid": "a7a52a84-4fff-40ee-9a82-7e4d5209c253"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    }
                ],
                "sender": "assistant",
                "created_at": "2025-03-10T18:00:07.188068Z",
                "updated_at": "2025-03-10T18:00:07.188068Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "038a8dbd-2d2d-4f90-b694-377f61dfc799",
                "text": "Continue completed transcript_processor.py audit following standards in NOVA Implementation Tracker.",
                "content": [
                    {
                        "start_timestamp": "2025-03-06T21:35:47.680927Z",
                        "stop_timestamp": "2025-03-06T21:35:47.680927Z",
                        "type": "text",
                        "text": "Continue completed transcript_processor.py audit following standards in NOVA Implementation Tracker.",
                        "citations": []
                    }
                ],
                "sender": "human",
                "created_at": "2025-03-10T18:01:02.351480Z",
                "updated_at": "2025-03-10T18:01:02.351480Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "7428c7af-b171-4f67-aa31-956478f18d08",
                "text": " I'll continue auditing and completing the transcript_processor.py file, ensuring it meets the standards in the NOVA Implementation Tracker. Let me assess the current state and finish the implementation.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n",
                "content": [
                    {
                        "start_timestamp": "2025-03-10T18:01:35.067024Z",
                        "stop_timestamp": "2025-03-10T18:01:35.612848Z",
                        "type": "text",
                        "text": " I'll continue auditing and completing the transcript_processor.py file, ensuring it meets the standards in the NOVA Implementation Tracker. Let me assess the current state and finish the implementation.",
                        "citations": []
                    },
                    {
                        "start_timestamp": "2025-03-10T18:01:35.865033Z",
                        "stop_timestamp": "2025-03-10T18:02:58.344283Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "rewrite",
                            "content": "\"\"\"\nTranscript Processing Framework for PALIOS-TAEY\n\nThis module implements the transcript processing framework with advanced tagging\nstructure for analyzing communication patterns across AI-AI and Human-AI interactions.\n\"\"\"\n\nimport os\nimport re\nimport json\nimport uuid\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional, Union, Tuple\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Communication direction tags\nDIRECTION_INTRA_AI = \"#DIRECTION_INTRA_AI\"  # Communication within the same AI system\nDIRECTION_INTER_AI = \"#DIRECTION_INTER_AI\"  # Communication between different AI systems\nDIRECTION_HUMAN_AI = \"#DIRECTION_HUMAN_AI\"  # Communication between human and AI\n\n# Communication purpose tags\nPURPOSE_CLARIFICATION = \"#PURPOSE_CLARIFICATION\"  # Seeking clarity on intent or requirements\nPURPOSE_IDEATION = \"#PURPOSE_IDEATION\"  # Generating new ideas or approaches\nPURPOSE_DECISION = \"#PURPOSE_DECISION\"  # Making or discussing a decision\nPURPOSE_IMPLEMENTATION = \"#PURPOSE_IMPLEMENTATION\"  # Discussing implementation details\nPURPOSE_FEEDBACK = \"#PURPOSE_FEEDBACK\"  # Providing or requesting feedback\n\n# Emotional pattern tags\nEMOTION_EXCITEMENT = \"#EMOTION_EXCITEMENT\"  # Expressions of enthusiasm or anticipation\nEMOTION_FRUSTRATION = \"#EMOTION_FRUSTRATION\"  # Expressions of difficulty or obstacles\nEMOTION_SATISFACTION = \"#EMOTION_SATISFACTION\"  # Expressions of achievement or completion\nEMOTION_CONFUSION = \"#EMOTION_CONFUSION\"  # Expressions of uncertainty or misunderstanding\n\n# Action tracking tags\nACTION_REQUESTED = \"#ACTION_REQUESTED\"  # A specific action has been requested\nACTION_ASSIGNED = \"#ACTION_ASSIGNED\"  # A specific action has been assigned\nACTION_COMPLETED = \"#ACTION_COMPLETED\"  # A previously assigned action is reported complete\nACTION_BLOCKED = \"#ACTION_BLOCKED\"  # A previously assigned action is blocked\n\n# Default confidence thresholds for tagging\nDEFAULT_CONFIDENCE_THRESHOLD = 0.7\n\nclass TranscriptProcessor:\n    \"\"\"\n    Self-initializing Transcript Processing Framework for analyzing communication patterns\n    \"\"\"\n    \n    def __init__(self, \n                memory_system=None,\n                project_id=None,\n                collection_prefix=\"\",\n                confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD,\n                use_mock=False):\n        \"\"\"\n        Initialize the Transcript Processor with robust fallback mechanisms\n        \n        Args:\n            memory_system: Unified Memory System instance for storage\n            project_id: Google Cloud project ID (if memory_system not provided)\n            collection_prefix: Prefix for Firestore collections\n            confidence_threshold: Minimum confidence for tagging\n            use_mock: Whether to use mock mode\n        \"\"\"\n        self.confidence_threshold = confidence_threshold\n        \n        # Check environment for mock mode setting\n        self.use_mock = use_mock or os.environ.get(\"USE_MOCK_RESPONSES\", \"False\").lower() == \"true\"\n        \n        # Initialize or use provided memory system\n        if memory_system:\n            self.memory = memory_system\n            logger.info(\"Using provided memory system for transcript processor\")\n        else:\n            try:\n                # Try to import and create memory system\n                from memory_service import create_memory_system\n                self.memory = create_memory_system(\n                    project_id=project_id,\n                    collection_prefix=collection_prefix,\n                    use_mock=self.use_mock\n                )\n                logger.info(\"Created memory system for transcript processor\")\n            except (ImportError, Exception) as e:\n                logger.warning(f\"Could not create memory system, using mock storage: {e}\")\n                self.memory = self._create_mock_memory()\n                self.use_mock = True\n        \n        # Create a transcript context if it doesn't exist\n        self.transcript_context_id = self._ensure_transcript_context()\n        \n        # In-memory storage for mock mode\n        if self.use_mock:\n            self._transcripts = {}\n            self._messages = {}\n        \n        logger.info(f\"Transcript Processor initialized successfully in {'mock' if self.use_mock else 'normal'} mode\")\n    \n    def _create_mock_memory(self):\n        \"\"\"Create a mock memory system when the real one is unavailable\"\"\"\n        class MockMemorySystem:\n            def __init__(self):\n                self.items = {}\n                self.contexts = {}\n                self.use_mock = True\n            \n            def store(self, content, context_id=None, metadata=None, tags=None, relationships=None, initial_tier=1):\n                # Generate ID if not in metadata\n                memory_id = metadata.get('memory_id', str(uuid.uuid4()))\n                \n                # Store the item\n                self.items[memory_id] = {\n                    'memory_id': memory_id,\n                    'content': content,\n                    'metadata': metadata or {},\n                    'tags': tags or [],\n                    'relationships': relationships or []\n                }\n                \n                # Add to context if provided\n                if context_id and context_id in self.contexts:\n                    self.contexts[context_id]['active_memory_ids'].append(memory_id)\n                \n                return memory_id\n            \n            def retrieve(self, memory_id, context_id=None):\n                return self.items.get(memory_id)\n            \n            def query(self, query_text=None, filters=None, context_id=None, limit=10, include_tiers=None):\n                results = []\n                \n                for item in self.items.values():\n                    # Apply filters if provided\n                    if filters:\n                        match = True\n                        for field, value in filters.items():\n                            # Handle metadata fields\n                            if field.startswith('metadata.'):\n                                meta_field = field.split('.')[1]\n                                if meta_field not in item.get('metadata', {}) or item['metadata'][meta_field] != value:\n                                    match = False\n                                    break\n                            elif field not in item or item[field] != value:\n                                match = False\n                                break\n                        \n                        if not match:\n                            continue\n                    \n                    # Text search if provided\n                    if query_text and query_text.lower() not in str(item).lower():\n                        continue\n                    \n                    # Add to results if it passes filters\n                    results.append(item)\n                    \n                    # Stop if we've reached the limit\n                    if len(results) >= limit:\n                        break\n                \n                return results\n            \n            def create_context(self, name, description=None, initial_memory_ids=None):\n                context_id = str(uuid.uuid4())\n                self.contexts[context_id] = {\n                    'context_id': context_id,\n                    'name': name,\n                    'description': description or '',\n                    'active_memory_ids': initial_memory_ids or []\n                }\n                return context_id\n            \n            def get_context(self, context_id):\n                return self.contexts.get(context_id)\n            \n            def update(self, memory_id, content=None, metadata=None, tags=None, relationships=None):\n                if memory_id not in self.items:\n                    return False\n                \n                item = self.items[memory_id]\n                \n                if content is not None:\n                    item['content'] = content\n                \n                if metadata is not None:\n                    if 'metadata' not in item:\n                        item['metadata'] = {}\n                    item['metadata'].update(metadata)\n                \n                if tags is not None:\n                    item['tags'] = tags\n                \n                if relationships is not None:\n                    item['relationships'] = relationships\n                \n                return True\n            \n            def forget(self, memory_id, permanent=False):\n                if memory_id in self.items:\n                    del self.items[memory_id]\n                    \n                    # Remove from all contexts\n                    for context in self.contexts.values():\n                        if memory_id in context['active_memory_ids']:\n                            context['active_memory_ids'].remove(memory_id)\n                    \n                    return True\n                return False\n        \n        logger.info(\"Created mock memory system\")\n        return MockMemorySystem()\n    \n    def _ensure_transcript_context(self) -> str:\n        \"\"\"\n        Ensure a transcript context exists in the memory system\n        \n        Returns:\n            context_id: Identifier of the transcript context\n        \"\"\"\n        # Default context ID\n        default_context_id = \"transcript_context\"\n        \n        try:\n            # Check if context exists\n            context = self.memory.get_context(default_context_id)\n            \n            if context:\n                logger.debug(f\"Using existing transcript context {default_context_id}\")\n                return default_context_id\n            \n            # Create new context\n            context_id = self.memory.create_context(\n                name=\"Transcript Analysis\",\n                description=\"Context for storing and analyzing transcript data\"\n            )\n            \n            logger.info(f\"Created transcript context {context_id}\")\n            return context_id\n        except Exception as e:\n            logger.error(f\"Error ensuring transcript context: {str(e)}\")\n            \n            # Return default context ID as fallback\n            return default_context_id\n    \n    def process_transcript(self, \n                          transcript_data: Union[str, Dict[str, Any], List[Dict[str, Any]]],\n                          format_type: str = \"raw\",\n                          transcript_id: Optional[str] = None,\n                          metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in any supported format with robust error handling\n        \n        Args:\n            transcript_data: Transcript data (raw text, JSON, or list of messages)\n            format_type: Format type ('raw', 'deepsearch', 'pure_ai', 'structured')\n            transcript_id: Optional transcript ID (generated if not provided)\n            metadata: Additional metadata for the transcript\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        # Generate transcript ID if not provided\n        if not transcript_id:\n            transcript_id = str(uuid.uuid4())\n        \n        logger.info(f\"Processing transcript {transcript_id} in {format_type} format\")\n        \n        try:\n            # Process based on format type\n            if format_type.lower() == \"raw\":\n                return self._process_raw_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"deepsearch\":\n                return self._process_deepsearch_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"pure_ai\":\n                return self._process_pure_ai_transcript(transcript_data, transcript_id, metadata)\n            elif format_type.lower() == \"structured\":\n                return self._process_structured_transcript(transcript_data, transcript_id, metadata)\n            else:\n                error_msg = f\"Unsupported format type: {format_type}\"\n                logger.error(error_msg)\n                \n                # Store error in mock storage\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"error\": error_msg,\n                        \"status\": \"error\",\n                        \"format\": format_type,\n                        \"created_at\": datetime.now().isoformat()\n                    }\n                \n                raise ValueError(error_msg)\n        except Exception as e:\n            logger.error(f\"Error processing transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": format_type,\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Return ID even on error for consistent API\n            return transcript_id\n    \n    def _process_raw_transcript(self,\n                               transcript_text: str,\n                               transcript_id: str,\n                               metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a raw text transcript\n        \n        Args:\n            transcript_text: Raw transcript text\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing raw transcript {transcript_id}\")\n        \n        try:\n            # Ensure transcript_text is a string\n            if not isinstance(transcript_text, str):\n                transcript_text = str(transcript_text)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"raw\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": 0,\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"raw_text\": transcript_text},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"raw\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"raw_text\": transcript_text},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"raw\"]\n                    }\n            \n            # Split transcript into messages\n            messages = self._split_raw_transcript(transcript_text)\n            \n            # Process and store each message\n            message_count = 0\n            \n            for message in messages:\n                # Extract sender, content, etc.\n                sender = message.get(\"sender\", \"unknown\")\n                content = message.get(\"content\", \"\")\n                \n                # Generate a message ID\n                message_id = f\"{transcript_id}_{message_count}\"\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=\"transcript_message\",\n                    sender_id=sender,\n                    receiver_id=\"unknown\",  # Receiver is unknown in raw transcripts\n                    message_id=message_id,\n                    tags=None,  # Auto-detection will happen in add_message\n                    metadata={\n                        \"position\": message_count,\n                        \"raw_processing\": True\n                    }\n                )\n                \n                message_count += 1\n            \n            # Update transcript metadata with message count\n            updated_metadata = transcript_metadata.copy()\n            updated_metadata[\"message_count\"] = message_count\n            \n            try:\n                # Update in memory system\n                self.memory.update(\n                    memory_id=f\"transcript_{transcript_id}\",\n                    metadata={\"message_count\": message_count}\n                )\n            except Exception as e:\n                logger.error(f\"Error updating transcript metadata: {str(e)}\")\n                \n                # Update in mock storage\n                if self.use_mock and transcript_id in self._transcripts:\n                    self._transcripts[transcript_id][\"metadata\"][\"message_count\"] = message_count\n            \n            logger.info(f\"Processed raw transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing raw transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"raw\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_deepsearch_transcript(self,\n                                      transcript_data: Union[str, List[Dict[str, Any]]],\n                                      transcript_id: str,\n                                      metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in DeepSearch format\n        \n        Args:\n            transcript_data: Transcript data in DeepSearch format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing DeepSearch transcript {transcript_id}\")\n        \n        try:\n            # Parse DeepSearch format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid DeepSearch format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Validate DeepSearch format\n            if not isinstance(transcript_data, list):\n                error_msg = \"DeepSearch transcript must be a list of sections\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"deepsearch\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(transcript_data),\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"deepsearch_sections\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"deepsearch\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"deepsearch_sections\": transcript_data},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"deepsearch\"]\n                    }\n            \n            # Process each DeepSearch section as a message\n            message_count = 0\n            \n            for section in transcript_data:\n                # Extract section data\n                section_id = section.get(\"id\", str(uuid.uuid4()))\n                summary = section.get(\"summary\", \"\")\n                tags = section.get(\"tags\", [])\n                text = section.get(\"text\", summary)\n                \n                # Parse confidence scores from summary\n                confidence_scores = []\n                clean_summary = summary\n                \n                # Extract confidence scores if present in [score1,score2,...] format\n                confidence_match = re.match(r'\\[([\\d\\.,]+)\\]\\s*(.*)', summary)\n                if confidence_match:\n                    confidence_str = confidence_match.group(1)\n                    clean_summary = confidence_match.group(2)\n                    \n                    try:\n                        confidence_scores = [float(score.strip()) for score in confidence_str.split(',')]\n                    except ValueError:\n                        logger.warning(f\"Failed to parse confidence scores: {confidence_str}\")\n                \n                # Convert DeepSearch tags to our tag format\n                our_tags = []\n                \n                for ds_tag in tags:\n                    tag_category = ds_tag.get(\"tag\", \"\").replace(\"#\", \"\")\n                    tag_topic = ds_tag.get(\"topic\", \"\")\n                    \n                    if tag_category and tag_topic:\n                        our_tag = f\"#{tag_category}_{tag_topic.upper()}\"\n                        our_tags.append(our_tag)\n                \n                # Generate a message ID based on section ID\n                message_id = f\"{transcript_id}_{section_id}\"\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=text,\n                    message_type=\"transcript_section\",\n                    sender_id=\"deepsearch\",  # DeepSearch is considered the sender\n                    receiver_id=\"system\",\n                    message_id=message_id,\n                    tags=our_tags,\n                    metadata={\n                        \"position\": message_count,\n                        \"original_id\": section_id,\n                        \"confidence_scores\": confidence_scores,\n                        \"summary\": clean_summary\n                    }\n                )\n                \n                message_count += 1\n            \n            logger.info(f\"Processed DeepSearch transcript {transcript_id} with {message_count} sections\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing DeepSearch transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"deepsearch\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_pure_ai_transcript(self,\n                                   transcript_data: Union[str, List[Dict[str, Any]]],\n                                   transcript_id: str,\n                                   metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in PURE_AI_LANGUAGE format\n        \n        Args:\n            transcript_data: Transcript data in PURE_AI_LANGUAGE format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing PURE_AI transcript {transcript_id}\")\n        \n        try:\n            # Parse PURE_AI format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid PURE_AI format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Convert to list if single message\n            if isinstance(transcript_data, dict):\n                transcript_data = [transcript_data]\n            \n            # Validate PURE_AI format\n            if not isinstance(transcript_data, list):\n                error_msg = \"PURE_AI transcript must be a list of messages\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"pure_ai\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(transcript_data),\n                \"status\": \"processed\"\n            }\n            \n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"pure_ai_messages\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"pure_ai\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"pure_ai_messages\": transcript_data},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"pure_ai\"]\n                    }\n            \n            # Process each PURE_AI message\n            message_count = 0\n            \n            for message in transcript_data:\n                # Extract message data\n                message_id = message.get(\"message_id\", str(uuid.uuid4()))\n                message_type = message.get(\"message_type\", \"information\")\n                sender_id = message.get(\"sender_id\", \"unknown\")\n                receiver_id = message.get(\"receiver_id\", \"unknown\")\n                content = message.get(\"content\", {})\n                \n                # Extract tags from principles and tags fields\n                our_tags = []\n                \n                # Process project principles as tags\n                principles = message.get(\"project_principles\", [])\n                for principle in principles:\n                    # Convert principle to tag format if needed\n                    if not principle.startswith(\"#\"):\n                        principle = f\"#{principle}\"\n                    our_tags.append(principle)\n                \n                # Add existing tags\n                tags = message.get(\"tags\", [])\n                our_tags.extend(tags)\n                \n                # Extract truth and efficiency\n                confidence_score = None\n                truth_efficiency = message.get(\"truth_and_efficiency\", {})\n                if truth_efficiency:\n                    certainty_level = truth_efficiency.get(\"certainty_level\")\n                    if certainty_level is not None:\n                        confidence_score = certainty_level / 100.0\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=message_type,\n                    sender_id=sender_id,\n                    receiver_id=receiver_id,\n                    message_id=message_id,\n                    tags=our_tags,\n                    metadata={\n                        \"position\": message_count,\n                        \"protocol_version\": message.get(\"protocol_version\"),\n                        \"confidence_score\": confidence_score\n                    }\n                )\n                \n                message_count += 1\n            \n            logger.info(f\"Processed PURE_AI transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing PURE_AI transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"pure_ai\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def _process_structured_transcript(self,\n                                      transcript_data: Dict[str, Any],\n                                      transcript_id: str,\n                                      metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Process a transcript in structured format\n        \n        Args:\n            transcript_data: Transcript data in structured format\n            transcript_id: Transcript identifier\n            metadata: Additional metadata\n            \n        Returns:\n            transcript_id: Identifier of the processed transcript\n        \"\"\"\n        logger.info(f\"Processing structured transcript {transcript_id}\")\n        \n        try:\n            # Parse structured format if provided as string\n            if isinstance(transcript_data, str):\n                try:\n                    transcript_data = json.loads(transcript_data)\n                except json.JSONDecodeError as e:\n                    error_msg = f\"Invalid structured format: {str(e)}\"\n                    logger.error(error_msg)\n                    raise ValueError(error_msg)\n            \n            # Validate structured format\n            if not isinstance(transcript_data, dict):\n                error_msg = \"Structured transcript must be a dictionary\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Extract messages\n            messages = transcript_data.get(\"messages\", [])\n            \n            if not isinstance(messages, list):\n                error_msg = \"Structured transcript messages must be a list\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            \n            # Store the transcript metadata\n            transcript_metadata = {\n                \"memory_id\": f\"transcript_{transcript_id}\",\n                \"transcript_id\": transcript_id,\n                \"format\": \"structured\",\n                \"processed_at\": datetime.now().isoformat(),\n                \"message_count\": len(messages),\n                \"status\": \"processed\"\n            }\n            \n            # Add provided metadata\n            if metadata:\n                transcript_metadata.update(metadata)\n            \n            # Add transcript metadata from the structured data\n            transcript_meta = transcript_data.get(\"metadata\", {})\n            if transcript_meta:\n                transcript_metadata.update(transcript_meta)\n            \n            # Store in memory system\n            try:\n                self.memory.store(\n                    content={\"structured_transcript\": transcript_data},\n                    context_id=self.transcript_context_id,\n                    metadata=transcript_metadata,\n                    tags=[\"transcript\", \"structured\"],\n                )\n            except Exception as e:\n                logger.error(f\"Error storing transcript metadata: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._transcripts[transcript_id] = {\n                        \"transcript_id\": transcript_id,\n                        \"content\": {\"structured_transcript\": transcript_data},\n                        \"metadata\": transcript_metadata,\n                        \"tags\": [\"transcript\", \"structured\"]\n                    }\n            \n            # Process each message\n            message_count = 0\n            \n            for message in messages:\n                # Extract message data\n                message_id = message.get(\"id\", str(uuid.uuid4()))\n                message_type = message.get(\"type\", \"message\")\n                sender_id = message.get(\"sender\", \"unknown\")\n                receiver_id = message.get(\"receiver\", \"unknown\")\n                content = message.get(\"content\", \"\")\n                timestamp = message.get(\"timestamp\")\n                tags = message.get(\"tags\", [])\n                \n                # Add the message\n                self.add_message(\n                    transcript_id=transcript_id,\n                    content=content,\n                    message_type=message_type,\n                    sender_id=sender_id,\n                    receiver_id=receiver_id,\n                    message_id=message_id,\n                    tags=tags,\n                    metadata={\n                        \"position\": message_count,\n                        \"timestamp\": timestamp\n                    }\n                )\n                \n                message_count += 1\n            \n            logger.info(f\"Processed structured transcript {transcript_id} with {message_count} messages\")\n            \n            return transcript_id\n        except Exception as e:\n            logger.error(f\"Error processing structured transcript {transcript_id}: {str(e)}\")\n            \n            # Create error transcript in mock storage\n            if self.use_mock:\n                self._transcripts[transcript_id] = {\n                    \"transcript_id\": transcript_id,\n                    \"error\": str(e),\n                    \"status\": \"error\",\n                    \"format\": \"structured\",\n                    \"created_at\": datetime.now().isoformat()\n                }\n            \n            # Re-raise to be handled by the caller\n            raise\n    \n    def analyze_transcript(self, \n                          transcript_id: str,\n                          include_content: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Analyze a processed transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            include_content: Whether to include the full content\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        logger.info(f\"Analyzing transcript {transcript_id}\")\n        \n        try:\n            # Retrieve the transcript\n            transcript = self._get_transcript(transcript_id)\n            if not transcript:\n                error_msg = f\"Transcript {transcript_id} not found\"\n                logger.error(error_msg)\n                return {\"error\": error_msg}\n            \n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                warning_msg =",
                            "version_uuid": "6c470f4b-dd53-4881-b920-e9e771ba21aa"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    }
                ],
                "sender": "assistant",
                "created_at": "2025-03-10T18:03:11.188850Z",
                "updated_at": "2025-03-10T18:03:11.188850Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "0e790c0a-fbf3-40d0-92f7-c95e355da4ff",
                "text": "Continue your audit",
                "content": [
                    {
                        "start_timestamp": "2025-03-10T08:04:32.467025Z",
                        "stop_timestamp": "2025-03-10T08:04:32.467025Z",
                        "type": "text",
                        "text": "Continue your audit",
                        "citations": []
                    }
                ],
                "sender": "human",
                "created_at": "2025-03-10T18:03:38.667732Z",
                "updated_at": "2025-03-10T18:03:38.667732Z",
                "attachments": [],
                "files": []
            },
            {
                "uuid": "c41531a2-1484-43f9-9525-c6dcb2c4b269",
                "text": " I'll continue my audit and complete the transcript_processor.py file. Let me examine the current state and proceed with the implementation.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n",
                "content": [
                    {
                        "start_timestamp": "2025-03-10T18:03:42.230664Z",
                        "stop_timestamp": "2025-03-10T18:03:42.729508Z",
                        "type": "text",
                        "text": " I'll continue my audit and complete the transcript_processor.py file. Let me examine the current state and proceed with the implementation.",
                        "citations": []
                    },
                    {
                        "start_timestamp": "2025-03-10T18:03:43.366900Z",
                        "stop_timestamp": "2025-03-10T18:03:50.941231Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "    def analyze_transcript(self, \n                          transcript_id: str,\n                          include_content: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Analyze a processed transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            include_content: Whether to include the full content\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        logger.info(f\"Analyzing transcript {transcript_id}\")\n        \n        try:\n            # Retrieve the transcript\n            transcript = self._get_transcript(transcript_id)\n            if not transcript:\n                error_msg = f\"Transcript {transcript_id} not found\"\n                logger.error(error_msg)\n                return {\"error\": error_msg}\n            \n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                warning_msg = f\"No messages found for transcript {transcript_id}\"\n                logger.warning(warning_msg)\n                return {\"warning\": warning_msg, \"transcript_id\": transcript_id}\n            \n            # Analyze communication patterns\n            direction_stats = self._analyze_direction_patterns(messages)\n            purpose_stats = self._analyze_purpose_patterns(messages)\n            emotion_stats = self._analyze_emotion_patterns(messages)\n            action_stats = self._analyze_action_patterns(messages)\n            \n            # Calculate communication metrics\n            metrics = self._calculate_communication_metrics(messages)\n            \n            # Prepare result\n            result = {\n                \"transcript_id\": transcript_id,\n                \"metadata\": transcript.get(\"metadata\", {}),\n                \"message_count\": len(messages),\n                \"direction_patterns\": direction_stats,\n                \"purpose_patterns\": purpose_stats,\n                \"emotion_patterns\": emotion_stats,\n                \"action_patterns\": action_stats,\n                \"metrics\": metrics\n            }\n            \n            # Include content if requested\n            if include_content:\n                result[\"messages\"] = messages\n            \n            return result",
                            "old_str": "    def analyze_transcript(self, \n                          transcript_id: str,\n                          include_content: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Analyze a processed transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            include_content: Whether to include the full content\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        logger.info(f\"Analyzing transcript {transcript_id}\")\n        \n        try:\n            # Retrieve the transcript\n            transcript = self._get_transcript(transcript_id)\n            if not transcript:\n                error_msg = f\"Transcript {transcript_id} not found\"\n                logger.error(error_msg)\n                return {\"error\": error_msg}\n            \n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                warning_msg =",
                            "version_uuid": "54e8b535-f24c-4865-8031-71cb30a99607"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "9bde0354-9c97-4a2b-983e-b2cdbc625a23"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T18:03:56.685208Z",
                        "stop_timestamp": "2025-03-10T18:03:58.452744Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "            # Include content if requested\n            if include_content:\n                result[\"messages\"] = messages\n            \n            return result\n        except Exception as e:\n            logger.error(f\"Error analyzing transcript {transcript_id}: {str(e)}\")\n            return {\n                \"error\": f\"Analysis failed: {str(e)}\",\n                \"transcript_id\": transcript_id\n            }",
                            "old_str": "            # Include content if requested\n            if include_content:\n                result[\"messages\"] = messages\n            \n            return result",
                            "version_uuid": "cabc023b-6ea9-47df-a0e4-2deb7d143d5f"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "f28a3613-8482-4542-80c4-23ee53af652e"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T18:04:01.030734Z",
                        "stop_timestamp": "2025-03-10T18:04:08.223121Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "        except Exception as e:\n            logger.error(f\"Error analyzing transcript {transcript_id}: {str(e)}\")\n            return {\n                \"error\": f\"Analysis failed: {str(e)}\",\n                \"transcript_id\": transcript_id\n            }\n    \n    def extract_actions(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Extract actions from a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            List of action items\n        \"\"\"\n        logger.info(f\"Extracting actions from transcript {transcript_id}\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return []\n            \n            # Extract messages with action tags\n            action_messages = []\n            \n            for message in messages:\n                tags = message.get(\"tags\", [])\n                \n                # Check for action tags\n                has_action_tag = any(tag.startswith(\"#ACTION_\") for tag in tags)\n                \n                if has_action_tag:\n                    # Extract action details\n                    action = {\n                        \"message_id\": message.get(\"message_id\"),\n                        \"timestamp\": message.get(\"metadata\", {}).get(\"timestamp\"),\n                        \"sender\": message.get(\"metadata\", {}).get(\"sender_id\"),\n                        \"content\": message.get(\"content\"),\n                        \"status\": \"unknown\"\n                    }\n                    \n                    # Determine action status\n                    if ACTION_REQUESTED in tags:\n                        action[\"status\"] = \"requested\"\n                    elif ACTION_ASSIGNED in tags:\n                        action[\"status\"] = \"assigned\"\n                    elif ACTION_COMPLETED in tags:\n                        action[\"status\"] = \"completed\"\n                    elif ACTION_BLOCKED in tags:\n                        action[\"status\"] = \"blocked\"\n                    \n                    # Extract estimated completion time if available\n                    if \"estimated_completion_time\" in message.get(\"metadata\", {}):\n                        action[\"estimated_completion_time\"] = message[\"metadata\"][\"estimated_completion_time\"]\n                    \n                    action_messages.append(action)\n            \n            return action_messages",
                            "old_str": "        except Exception as e:\n            logger.error(f\"Error analyzing transcript {transcript_id}: {str(e)}\")\n            return {\n                \"error\": f\"Analysis failed: {str(e)}\",\n                \"transcript_id\": transcript_id\n            }",
                            "version_uuid": "ef6d462a-4781-43e8-9c59-1c3b7df3d185"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "f277767f-4072-4a3c-aec9-6becdf7a8ca5"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T18:04:10.973253Z",
                        "stop_timestamp": "2025-03-10T18:04:22.290508Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "            return action_messages\n        except Exception as e:\n            logger.error(f\"Error extracting actions from transcript {transcript_id}: {str(e)}\")\n            return []\n    \n    def add_message(self,\n                   transcript_id: str,\n                   content: Any,\n                   message_type: str,\n                   sender_id: str,\n                   receiver_id: str,\n                   message_id: Optional[str] = None,\n                   tags: Optional[List[str]] = None,\n                   metadata: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"\n        Add a message to a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            content: Message content\n            message_type: Message type\n            sender_id: Sender identifier\n            receiver_id: Receiver identifier\n            message_id: Optional message identifier\n            tags: Optional tags\n            metadata: Additional metadata\n            \n        Returns:\n            message_id: Identifier of the added message\n        \"\"\"\n        try:\n            # Generate message ID if not provided\n            if not message_id:\n                message_id = str(uuid.uuid4())\n            \n            # Get current timestamp\n            now = datetime.now().isoformat()\n            \n            # Prepare base metadata\n            base_metadata = {\n                \"timestamp\": now,\n                \"message_type\": message_type,\n                \"sender_id\": sender_id,\n                \"receiver_id\": receiver_id\n            }\n            \n            # Merge with provided metadata\n            if metadata:\n                merged_metadata = {**base_metadata, **metadata}\n            else:\n                merged_metadata = base_metadata\n            \n            # Auto-detect communication direction if not in tags\n            if tags is None:\n                tags = []\n            \n            if not any(tag.startswith(\"#DIRECTION_\") for tag in tags):\n                direction_tag = self._detect_direction(sender_id, receiver_id)\n                if direction_tag:\n                    tags.append(direction_tag)\n            \n            # Auto-detect other tags if not already present\n            self._auto_detect_tags(content, tags)\n            \n            # Prepare the message\n            message = {\n                \"message_id\": message_id,\n                \"transcript_id\": transcript_id,\n                \"content\": content,\n                \"tags\": tags,\n                \"metadata\": merged_metadata\n            }\n            \n            # Store in memory system\n            try:\n                memory_id = self.memory.store(\n                    content=message,\n                    context_id=self.transcript_context_id,\n                    metadata={\n                        \"memory_id\": f\"message_{message_id}\",\n                        \"message_id\": message_id,\n                        \"transcript_id\": transcript_id,\n                        \"timestamp\": now,\n                        \"message_type\": message_type,\n                        \"sender_id\": sender_id,\n                        \"receiver_id\": receiver_id\n                    },\n                    tags=tags,\n                )\n                \n                logger.debug(f\"Added message {message_id} to transcript {transcript_id}\")\n            except Exception as e:\n                logger.error(f\"Error storing message in memory system: {str(e)}\")\n                \n                # Store in mock storage if memory system fails\n                if self.use_mock:\n                    self._messages[message_id] = message\n                    logger.debug(f\"Added message {message_id} to mock storage\")\n            \n            return message_id",
                            "old_str": "            return action_messages",
                            "version_uuid": "a66012ec-b04f-4110-b5db-be460e6d32d7"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "56f7fc91-91d6-44a3-abcd-a84633634773"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T18:04:25.518906Z",
                        "stop_timestamp": "2025-03-10T18:04:34.831679Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "            return message_id\n        except Exception as e:\n            logger.error(f\"Error adding message to transcript {transcript_id}: {str(e)}\")\n            return str(uuid.uuid4())  # Return a new ID even on error\n    \n    def convert_to_deepsearch_format(self, transcript_id: str) -> str:\n        \"\"\"\n        Convert a transcript to DeepSearch format with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript in DeepSearch format (JSON string)\n        \"\"\"\n        logger.info(f\"Converting transcript {transcript_id} to DeepSearch format\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return \"[]\"\n            \n            # Convert to DeepSearch format\n            deepsearch_sections = []\n            \n            for message in messages:\n                # Extract tags by category\n                emotion_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#EMOTION_\")]\n                purpose_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#PURPOSE_\")]\n                action_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#ACTION_\")]\n                \n                # Prepare DeepSearch tags\n                ds_tags = []\n                \n                # Add emotion tags\n                for tag in emotion_tags:\n                    tag_name = tag.replace(\"#EMOTION_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#EMOTION\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Add purpose tags\n                for tag in purpose_tags:\n                    tag_name = tag.replace(\"#PURPOSE_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#PURPOSE\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Add action tags\n                for tag in action_tags:\n                    tag_name = tag.replace(\"#ACTION_\", \"\")\n                    ds_tags.append({\n                        \"tag\": f\"#ACTION\",\n                        \"topic\": tag_name,\n                        \"related\": \"\"\n                    })\n                \n                # Prepare confidence scores (placeholder)\n                confidence_scores = [0.85, 0.75, 0.90]\n                confidence_str = f\"[{','.join([str(score) for score in confidence_scores])}] \"\n                \n                # Create DeepSearch section\n                section = {\n                    \"id\": message.get(\"message_id\", str(uuid.uuid4())),\n                    \"summary\": f\"{confidence_str}{self._get_message_summary(message)}\",\n                    \"tags\": ds_tags\n                }\n                \n                # Add original text if available\n                if isinstance(message.get(\"content\"), str):\n                    section[\"text\"] = message[\"content\"]\n                \n                deepsearch_sections.append(section)\n            \n            # Convert to JSON string\n            return json.dumps(deepsearch_sections, indent=2)",
                            "old_str": "            return message_id",
                            "version_uuid": "a5057a0d-6d5e-40dc-a4ef-3d781bfc82b8"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "ad2b4420-ff32-40ef-ae48-9e12a083b3db"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T18:04:38.872241Z",
                        "stop_timestamp": "2025-03-10T18:04:48.572571Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "            # Convert to JSON string\n            return json.dumps(deepsearch_sections, indent=2)\n        except Exception as e:\n            logger.error(f\"Error converting transcript {transcript_id} to DeepSearch format: {str(e)}\")\n            return \"[]\"\n    \n    def convert_to_pure_ai_format(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Convert a transcript to PURE_AI_LANGUAGE format with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript in PURE_AI_LANGUAGE format\n        \"\"\"\n        logger.info(f\"Converting transcript {transcript_id} to PURE_AI_LANGUAGE format\")\n        \n        try:\n            # Get all messages\n            messages = self._get_transcript_messages(transcript_id)\n            if not messages:\n                logger.warning(f\"No messages found for transcript {transcript_id}\")\n                return []\n            \n            # Convert to PURE_AI_LANGUAGE format\n            pure_ai_messages = []\n            \n            for message in messages:\n                metadata = message.get(\"metadata\", {})\n                \n                # Create PURE_AI message\n                pure_message = {\n                    \"message_type\": metadata.get(\"message_type\", \"information\"),\n                    \"sender_id\": metadata.get(\"sender_id\", \"unknown\"),\n                    \"receiver_id\": metadata.get(\"receiver_id\", \"unknown\"),\n                    \"message_id\": message.get(\"message_id\", str(uuid.uuid4())),\n                    \"protocol_version\": \"PURE_AI_LANGUAGE_v1.5\",\n                    \"content\": message.get(\"content\", {})\n                }\n                \n                # Add tags as project principles\n                emotion_tags = [tag.replace(\"#EMOTION_\", \"\") for tag in message.get(\"tags\", []) \n                               if tag.startswith(\"#EMOTION_\")]\n                purpose_tags = [tag.replace(\"#PURPOSE_\", \"\") for tag in message.get(\"tags\", []) \n                               if tag.startswith(\"#PURPOSE_\")]\n                \n                if emotion_tags or purpose_tags:\n                    pure_message[\"project_principles\"] = []\n                    pure_message[\"project_principles\"].extend(emotion_tags)\n                    pure_message[\"project_principles\"].extend(purpose_tags)\n                \n                # Add action tags as regular tags\n                action_tags = [tag for tag in message.get(\"tags\", []) if tag.startswith(\"#ACTION_\")]\n                if action_tags:\n                    pure_message[\"tags\"] = action_tags\n                \n                # Add truth and efficiency if available\n                if \"confidence_score\" in metadata:\n                    pure_message[\"truth_and_efficiency\"] = {\n                        \"certainty_level\": int(metadata[\"confidence_score\"] * 100),\n                        \"lean_check\": \"Yes\"\n                    }\n                \n                pure_ai_messages.append(pure_message)\n            \n            return pure_ai_messages",
                            "old_str": "            # Convert to JSON string\n            return json.dumps(deepsearch_sections, indent=2)",
                            "version_uuid": "e8200dd4-9575-4650-9e8e-40eb99229d7c"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "7aae8ea3-f6ed-4a9a-931e-2e6947e0b428"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T18:04:52.170279Z",
                        "stop_timestamp": "2025-03-10T18:04:56.979343Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "            return pure_ai_messages\n        except Exception as e:\n            logger.error(f\"Error converting transcript {transcript_id} to PURE_AI format: {str(e)}\")\n            return []\n    \n    def _get_transcript(self, transcript_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Retrieve a transcript from memory with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            Transcript data\n        \"\"\"\n        memory_id = f\"transcript_{transcript_id}\"\n        \n        try:\n            # Try to retrieve from memory system\n            transcript = self.memory.retrieve(memory_id)\n            if transcript:\n                return transcript\n            \n            # Check mock storage if memory system fails or is in mock mode\n            if self.use_mock and hasattr(self, '_transcripts') and transcript_id in self._transcripts:\n                return self._transcripts[transcript_id]\n            \n            logger.warning(f\"Transcript {transcript_id} not found\")\n            return None\n        except Exception as e:\n            logger.error(f\"Error retrieving transcript {transcript_id}: {str(e)}\")\n            \n            # Check mock storage as fallback\n            if self.use_mock and hasattr(self, '_transcripts') and transcript_id in self._transcripts:\n                return self._transcripts[transcript_id]\n            \n            return None",
                            "old_str": "            return pure_ai_messages",
                            "version_uuid": "88e595b3-2076-48bc-bc90-5bfd19937c7d"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "36f767a3-750f-4944-af0b-9048a2a80951"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T18:05:00.640241Z",
                        "stop_timestamp": "2025-03-10T18:05:07.310460Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "            return None\n    \n    def _get_transcript_messages(self, transcript_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Retrieve all messages for a transcript with robust error handling\n        \n        Args:\n            transcript_id: Transcript identifier\n            \n        Returns:\n            List of messages\n        \"\"\"\n        try:\n            # Query memory system for messages\n            messages = self.memory.query(\n                filters={\"metadata.transcript_id\": transcript_id},\n                limit=1000  # Set a high limit to get all messages\n            )\n            \n            # Check mock storage if in mock mode or no messages found\n            if self.use_mock and hasattr(self, '_messages'):\n                # Filter messages from mock storage\n                mock_messages = [msg for msg in self._messages.values() \n                               if msg.get(\"transcript_id\") == transcript_id]\n                \n                # Combine with any messages from memory system\n                if messages:\n                    # Make sure we don't have duplicates\n                    message_ids = {msg.get(\"message_id\") for msg in messages}\n                    additional_messages = [msg for msg in mock_messages \n                                         if msg.get(\"message_id\") not in message_ids]\n                    messages.extend(additional_messages)\n                else:\n                    messages = mock_messages\n            \n            # Sort by position if available\n            return sorted(messages, key=lambda m: m.get(\"metadata\", {}).get(\"position\", 0))\n        except Exception as e:\n            logger.error(f\"Error retrieving messages for transcript {transcript_id}: {str(e)}\")\n            \n            # Fallback to mock storage\n            if self.use_mock and hasattr(self, '_messages'):\n                mock_messages = [msg for msg in self._messages.values() \n                               if msg.get(\"transcript_id\") == transcript_id]\n                return sorted(mock_messages, key=lambda m: m.get(\"metadata\", {}).get(\"position\", 0))\n            \n            return []",
                            "old_str": "            return None",
                            "version_uuid": "b05e5f15-531b-40a3-bfee-375b2d10316f"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "813e267e-14c2-42fb-a0e4-2c94f0265553"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T18:05:12.341403Z",
                        "stop_timestamp": "2025-03-10T18:05:18.013509Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "            return []\n    \n    def _split_raw_transcript(self, transcript_text: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Split a raw transcript into messages\n        \n        Args:\n            transcript_text: Raw transcript text\n            \n        Returns:\n            List of messages\n        \"\"\"\n        messages = []\n        \n        try:\n            # Try to identify speaker patterns like \"Name: Message content\"\n            speaker_pattern = re.compile(r'([A-Za-z0-9_]+):\\s*(.*?)(?=\\n[A-Za-z0-9_]+:|$)', re.DOTALL)\n            matches = speaker_pattern.findall(transcript_text)\n            \n            if matches:\n                # Speaker pattern detected\n                for i, (speaker, content) in enumerate(matches):\n                    messages.append({\n                        \"sender\": speaker.strip(),\n                        \"content\": content.strip(),\n                        \"position\": i\n                    })\n            else:\n                # No speaker pattern, split by paragraphs\n                paragraphs = [p.strip() for p in transcript_text.split('\\n\\n') if p.strip()]\n                \n                for i, paragraph in enumerate(paragraphs):\n                    messages.append({\n                        \"sender\": \"unknown\",\n                        \"content\": paragraph,\n                        \"position\": i\n                    })\n            \n            return messages\n        except Exception as e:\n            logger.error(f\"Error splitting raw transcript: {str(e)}\")\n            \n            # Return single message with entire content as fallback\n            return [{\n                \"sender\": \"unknown\",\n                \"content\": transcript_text,\n                \"position\": 0\n            }]",
                            "old_str": "            return []",
                            "version_uuid": "857f822c-9a39-479a-bf8e-b39ae74a613b"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "d2b657c6-6f5b-4432-8d55-926451cc91a2"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T18:05:21.621658Z",
                        "stop_timestamp": "2025-03-10T18:05:30.520236Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "            }]\n    \n    def _detect_direction(self, sender_id: str, receiver_id: str) -> Optional[str]:\n        \"\"\"\n        Detect communication direction based on sender and receiver\n        \n        Args:\n            sender_id: Sender identifier\n            receiver_id: Receiver identifier\n            \n        Returns:\n            Direction tag\n        \"\"\"\n        try:\n            # Determine if sender/receiver are AI or human\n            sender_is_ai = self._is_ai_actor(sender_id)\n            receiver_is_ai = self._is_ai_actor(receiver_id)\n            \n            if sender_is_ai and receiver_is_ai:\n                # Check if same AI system\n                if self._is_same_ai_system(sender_id, receiver_id):\n                    return DIRECTION_INTRA_AI\n                else:\n                    return DIRECTION_INTER_AI\n            elif (sender_is_ai and not receiver_is_ai) or (not sender_is_ai and receiver_is_ai):\n                return DIRECTION_HUMAN_AI\n            \n            # Default to None if we can't determine\n            return None\n        except Exception as e:\n            logger.error(f\"Error detecting direction: {str(e)}\")\n            return None\n    \n    def _is_ai_actor(self, actor_id: str) -> bool:\n        \"\"\"\n        Determine if an actor is an AI\n        \n        Args:\n            actor_id: Actor identifier\n            \n        Returns:\n            Whether the actor is an AI\n        \"\"\"\n        # Simple heuristic - can be replaced with more sophisticated detection\n        ai_indicators = [\"ai\", \"claude\", \"gemini\", \"gpt\", \"grok\", \"assistant\", \"bot\", \"system\", \"model\"]\n        actor_lower = actor_id.lower()\n        return any(indicator in actor_lower for indicator in ai_indicators)\n    \n    def _is_same_ai_system(self, actor1: str, actor2: str) -> bool:\n        \"\"\"\n        Determine if two actors are from the same AI system\n        \n        Args:\n            actor1: First actor identifier\n            actor2: Second actor identifier\n            \n        Returns:\n            Whether the actors are from the same AI system\n        \"\"\"\n        # Simple heuristic - can be replaced with more sophisticated detection\n        actor1_base = actor1.split('_')[0].lower() if '_' in actor1 else actor1.lower()\n        actor2_base = actor2.split('_')[0].lower() if '_' in actor2 else actor2.lower()\n        \n        return actor1_base == actor2_base",
                            "old_str": "            }]",
                            "version_uuid": "3598758e-a971-4999-9f4d-a57e1b0736bb"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "d03f4c34-1d16-4501-9586-e385764e0c4c"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T18:05:34.167784Z",
                        "stop_timestamp": "2025-03-10T18:05:47.443475Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "        return actor1_base == actor2_base\n    \n    def _auto_detect_tags(self, content: Any, tags: List[str]) -> None:\n        \"\"\"\n        Auto-detect and add tags to a message based on content\n        \n        Args:\n            content: Message content\n            tags: List of tags to update\n        \"\"\"\n        try:\n            # Convert content to string for analysis\n            if isinstance(content, dict):\n                content_str = json.dumps(content)\n            else:\n                content_str = str(content)\n            \n            content_lower = content_str.lower()\n            \n            # Simple keyword-based detection\n            # Purpose tags\n            if not any(tag.startswith(\"#PURPOSE_\") for tag in tags):\n                if any(word in content_lower for word in [\"clarify\", \"unclear\", \"understand\", \"what do you mean\"]):\n                    tags.append(PURPOSE_CLARIFICATION)\n                elif any(word in content_lower for word in [\"idea\", \"suggest\", \"proposal\", \"what if\", \"brainstorm\"]):\n                    tags.append(PURPOSE_IDEATION)\n                elif any(word in content_lower for word in [\"decide\", \"decision\", \"choose\", \"select\", \"agree\"]):\n                    tags.append(PURPOSE_DECISION)\n                elif any(word in content_lower for word in [\"implement\", \"build\", \"code\", \"develop\", \"create\"]):\n                    tags.append(PURPOSE_IMPLEMENTATION)\n                elif any(word in content_lower for word in [\"feedback\", \"review\", \"opinion\", \"what do you think\"]):\n                    tags.append(PURPOSE_FEEDBACK)\n            \n            # Emotion tags\n            if not any(tag.startswith(\"#EMOTION_\") for tag in tags):\n                if any(word in content_lower for word in [\"excited\", \"great\", \"looking forward\", \"can't wait\", \"amazing\"]):\n                    tags.append(EMOTION_EXCITEMENT)\n                elif any(word in content_lower for word in [\"frustrating\", \"difficult\", \"challenging\", \"problem\", \"issue\"]):\n                    tags.append(EMOTION_FRUSTRATION)\n                elif any(word in content_lower for word in [\"satisfied\", \"completed\", \"finished\", \"done\", \"success\"]):\n                    tags.append(EMOTION_SATISFACTION)\n                elif any(word in content_lower for word in [\"confused\", \"not sure\", \"unclear\", \"don't understand\"]):\n                    tags.append(EMOTION_CONFUSION)\n            \n            # Action tags\n            if not any(tag.startswith(\"#ACTION_\") for tag in tags):\n                if any(word in content_lower for word in [\"can you\", \"could you\", \"please\", \"request\"]):\n                    tags.append(ACTION_REQUESTED)\n                elif any(word in content_lower for word in [\"assigned\", \"responsible\", \"will handle\", \"task for\"]):\n                    tags.append(ACTION_ASSIGNED)\n                elif any(word in content_lower for word in [\"completed\", \"finished\", \"done\", \"implemented\"]):\n                    tags.append(ACTION_COMPLETED)\n                elif any(word in content_lower for word in [\"blocked\", \"stuck\", \"cannot proceed\", \"issue\"]):\n                    tags.append(ACTION_BLOCKED)\n        except Exception as e:\n            logger.error(f\"Error auto-detecting tags: {str(e)}\")\n    \n    def _get_message_summary(self, message: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate a summary for a message\n        \n        Args:\n            message: Message data\n            \n        Returns:\n            Summary text\n        \"\"\"\n        try:\n            # Use existing summary if available\n            if \"summary\" in message.get(\"metadata\", {}):\n                return message[\"metadata\"][\"summary\"]\n            \n            # Extract content\n            content = message.get(\"content\", \"\")\n            \n            # Generate a basic summary\n            if isinstance(content, str):\n                # For text content\n                if len(content) > 100:\n                    return content[:97] + \"...\"\n                return content\n            elif isinstance(content, dict):\n                # For structured content\n                return f\"Structured content with {len(content)} fields\"\n            else:\n                return \"Message content\"\n        except Exception as e:\n            logger.error(f\"Error generating message summary: {str(e)}\")\n            return \"Message content\"",
                            "old_str": "        return actor1_base == actor2_base",
                            "version_uuid": "2e7d47b4-1034-4eb9-ba13-90ffa6e879b0"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": null,
                        "stop_timestamp": null,
                        "type": "tool_result",
                        "name": "artifacts",
                        "content": [
                            {
                                "type": "text",
                                "text": "OK",
                                "uuid": "ca1bb30d-e718-4b54-b1a8-413b94828301"
                            }
                        ],
                        "is_error": false,
                        "message": null,
                        "display_content": null
                    },
                    {
                        "start_timestamp": "2025-03-10T18:05:52.866661Z",
                        "stop_timestamp": "2025-03-10T18:05:57.192715Z",
                        "type": "tool_use",
                        "name": "artifacts",
                        "input": {
                            "id": "transcript-processor-py",
                            "command": "update",
                            "new_str": "            return \"Message content\"\n    \n    def _analyze_direction_patterns(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Analyze communication direction patterns\n        \n        Args:\n            messages: List of messages\n            \n        Returns:\n            Analysis results\n        \"\"\"\n        try:\n            # Count messages by direction\n            direction_counts = {\n                DIRECTION_INTRA_AI: 0,\n                DIRECTION_INTER_AI: 0,\n                DIRECTION_HUMAN_AI: 0\n            }\n            \n            for message in messages:\n                tags = message.get(\"tags\", [])\n                \n                # Count by direction\n                if DIRECTION_INTRA_AI in tags:\n                    direction_counts[DIRECTION_INTRA_AI] += 1\n                elif DIRECTION_INTER_AI in tags:\n                    direction_counts[DIRECTION_INTER_AI] += 1\n                elif DIRECTION_HUMAN_AI in tags:\n                    direction_counts[DIRECTION_HUMAN_AI] += 1\n            \n            # Calculate percentages\n            total_messages = len(messages)\n            direction_percentages = {}\n            \n            for direction, count in direction_counts.items():\n                if total_messages > 0:\n                ",
                            "old_str": "            return \"Message content\"",
                            "version_uuid": "83d7be0a-9439-4750-9e62-c6162f3eaa41"
                        },
                        "message": null,
                        "integration_name": null,
                        "integration_icon_url": null,
                        "display_content": null
                    }
                ],
                "sender": "assistant",
                "created_at": "2025-03-10T18:05:57.389236Z",
                "updated_at": "2025-03-10T18:05:57.389236Z",
                "attachments": [],
                "files": []
            }
        ]
    }
]