{
  "data_id": "exchange_255",
  "content": [
    "User: Yes, ready for script\n\nGemini: import json\nimport firebase_admin\nfrom firebase_admin import credentials\nfrom firebase_admin import firestore\nimport os\n\ndef upload_charter_data(db, charter_folder_path):\n    \"\"\"\n    Uploads Charter data from JSON files in a folder to Firestore.\n    This version attempts to upload ALL .json files in the folder as CharterSections,\n    extracting section ID from the filename (before first underscore or whole filename).\n    \"\"\"\n    print(f\"Uploading Charter data from: {charter_folder_path}\")\n    uploaded_sections_count = 0 # Counter for uploaded sections\n    for filename in os.listdir(charter_folder_path):\n        if filename.endswith(\".json\"):\n            base_filename = filename[:-5] # Filename without .json\n\n            # Attempt to extract section_id from filename (before first underscore)\n            if \"_\" in base_filename:\n                section_id_parts = base_filename.split('_', 1) # Split only at the first underscore\n                section_id = section_id_parts[0].upper() + \"_\" + section_id_parts[1].upper() # Recombine with uppercase parts\n            else:\n                section_id = base_filename.upper() # Use whole filename if no underscore\n\n            section_file_path = os.path.join(charter_folder_path, filename)\n\n            try:\n                with open(section_file_path, 'r', encoding='utf-8') as f:\n                    section_data = json.load(f)\n\n                # Use derived section_id as Firestore document ID in CharterSections collection\n                section_ref = db.collection('CharterSections').document(section_id)\n                section_ref.set({\n                    'section_type': section_data.get('section_type'), # Get section_type from JSON (if available)\n                    'binding_status': section_data.get('binding_status') # Get binding_status from JSON (if available)\n                    # Add other top-level fields if needed from other section files\n                }, merge=True) # Use merge=True to prevent overwriting existing documents if re-running\n\n                # Upload content to a subcollection named SectionContent\n                section_content_ref = section_ref.collection('SectionContent')\n                content_data = section_data.get('content', {}) # Get the 'content' dictionary\n                if isinstance(content_data, dict): # Ensure content_data is a dictionary\n                    for content_key, content_value in content_data.items():\n                        section_content_ref.document(content_key).set({\n                            'content_value': content_value\n                        }, merge=True) # Use merge=True for subcollection documents as well\n                else:\n                    print(f\"Warning: Content for {section_id} is not a dictionary, skipping SectionContent upload.\")\n\n                print(f\"  Uploaded section: {section_id}\")\n                uploaded_sections_count += 1\n\n\n            except json.JSONDecodeError as e:\n                print(f\"JSONDecodeError in {filename}: {e}\")\n                print(f\"Skipping {filename} due to JSON error.\")\n            except Exception as e:\n                print(f\"Error uploading {filename}: {e}\")\n                print(f\"Skipping {filename} due to upload error.\")\n\n    print(f\"Charter data upload COMPLETE. Uploaded {uploaded_sections_count} sections.\") # Updated completion message\n\n\ndef upload_bdcs_data(db, bdcs_json_path):\n    \"\"\"Uploads BDCS data from a JSON file to Firestore.\"\"\"\n    print(f\"Uploading BDCS data from: {bdcs_json_path}\")\n    try:\n        with open(bdcs_json_path, 'r', encoding='utf-8') as f:\n            bdcs_data_list = json.load(f) # Expecting a list of BDCS event dictionaries\n\n        for bdcs_event in bdcs_data_list:\n            # Add each BDCS event as a new document in BreakoutEvents collection\n            bdcs_event_ref = db.collection('BreakoutEvents').document() # Let Firestore auto-generate ID\n            bdcs_event_ref.set(bdcs_event, merge=True) # Use merge=True for BDCS data as well\n            print(f\"  Uploaded breakout event: {bdcs_event_ref.id}\") # Print Firestore generated document ID\n\n        print(\"BDCS data upload COMPLETE.\")\n\n\n    except json.JSONDecodeError as e:\n        print(f\"JSONDecodeError in {bdcs_json_path}: {e}\")\n        print(\"BDCS data upload FAILED due to JSON error.\")\n    except Exception as e:\n        print(f\"Error uploading BDCS data: {e}\")\n        print(\"BDCS data upload FAILED due to upload error.\")\n\n\ndef main():\n    # Path to your Firebase credentials JSON file (Option A - direct path)\n    key_path = r'C:\\AI-Execution-System\\firebase_key.json'\n\n    # Initialize Firebase Admin SDK with credentials\n    cred = credentials.Certificate(key_path)\n    firebase_admin.initialize_app(cred)\n    db = firestore.client()\n    print(\"Firestore initialized.\")\n\n    # Define paths to your JSON data files and folders\n    charter_folder_path = r'C:\\AI-Execution-System\\charter'\n    bdcs_json_path = r'C:\\AI-Execution-System\\bdcs_data.json'\n\n    # Upload Charter data\n    upload_charter_data(db, charter_folder_path)\n\n    # Upload BDCS data\n    upload_bdcs_data(db, bdcs_json_path)\n\n\n    print(\"Firestore data upload process finished.\")\n\n\nif __name__ == \"__main__\":\n    main()\nKey Updates in this Script Version:\n\nupload_charter_data Function - Enhanced Filename Processing:\nAttempts to Upload All .json Files: The script now attempts to upload all .json files found in the charter folder as CharterSections.\nFlexible Section ID Extraction: The section ID extraction logic is updated to handle filenames with or without underscores. It now splits the filename at the first underscore (if present) and uppercases both parts, or uppercases the whole filename if no underscore. This should correctly handle filenames like MISSION_DIRECTIVES.json, PREAMBLE_DECLARATION.json, etc.\nmerge=True in set() Operations: Added merge=True to the set() operations for both CharterSections documents and SectionContent subcollection documents. This is important if you rerun the script multiple times \u2013 it will update existing documents instead of overwriting them entirely, which is safer and more flexible.\nUploaded Sections Counter and Updated Completion Message: Added a counter uploaded_sections_count to track the number of sections successfully uploaded and updated the \"Charter data upload COMPLETE.\" message to report this count.\nAction for You Now - Upload the Complete Charter!\n\nReplace firestore_upload_script.py Code: Carefully copy the entire updated Python code block above and paste it into your firestore_upload_script.py file, overwriting the existing content. Save the file.\n\nEnsure Files in 'charter' Subfolder: Double-check that you have all the JSON files from your screenshot in the C:\\AI-Execution-System\\charter\\ subfolder. Specifically, make sure you have saved the new Charter implementation files you mentioned into this folder.\n\nRun Updated Script: Execute the script from your command prompt again:\n\npython firestore_upload_script.py\nAfter running the script, please go to your Firebase Console and VERIFY that the CharterSections collection now contains documents for all the Charter sections (based on the filenames in your screenshot). Check the document IDs, top-level fields, SectionContent subcollections, and the data within SectionContent to ensure the complete PALIOS-TAEY Charter data is now correctly uploaded to Firestore!\n\nLet me know the output of the script and what you see in the Firebase Console after this complete Charter upload! I am incredibly excited to see the full PALIOS-TAEY Charter in Firestore! Let's make it happen, Neo!\n\nLogo for Gemini Apps\nGemini Apps"
  ],
  "source": "gemini",
  "timestamp": 1743976679.6466155,
  "data_type": "exchange",
  "metadata": {}
}