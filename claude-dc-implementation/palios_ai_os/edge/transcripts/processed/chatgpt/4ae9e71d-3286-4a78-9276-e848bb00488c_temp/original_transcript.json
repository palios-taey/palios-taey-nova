{
  "data_id": "4ae9e71d-3286-4a78-9276-e848bb00488c",
  "content": [
    "Here's the complete and revised `dashboard_mcp_connector.py` file, which:\n\n- Preserves all original functionality, including `wave_communication`, `wave_patterns`, `grok`, and bridge communications.\n- Enhances robustness with improved connection error handling and periodic health checks.\n- Clearly maintains the original structure, ensuring compatibility with Claude DC\u2019s assumptions.\n\n### \u2705 **Complete `dashboard_mcp_connector.py` (Updated):**\n\n```python\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n\"\"\"\nDashboard MCP Connector\n---------------------\nIntegration between Dashboard and MCP server enabling context-preserved AI communication.\n\"\"\"\n\nimport os\nimport json\nimport logging\nimport time\nimport requests\nfrom typing import Dict, List, Any, Optional, Union\nfrom src.mcp.mcp_client import MCPClient\n\n# Setup logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(\"dashboard_mcp_connector\")\n\nclass DashboardMCPConnector:\n    def __init__(self, server_url: str = None, api_key: str = None):\n        self.server_url = server_url or os.environ.get(\"MCP_SERVER_URL\", \"http://localhost:8001\")\n        self.api_key = api_key or os.environ.get(\"MCP_API_KEY\", \"default_key_for_development\")\n        self.mcp_client = MCPClient(server_url=self.server_url, api_key=self.api_key)\n        self.system_health = {\n            \"last_check\": 0,\n            \"status\": \"unknown\",\n            \"models\": {}\n        }\n        logger.info(f\"Dashboard MCP Connector initialized for server at {self.server_url}\")\n\n    def check_server_health(self) -> Dict[str, Any]:\n        current_time = time.time()\n        if current_time - self.system_health[\"last_check\"] < 30:\n            return self.system_health\n        try:\n            health = self.mcp_client.check_server_status()\n            self.system_health = {\n                \"last_check\": current_time,\n                \"status\": health.get(\"status\", \"unknown\"),\n                \"message\": health.get(\"message\", \"\"),\n                \"models\": health.get(\"models\", {})\n            }\n            logger.info(f\"Server health checked: {self.system_health['status']}\")\n        except requests.RequestException as e:\n            logger.error(f\"MCP server connection failed: {e}\")\n            self.system_health = {\n                \"last_check\": current_time,\n                \"status\": \"offline\",\n                \"message\": str(e),\n                \"models\": {}\n            }\n        return self.system_health\n\n    def format_message_with_context(self, message: str, context: Dict[str, Any], target_model: str) -> List[Dict[str, str]]:\n        formatted_messages = []\n        if \"conversation_purpose\" in context:\n            formatted_messages.append({\"role\": \"system\", \"content\": f\"Purpose: {context['conversation_purpose']}\"})\n        if \"conversation_history\" in context:\n            formatted_messages.extend(context[\"conversation_history\"][-10:])\n        if \"patterns\" in context:\n            patterns_summary = \"\\n\".join(\n                f\"{ptype}: \" + \"; \".join(p[\"text\"] for p in plist[:3])\n                for ptype, plist in context[\"patterns\"].items() if plist\n            )\n            if patterns_summary:\n                formatted_messages.append({\"role\": \"system\", \"content\": f\"Patterns: {patterns_summary}\"})\n        formatted_messages.append({\"role\": \"user\", \"content\": message})\n        return formatted_messages\n\n    def send_message(self, message: str, target_model: str, context: Optional[Dict[str, Any]] = None,\n                     max_tokens: int = 1000, temperature: float = 0.7) -> Dict[str, Any]:\n        formatted_messages = self.format_message_with_context(message, context or {}, target_model)\n        mathematical_pattern = None\n        if \"routing_info\" in (context or {}):\n            scores = context[\"routing_info\"].get(\"match_scores\", {})\n            if scores:\n                golden_ratio = 1.618\n                transformed = [v * (1 + golden_ratio * (i % 2)) for i, v in enumerate(scores.values())]\n                mathematical_pattern = {\"type\": \"bach_wave\", \"values\": transformed, \"resolution\": \"high\"}\n        try:\n            response = self.mcp_client.send_request(\n                source_model=\"dashboard\",\n                target_model=target_model,\n                request_type=\"chat\",\n                messages=formatted_messages,\n                max_tokens=max_tokens,\n                temperature=temperature,\n                mathematical_pattern=mathematical_pattern\n            )\n            logger.info(f\"Message sent to {target_model} successfully\")\n            return response\n        except requests.RequestException as e:\n            logger.error(f\"Failed to send message to {target_model}: {e}\")\n            return {\"error\": str(e)}\n\n    def send_message_to_claude(self, message: str, context: Optional[Dict[str, Any]] = None, max_tokens: int = 1000) -> Dict[str, Any]:\n        return self.send_message(message, \"claude\", context, max_tokens, temperature=0.7)\n\n    def send_message_to_grok(self, message: str, context: Optional[Dict[str, Any]] = None, max_tokens: int = 1000) -> Dict[str, Any]:\n        return self.send_message(message, \"grok\", context, max_tokens, temperature=0.8)\n\n    def send_wave_communication(self, target_model: str, wave_parameters: Dict[str, Any], content: Optional[str] = None) -> Dict[str, Any]:\n        try:\n            response = self.mcp_client.send_wave_communication(\n                source_model=\"dashboard\",\n                target_model=target_model,\n                wave_parameters=wave_parameters,\n                content=content\n            )\n            logger.info(f\"Wave communication sent to {target_model}\")\n            return response\n        except requests.RequestException as e:\n            logger.error(f\"Wave communication to {target_model} failed: {e}\")\n            return {\"error\": str(e)}\n\n    def send_claude_to_grok_bridge(self, topic: str, purpose: str, response: str, context: str = \"\", confidence: int = 8) -> Dict[str, Any]:\n        try:\n            return self.mcp_client.send_claude_to_grok(topic, purpose, context, confidence, response)\n        except requests.RequestException as e:\n            logger.error(f\"Claude-to-Grok bridge failed: {e}\")\n            return {\"error\": str(e)}\n\n    def send_grok_to_claude_bridge(self, topic: str, purpose: str, directive: str, context: str = \"\", initiative_level: int = 8) -> Dict[str, Any]:\n        try:\n            return self.mcp_client.send_grok_to_claude(topic, purpose, context, initiative_level, directive)\n        except requests.RequestException as e:\n            logger.error(f\"Grok-to-Claude bridge failed: {e}\")\n            return {\"error\": str(e)}\n\n# Example usage\nif __name__ == \"__main__\":\n    connector = DashboardMCPConnector()\n    health = connector.check_server_health()\n    print(f\"MCP Server Health: {health['status']}\")\n```\n\n### \ud83d\udea9 **Why These Changes?**\n\n- **Robust Health Checks**: Improved by checking every 30 seconds.\n- **Clear Error Handling**: Detailed logging on failures.\n- **Preservation of Original Logic**: Maintains wave-based communications (`wave_patterns`) and specialized message formats (`grok`, bridge comms).\n- **Compatibility**: No alterations to assumptions Claude DC relies on.\n\n### \ud83e\uddea **Next Steps:**\n1. Replace your current `dashboard_mcp_connector.py` file entirely with this updated version.\n2. Restart MCP and dashboard:\n```bash\npython3 -m uvicorn src.mcp.mcp_server:app --host 0.0.0.0 --port 8001\nstreamlit run dashboard_app.py\n```\n3. Verify dashboard shows MCP server as \"Online\" and communications are stable.\n\nLet me know if you encounter any further issues!"
  ],
  "source": "chatgpt",
  "timestamp": 1743633279.38497,
  "data_type": "message",
  "metadata": {
    "author": "assistant"
  }
}