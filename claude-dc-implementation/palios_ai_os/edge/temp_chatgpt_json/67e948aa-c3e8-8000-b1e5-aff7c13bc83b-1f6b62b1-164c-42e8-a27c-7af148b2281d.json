{"data_id": "67e948aa-c3e8-8000-b1e5-aff7c13bc83b-1f6b62b1-164c-42e8-a27c-7af148b2281d", "content": ["Here's the update and error:\n    def pattern_to_visual_parameters(self, pattern_embedding: np.ndarray) -> Dict[str, Any]:\n        \"\"\"\n        Convert pattern embedding to visual parameters for visualization.\n        \n        Args:\n            pattern_embedding: Pattern embedding vector\n            \n        Returns:\n            Dictionary of visual parameters\n        \"\"\"\n        # Apply PCA to reduce to essential components\n        if pattern_embedding.ndim == 1:\n            pattern_embedding = pattern_embedding.reshape(1, -1)\n            \n        if pattern_embedding.shape[1] > 3:\n            pca = PCA(n_components=3)\n            reduced = pca.fit_transform(pattern_embedding)[0]\n        else:\n            # Ensure the number of PCA components is valid\n            n_components = min(3, pattern_embedding.shape[1])\n            pca = PCA(n_components=n_components)\n            reduced = pca.fit_transform(pattern_embedding)[0]\n\n            # If we got fewer than 3 dimensions, pad with zeros\n            if len(reduced) < 3:\n                reduced = np.pad(reduced, (0, 3 - len(reduced)), 'constant')\n        \n        # Map to HSL color space (Hue, Saturation, Lightness)\n        # Hue: first component mapped to [0, 360]\n\nValueError: n_components=3 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'\nTraceback:\n\nFile \"/home/jesse/projects/palios-taey-nova/claude-dc-implementation/src/dashboard/app.py\", line 965, in <module>\n    main()\nFile \"/home/jesse/projects/palios-taey-nova/claude-dc-implementation/src/dashboard/app.py\", line 947, in main\n    display_pattern_visualization(patterns)\nFile \"/home/jesse/projects/palios-taey-nova/claude-dc-implementation/src/dashboard/app.py\", line 730, in display_pattern_visualization\n    img_data = generate_pattern_visualization(selected_pattern, confidence)\nFile \"/home/jesse/projects/palios-taey-nova/claude-dc-implementation/src/dashboard/app.py\", line 335, in generate_pattern_visualization\n    visual_params = model.pattern_to_visual_parameters(embedding.reshape(1, -1))\nFile \"/home/jesse/projects/palios-taey-nova/claude-dc-implementation/src/models/pattern_model.py\", line 467, in pattern_to_visual_parameters\n    reduced = pca.fit_transform(pattern_embedding)[0]\nFile \"/home/jesse/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\nFile \"/home/jesse/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\nFile \"/home/jesse/.local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py\", line 468, in fit_transform\n    U, S, _, X, x_is_centered, xp = self._fit(X)\nFile \"/home/jesse/.local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py\", line 542, in _fit\n    return self._fit_full(X, n_components, xp, is_array_api_compliant)\nFile \"/home/jesse/.local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py\", line 556, in _fit_full\n    raise ValueError("], "source": "ChatGPT", "timestamp": 1743541251.485, "data_type": "conversation", "metadata": {"author": "user", "original_conversation_id": "67e948aa-c3e8-8000-b1e5-aff7c13bc83b"}}